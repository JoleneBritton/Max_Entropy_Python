Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Loading pytorch/1.1.0
  Loading requirement: cuda/10.0 cudnn/7.4
['./GLYCOLYSIS_TCA_GOGAT_FUNCTION.py', '1', '6', '0', '1e-06']
./GLYCOLYSIS_TCA_GOGAT_FUNCTION.py 1 6 0 1e-06
The total numbers of args passed to the script: 5 
Args list: ['./GLYCOLYSIS_TCA_GOGAT_FUNCTION.py', '1', '6', '0', '1e-06'] 
Script name: ./GLYCOLYSIS_TCA_GOGAT_FUNCTION.py
Argument # 0 : ./GLYCOLYSIS_TCA_GOGAT_FUNCTION.py
Argument # 1 : 1
Argument # 2 : 6
Argument # 3 : 0
Argument # 4 : 1e-06
sim
1
n_back_step
6
using experimental metabolite data
False
learning_rate
1e-06
epsilon
0.5
eps_threshold
25
gamma
0.9
Using device: cpu
**************************************Path Length ds<0******************************************
195
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.01441152 0.16777216 0.13421773 0.2097152
 0.08589935 0.01441152 0.08589935 0.00000468 0.4096     0.2097152
 0.00123794 0.32768    0.10737418]
[11.79533284 11.79533284 11.79533284 11.79533284 11.79533284 11.79533284
 11.79533284 11.79533284 11.79533284 11.79533284  5.89766642  5.89766642
 11.79533284 11.79533284 11.79533284  5.89766642  5.89766642  5.89766642
 11.79533284 11.79533284  0.        ]
original epr
4.192209886227653
index of max error on path
189
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2179, grad_fn=<MaxBackward1>)

tensor(0.1546, grad_fn=<MaxBackward1>)
random,nn steps
94
101
TOTAL REWARD
13.930031065302032
ave loss
0.563875991717363
max_loss
1.0456700325012207
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.563875991717363, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 0}
TOTALPREDICTION
tensor([3.5298], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
189
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00377789 0.08589935 0.4096     0.64
 0.4096     0.00922337 0.262144   0.00002788 0.06871948 0.08589935
 0.00154743 0.10737418 0.2097152 ]
[11.79180748 11.79180748 11.79180748 11.79180748 11.79180748 11.79180748
 11.79180748 11.79180748 11.79180748 11.79180748  5.89590374  5.89590374
 11.79180748 11.79180748 11.79180748  5.89590374  5.89590374  5.89590374
 11.79180748 11.79180748  0.        ]
original epr
4.186842748100105
index of max error on path
184
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2178, grad_fn=<MaxBackward1>)

tensor(0.1546, grad_fn=<MaxBackward1>)
random,nn steps
91
98
TOTAL REWARD
13.924684054155277
ave loss
0.5682666123544098
max_loss
1.0316877365112305
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.563875991717363, 'num_bad_epochs': 1, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 1}
TOTALPREDICTION
tensor([3.5684], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
193
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00302231 0.262144   0.4096     0.2097152
 0.16777216 0.00922337 0.10737418 0.00001784 0.04398047 0.4096
 0.00241785 0.2097152  0.10737418]
[11.79428354 11.79428354 11.79428354 11.79428354 11.79428354 11.79428354
 11.79428354 11.79428354 11.79428354 11.79428354  5.89714177  5.89714177
 11.79428354 11.79428354 11.79428354  5.89714177  5.89714177  5.89714177
 11.79428354 11.79428354  0.        ]
original epr
4.191889685827513
index of max error on path
187
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2178, grad_fn=<MaxBackward1>)

tensor(0.1547, grad_fn=<MaxBackward1>)
random,nn steps
93
100
TOTAL REWARD
13.814905756990122
ave loss
0.5464970875589341
max_loss
0.9667248725891113
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.5464970875589341, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 2}
TOTALPREDICTION
tensor([3.6532], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
188
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00590296 0.262144   0.2097152  0.4096
 0.08589935 0.08589935 0.4096     0.00000374 0.2097152  0.4096
 0.00302231 0.00472237 0.32768   ]
[11.79339289 11.79339289 11.79339289 11.79339289 11.79339289 11.79339289
 11.79339289 11.79339289 11.79339289 11.79339289  5.89669644  5.89669644
 11.79339289 11.79339289 11.79339289  5.89669644  5.89669644  5.89669644
 11.79339289 11.79339289  0.        ]
original epr
4.182863548781804
index of max error on path
182
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2178, grad_fn=<MaxBackward1>)

tensor(0.1548, grad_fn=<MaxBackward1>)
random,nn steps
88
100
TOTAL REWARD
13.960885147263628
ave loss
0.583229790501138
max_loss
1.053523063659668
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.5464970875589341, 'num_bad_epochs': 1, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 3}
TOTALPREDICTION
tensor([3.5658], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
195
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.01441152 0.2097152  0.2097152  0.262144
 0.00922337 0.0180144  0.262144   0.00000585 0.16777216 0.32768
 0.00472237 0.13421773 0.08589935]
[11.79567043 11.79567043 11.79567043 11.79567043 11.79567043 11.79567043
 11.79567043 11.79567043 11.79567043 11.79567043  5.89783521  5.89783521
 11.79567043 11.79567043 11.79567043  5.89783521  5.89783521  5.89783521
 11.79567043 11.79567043  0.        ]
original epr
4.193207507414539
index of max error on path
189
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2177, grad_fn=<MaxBackward1>)

tensor(0.1549, grad_fn=<MaxBackward1>)
random,nn steps
99
96
TOTAL REWARD
13.928735493314521
ave loss
0.5494430250082261
max_loss
0.9635171890258789
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.5464970875589341, 'num_bad_epochs': 2, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 4}
TOTALPREDICTION
tensor([3.6985], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
191
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.01441152 0.08589935 0.16777216 0.13421773
 0.10737418 0.01441152 0.13421773 0.0000223  0.13421773 0.08589935
 0.00472237 0.10737418 0.4096    ]
[11.72231149 11.72231149 11.72231149 11.72231149 11.72231149 11.72231149
 11.72231149 11.72231149 11.72231149 11.72231149  5.86115575  5.86115575
 11.72231149 11.72231149 11.72231149  5.86115575  5.86115575  5.86115575
 11.72231149 11.72231149  0.        ]
original epr
4.180338217781358
index of max error on path
185
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2177, grad_fn=<MaxBackward1>)

tensor(0.1549, grad_fn=<MaxBackward1>)
random,nn steps
108
83
TOTAL REWARD
13.917776069121954
ave loss
0.5671153169963996
max_loss
1.0437772274017334
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.5464970875589341, 'num_bad_epochs': 3, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 5}
TOTALPREDICTION
tensor([3.6315], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
190
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.0180144  0.08589935 0.16777216 0.262144
 0.2097152  0.00590296 0.06871948 0.00002788 0.10737418 0.2097152
 0.00241785 0.2097152  0.2097152 ]
[11.79675134 11.79675134 11.79675134 11.79675134 11.79675134 11.79675134
 11.79675134 11.79675134 11.79675134 11.79675134  5.89837567  5.89837567
 11.79675134 11.79675134 11.79675134  5.89837567  5.89837567  5.89837567
 11.79675134 11.79675134  0.        ]
original epr
4.188467111974955
index of max error on path
184
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2176, grad_fn=<MaxBackward1>)

tensor(0.1550, grad_fn=<MaxBackward1>)
random,nn steps
108
82
TOTAL REWARD
13.731637147461878
ave loss
0.5607817017718365
max_loss
0.9344568252563477
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.5464970875589341, 'num_bad_epochs': 4, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 6}
TOTALPREDICTION
tensor([3.6042], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
197
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.0180144  0.08589935 0.262144   0.262144
 0.16777216 0.00302231 0.16777216 0.00001784 0.512      0.04398047
 0.00922337 0.05497558 0.04398047]
[11.79451218 11.79451218 11.79451218 11.79451218 11.79451218 11.79451218
 11.79451218 11.79451218 11.79451218 11.79451218  5.89725609  5.89725609
 11.79451218 11.79451218 11.79451218  5.89725609  5.89725609  5.89725609
 11.79451218 11.79451218  0.        ]
original epr
4.1943872245051645
index of max error on path
191
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2176, grad_fn=<MaxBackward1>)

tensor(0.1550, grad_fn=<MaxBackward1>)
random,nn steps
114
83
TOTAL REWARD
13.886135452929347
ave loss
0.5541291690719914
max_loss
0.9978037476539612
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.5464970875589341, 'num_bad_epochs': 5, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 7}
TOTALPREDICTION
tensor([3.7201], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
198
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.0180144  0.16777216 0.13421773 0.022518
 0.06871948 0.022518   0.08589935 0.00000585 0.16777216 0.262144
 0.00472237 0.2097152  0.2097152 ]
[11.79718614 11.79718614 11.79718614 11.79718614 11.79718614 11.79718614
 11.79718614 11.79718614 11.79718614 11.79718614  5.89859307  5.89859307
 11.79718614 11.79718614 11.79718614  5.89859307  5.89859307  5.89859307
 11.79718614 11.79718614  0.        ]
original epr
4.18852995099788
index of max error on path
192
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2175, grad_fn=<MaxBackward1>)

tensor(0.1551, grad_fn=<MaxBackward1>)
random,nn steps
112
86
TOTAL REWARD
14.002666283275735
ave loss
0.54369805241474
max_loss
1.0305731296539307
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.54369805241474, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 8}
TOTALPREDICTION
tensor([3.7538], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
190
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.01152922 0.05497558 0.13421773 0.4096
 0.13421773 0.022518   0.08589935 0.00001142 0.13421773 0.2097152
 0.00590296 0.08589935 0.262144  ]
[11.79614209 11.79614209 11.79614209 11.79614209 11.79614209 11.79614209
 11.79614209 11.79614209 11.79614209 11.79614209  5.89807104  5.89807104
 11.79614209 11.79614209 11.79614209  5.89807104  5.89807104  5.89807104
 11.79614209 11.79614209  0.        ]
original epr
4.186093507198483
index of max error on path
184
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2175, grad_fn=<MaxBackward1>)

tensor(0.1551, grad_fn=<MaxBackward1>)
random,nn steps
98
92
TOTAL REWARD
13.884758167600275
ave loss
0.5507278465910962
max_loss
1.0361497402191162
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.54369805241474, 'num_bad_epochs': 1, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 9}
TOTALPREDICTION
tensor([3.5984], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
195
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00154743 0.512      0.2097152  0.32768
 0.262144   0.00590296 0.13421773 0.00001142 0.05497558 0.4096
 0.00123794 0.4096     0.08589935]
[11.79308292 11.79308292 11.79308292 11.79308292 11.79308292 11.79308292
 11.79308292 11.79308292 11.79308292 11.79308292  5.89654146  5.89654146
 11.79308292 11.79308292 11.79308292  5.89654146  5.89654146  5.89654146
 11.79308292 11.79308292  0.        ]
original epr
4.192604229849282
index of max error on path
189
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2174, grad_fn=<MaxBackward1>)

tensor(0.1552, grad_fn=<MaxBackward1>)
random,nn steps
92
103
TOTAL REWARD
13.97196228700861
ave loss
0.5247353215248157
max_loss
0.9516319036483765
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.5247353215248157, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 10}
TOTALPREDICTION
tensor([3.7000], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
190
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.0073787  0.13421773 0.13421773 0.4096
 0.13421773 0.0073787  0.0281475  0.00000913 0.16777216 0.2097152
 0.00302231 1.         0.262144  ]
[11.79121216 11.79121216 11.79121216 11.79121216 11.79121216 11.79121216
 11.79121216 11.79121216 11.79121216 11.79121216  5.89560608  5.89560608
 11.79121216 11.79121216 11.79121216  5.89560608  5.89560608  5.89560608
 11.79121216 11.79121216  0.        ]
original epr
4.184669923076164
index of max error on path
184
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2174, grad_fn=<MaxBackward1>)

tensor(0.1553, grad_fn=<MaxBackward1>)
random,nn steps
92
98
TOTAL REWARD
14.047539187058272
ave loss
0.5504718493474158
max_loss
1.0154173374176025
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.5247353215248157, 'num_bad_epochs': 1, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 11}
TOTALPREDICTION
tensor([3.5833], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
191
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.01441152 0.2097152  0.13421773 0.2097152
 0.00123794 0.10737418 0.2097152  0.00001142 0.13421773 0.16777216
 0.00590296 0.262144   0.32768   ]
[11.79684939 11.79684939 11.79684939 11.79684939 11.79684939 11.79684939
 11.79684939 11.79684939 11.79684939 11.79684939  5.89842469  5.89842469
 11.79684939 11.79684939 11.79684939  5.89842469  5.89842469  5.89842469
 11.79684939 11.79684939  0.        ]
original epr
4.1838027947285905
index of max error on path
185
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2173, grad_fn=<MaxBackward1>)

tensor(0.1553, grad_fn=<MaxBackward1>)
random,nn steps
93
98
TOTAL REWARD
13.972360142262328
ave loss
0.5573067652617449
max_loss
1.0106250047683716
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.5247353215248157, 'num_bad_epochs': 2, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 12}
TOTALPREDICTION
tensor([3.5928], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
193
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00590296 0.262144   0.16777216 0.10737418
 0.13421773 0.01152922 0.262144   0.00000585 0.32768    0.2097152
 0.00241785 0.08589935 0.2097152 ]
[11.79607221 11.79607221 11.79607221 11.79607221 11.79607221 11.79607221
 11.79607221 11.79607221 11.79607221 11.79607221  5.8980361   5.8980361
 11.79607221 11.79607221 11.79607221  5.8980361   5.8980361   5.8980361
 11.79607221 11.79607221  0.        ]
original epr
4.188327992812614
index of max error on path
187
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2173, grad_fn=<MaxBackward1>)

tensor(0.1554, grad_fn=<MaxBackward1>)
random,nn steps
96
97
TOTAL REWARD
13.928785970062862
ave loss
0.5383388622437116
max_loss
0.9562444090843201
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.5247353215248157, 'num_bad_epochs': 3, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 13}
TOTALPREDICTION
tensor([3.6563], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
197
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00302231 0.4096     0.04398047 0.13421773
 0.00590296 0.10737418 0.13421773 0.00001142 0.2097152  0.13421773
 0.01441152 0.16777216 0.16777216]
[11.79682656 11.79682656 11.79682656 11.79682656 11.79682656 11.79682656
 11.79682656 11.79682656 11.79682656 11.79682656  5.89841328  5.89841328
 11.79682656 11.79682656 11.79682656  5.89841328  5.89841328  5.89841328
 11.79682656 11.79682656  0.        ]
original epr
4.190186244966387
index of max error on path
191
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2173, grad_fn=<MaxBackward1>)

tensor(0.1555, grad_fn=<MaxBackward1>)
random,nn steps
106
91
TOTAL REWARD
13.990368689586072
ave loss
0.528406835903371
max_loss
1.0005362033843994
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.5247353215248157, 'num_bad_epochs': 4, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 14}
TOTALPREDICTION
tensor([3.6960], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
196
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.0073787  0.262144   0.32768    0.512
 0.16777216 0.00154743 0.16777216 0.00001784 0.2097152  0.04398047
 0.0073787  0.10737418 0.05497558]
[11.79403893 11.79403893 11.79403893 11.79403893 11.79403893 11.79403893
 11.79403893 11.79403893 11.79403893 11.79403893  5.89701946  5.89701946
 11.79403893 11.79403893 11.79403893  5.89701946  5.89701946  5.89701946
 11.79403893 11.79403893  0.        ]
original epr
4.193870623439695
index of max error on path
190
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2172, grad_fn=<MaxBackward1>)

tensor(0.1556, grad_fn=<MaxBackward1>)
random,nn steps
92
104
TOTAL REWARD
13.969660431303016
ave loss
0.5279098968876867
max_loss
0.9571110010147095
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.5247353215248157, 'num_bad_epochs': 5, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 15}
TOTALPREDICTION
tensor([3.6876], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
194
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.01441152 0.13421773 0.08589935 0.10737418
 0.262144   0.0180144  0.05497558 0.00000913 0.8        0.05497558
 0.00241785 0.13421773 0.262144  ]
[11.71638939 11.71638939 11.71638939 11.71638939 11.71638939 11.71638939
 11.71638939 11.71638939 11.71638939 11.71638939  5.85819469  5.85819469
 11.71638939 11.71638939 11.71638939  5.85819469  5.85819469  5.85819469
 11.71638939 11.71638939  0.        ]
original epr
4.184041225960607
index of max error on path
188
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2172, grad_fn=<MaxBackward1>)

tensor(0.1556, grad_fn=<MaxBackward1>)
random,nn steps
95
99
TOTAL REWARD
13.948442390974153
ave loss
0.5350011424305513
max_loss
0.9840386509895325
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.5247353215248157, 'num_bad_epochs': 6, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 16}
TOTALPREDICTION
tensor([3.6768], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
201
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00302231 0.32768    0.2097152  0.32768
 0.0281475  0.01152922 0.262144   0.00000468 0.262144   0.262144
 0.00241785 0.32768    0.022518  ]
[11.71903272 11.71903272 11.71903272 11.71903272 11.71903272 11.71903272
 11.71903272 11.71903272 11.71903272 11.71903272  5.85951636  5.85951636
 11.71903272 11.71903272 11.71903272  5.85951636  5.85951636  5.85951636
 11.71903272 11.71903272  0.        ]
original epr
4.195360837357612
index of max error on path
197
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2171, grad_fn=<MaxBackward1>)

tensor(0.1558, grad_fn=<MaxBackward1>)
random,nn steps
103
98
TOTAL REWARD
13.972306738550579
ave loss
0.5010073327306491
max_loss
0.8782418966293335
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.5010073327306491, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 17}
TOTALPREDICTION
tensor([3.7702], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
196
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.01152922 0.16777216 0.32768    0.4096
 0.0180144  0.0180144  0.16777216 0.00002788 0.03518437 0.08589935
 0.0073787  0.13421773 0.08589935]
[11.79560622 11.79560622 11.79560622 11.79560622 11.79560622 11.79560622
 11.79560622 11.79560622 11.79560622 11.79560622  5.89780311  5.89780311
 11.79560622 11.79560622 11.79560622  5.89780311  5.89780311  5.89780311
 11.79560622 11.79560622  0.        ]
original epr
4.19303689954104
index of max error on path
190
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2171, grad_fn=<MaxBackward1>)

tensor(0.1558, grad_fn=<MaxBackward1>)
random,nn steps
98
98
TOTAL REWARD
13.950998590310897
ave loss
0.5219484126689483
max_loss
0.9524045586585999
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.5010073327306491, 'num_bad_epochs': 1, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 18}
TOTALPREDICTION
tensor([3.6984], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
194
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00472237 0.16777216 0.16777216 0.2097152
 0.2097152  0.01441152 0.08589935 0.00000731 0.10737418 0.4096
 0.00154743 0.32768    0.13421773]
[11.79537247 11.79537247 11.79537247 11.79537247 11.79537247 11.79537247
 11.79537247 11.79537247 11.79537247 11.79537247  5.89768624  5.89768624
 11.79537247 11.79537247 11.79537247  5.89768624  5.89768624  5.89768624
 11.79537247 11.79537247  0.        ]
original epr
4.191158877411563
index of max error on path
190
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2170, grad_fn=<MaxBackward1>)

tensor(0.1559, grad_fn=<MaxBackward1>)
random,nn steps
89
105
TOTAL REWARD
13.966634936845779
ave loss
0.5214797393562868
max_loss
0.9064633250236511
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.5010073327306491, 'num_bad_epochs': 2, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 19}
TOTALPREDICTION
tensor([3.6630], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
193
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00377789 0.32768    0.512      0.10737418
 0.2097152  0.0281475  0.13421773 0.00000913 0.4096     0.08589935
 0.00040565 0.2097152  0.13421773]
[11.79334138 11.79334138 11.79334138 11.79334138 11.79334138 11.79334138
 11.79334138 11.79334138 11.79334138 11.79334138  5.89667069  5.89667069
 11.79334138 11.79334138 11.79334138  5.89667069  5.89667069  5.89667069
 11.79334138 11.79334138  0.        ]
original epr
4.190498979385911
index of max error on path
187
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2170, grad_fn=<MaxBackward1>)

tensor(0.1560, grad_fn=<MaxBackward1>)
random,nn steps
95
98
TOTAL REWARD
13.972927817823221
ave loss
0.5262213858915734
max_loss
0.9673062562942505
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.5010073327306491, 'num_bad_epochs': 3, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 20}
TOTALPREDICTION
tensor([3.6131], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
189
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00241785 0.4096     0.262144   0.16777216
 0.16777216 0.00590296 0.2097152  0.00000731 0.32768    0.13421773
 0.00193428 0.2097152  0.4096    ]
[11.71968655 11.71968655 11.71968655 11.71968655 11.71968655 11.71968655
 11.71968655 11.71968655 11.71968655 11.71968655  5.85984328  5.85984328
 11.71968655 11.71968655 11.71968655  5.85984328  5.85984328  5.85984328
 11.71968655 11.71968655  0.        ]
original epr
4.179847862567133
index of max error on path
183
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2169, grad_fn=<MaxBackward1>)

tensor(0.1561, grad_fn=<MaxBackward1>)
random,nn steps
95
94
TOTAL REWARD
13.95839900111162
ave loss
0.5255731517675692
max_loss
0.965390682220459
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.5010073327306491, 'num_bad_epochs': 4, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 21}
TOTALPREDICTION
tensor([3.5707], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
190
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00922337 0.262144   0.0281475  0.08589935
 0.32768    0.00241785 0.2097152  0.00002788 0.08589935 0.32768
 0.00302231 0.2097152  0.8       ]
[11.79624264 11.79624264 11.79624264 11.79624264 11.79624264 11.79624264
 11.79624264 11.79624264 11.79624264 11.79624264  5.89812132  5.89812132
 11.79624264 11.79624264 11.79624264  5.89812132  5.89812132  5.89812132
 11.79624264 11.79624264  0.        ]
original epr
4.164766532690155
index of max error on path
184
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2169, grad_fn=<MaxBackward1>)

tensor(0.1561, grad_fn=<MaxBackward1>)
random,nn steps
97
93
TOTAL REWARD
13.680840039908805
ave loss
0.5215065871414385
max_loss
0.8758085370063782
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.5010073327306491, 'num_bad_epochs': 5, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 22}
TOTALPREDICTION
tensor([3.5780], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
196
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00377789 0.16777216 0.2097152  0.2097152
 0.262144   0.00922337 0.10737418 0.00001142 0.08589935 0.4096
 0.00193428 0.262144   0.06871948]
[11.79530699 11.79530699 11.79530699 11.79530699 11.79530699 11.79530699
 11.79530699 11.79530699 11.79530699 11.79530699  5.8976535   5.8976535
 11.79530699 11.79530699 11.79530699  5.8976535   5.8976535   5.8976535
 11.79530699 11.79530699  0.        ]
original epr
4.193785695021443
index of max error on path
190
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2169, grad_fn=<MaxBackward1>)

tensor(0.1563, grad_fn=<MaxBackward1>)
random,nn steps
92
104
TOTAL REWARD
13.885811596270168
ave loss
0.4868385986405976
max_loss
0.8525245189666748
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.4868385986405976, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 23}
TOTALPREDICTION
tensor([3.6942], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
194
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00922337 0.32768    0.06871948 0.262144
 0.2097152  0.00472237 0.06871948 0.00000913 0.13421773 0.262144
 0.00302231 0.2097152  0.2097152 ]
[11.72070326 11.72070326 11.72070326 11.72070326 11.72070326 11.72070326
 11.72070326 11.72070326 11.72070326 11.72070326  5.86035163  5.86035163
 11.72070326 11.72070326 11.72070326  5.86035163  5.86035163  5.86035163
 11.72070326 11.72070326  0.        ]
original epr
4.188126436720068
index of max error on path
189
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2168, grad_fn=<MaxBackward1>)

tensor(0.1564, grad_fn=<MaxBackward1>)
random,nn steps
105
89
TOTAL REWARD
13.94080173571747
ave loss
0.5021838550407862
max_loss
0.9074921607971191
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.4868385986405976, 'num_bad_epochs': 1, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 24}
TOTALPREDICTION
tensor([3.6641], grad_fn=<AddBackward0>)
RESET epsilon ANNEALING
0.25
**************************************Path Length ds<0******************************************
205
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00377789 0.4096     0.16777216 0.512
 0.4096     0.00241785 0.4096     0.00004356 0.00241785 0.2097152
 0.00079228 0.512      0.0281475 ]
[11.79176474 11.79176474 11.79176474 11.79176474 11.79176474 11.79176474
 11.79176474 11.79176474 11.79176474 11.79176474  5.89588237  5.89588237
 11.79176474 11.79176474 11.79176474  5.89588237  5.89588237  5.89588237
 11.79176474 11.79176474  0.        ]
original epr
4.1945893843229705
index of max error on path
124
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2168, grad_fn=<MaxBackward1>)

tensor(0.1565, grad_fn=<MaxBackward1>)
random,nn steps
64
141
TOTAL REWARD
13.778770642745352
ave loss
0.45255300489867606
max_loss
0.9408146142959595
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.45255300489867606, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 25}
TOTALPREDICTION
tensor([3.7936], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
191
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00079228 0.64       0.2097152  1.
 0.04398047 0.00922337 0.262144   0.00000098 0.512      0.8
 0.00123794 0.512      0.10737418]
[11.70106649 11.70106649 11.70106649 11.70106649 11.70106649 11.70106649
 11.70106649 11.70106649 11.70106649 11.70106649  5.85053325  5.85053325
 11.70106649 11.70106649 11.70106649  5.85053325  5.85053325  5.85053325
 11.70106649 11.70106649  0.        ]
original epr
4.184924851677987
index of max error on path
185
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2167, grad_fn=<MaxBackward1>)

tensor(0.1566, grad_fn=<MaxBackward1>)
random,nn steps
44
147
TOTAL REWARD
14.116118759954785
ave loss
0.5054492073533423
max_loss
0.873519778251648
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.45255300489867606, 'num_bad_epochs': 1, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 26}
TOTALPREDICTION
tensor([3.5540], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
202
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.01152922 0.32768    0.32768    0.64
 0.262144   0.00040565 0.32768    0.00004356 0.00079228 0.262144
 0.00472237 0.4096     0.05497558]
[11.79088396 11.79088396 11.79088396 11.79088396 11.79088396 11.79088396
 11.79088396 11.79088396 11.79088396 11.79088396  5.89544198  5.89544198
 11.79088396 11.79088396 11.79088396  5.89544198  5.89544198  5.89544198
 11.79088396 11.79088396  0.        ]
original epr
4.193016563117542
index of max error on path
196
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2167, grad_fn=<MaxBackward1>)

tensor(0.1567, grad_fn=<MaxBackward1>)
random,nn steps
48
154
TOTAL REWARD
13.914196554884425
ave loss
0.46517928424153
max_loss
0.8884105086326599
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.45255300489867606, 'num_bad_epochs': 2, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 27}
TOTALPREDICTION
tensor([3.7517], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
190
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00377789 0.05497558 0.4096     0.262144
 0.08589935 0.00590296 0.512      0.00000239 0.512      0.32768
 0.00193428 0.512      0.16777216]
[11.79025395 11.79025395 11.79025395 11.79025395 11.79025395 11.79025395
 11.79025395 11.79025395 11.79025395 11.79025395  5.89512698  5.89512698
 11.79025395 11.79025395 11.79025395  5.89512698  5.89512698  5.89512698
 11.79025395 11.79025395  0.        ]
original epr
4.188414180664144
index of max error on path
184
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2168, grad_fn=<MaxBackward1>)

tensor(0.1568, grad_fn=<MaxBackward1>)
random,nn steps
51
139
TOTAL REWARD
13.96474645874111
ave loss
0.5077576276503111
max_loss
0.9107531905174255
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.45255300489867606, 'num_bad_epochs': 3, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 28}
TOTALPREDICTION
tensor([3.5427], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
188
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00020769 1.         0.512      0.262144
 0.01152922 1.         0.512      0.00002788 0.8        0.00922337
 0.00013292 0.4096     0.32768   ]
[11.77766123 11.77766123 11.77766123 11.77766123 11.77766123 11.77766123
 11.77766123 11.77766123 11.77766123 11.77766123  5.88883061  5.88883061
 11.77766123 11.77766123 11.77766123  5.88883061  5.88883061  5.88883061
 11.77766123 11.77766123  0.        ]
original epr
4.177707222094659
index of max error on path
182
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2169, grad_fn=<MaxBackward1>)

tensor(0.1569, grad_fn=<MaxBackward1>)
random,nn steps
42
146
TOTAL REWARD
14.028214816887457
ave loss
0.5186363929446708
max_loss
0.9215800762176514
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.45255300489867606, 'num_bad_epochs': 4, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 29}
TOTALPREDICTION
tensor([3.4923], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
185
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00099035 0.64       0.512      0.2097152
 0.64       0.00016615 0.8        0.00000585 0.512      0.13421773
 0.00193428 0.512      0.512     ]
[11.78469243 11.78469243 11.78469243 11.78469243 11.78469243 11.78469243
 11.78469243 11.78469243 11.78469243 11.78469243  5.89234622  5.89234622
 11.78469243 11.78469243 11.78469243  5.89234622  5.89234622  5.89234622
 11.78469243 11.78469243  0.        ]
original epr
4.173153536772757
index of max error on path
179
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2169, grad_fn=<MaxBackward1>)

tensor(0.1569, grad_fn=<MaxBackward1>)
random,nn steps
41
144
TOTAL REWARD
14.011913285167578
ave loss
0.5258749557508005
max_loss
0.9269469976425171
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.45255300489867606, 'num_bad_epochs': 5, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 30}
TOTALPREDICTION
tensor([3.4752], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
184
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00032452 0.512      0.64       0.512
 0.64       0.00123794 0.8        0.00000192 0.32768    0.8
 0.00063383 0.4096     0.32768   ]
[11.77792496 11.77792496 11.77792496 11.77792496 11.77792496 11.77792496
 11.77792496 11.77792496 11.77792496 11.77792496  5.88896248  5.88896248
 11.77792496 11.77792496 11.77792496  5.88896248  5.88896248  5.88896248
 11.77792496 11.77792496  0.        ]
original epr
4.177885135179849
index of max error on path
178
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2170, grad_fn=<MaxBackward1>)

tensor(0.1570, grad_fn=<MaxBackward1>)
random,nn steps
40
144
TOTAL REWARD
13.95760769549314
ave loss
0.5081459244956141
max_loss
0.8870983123779297
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.45255300489867606, 'num_bad_epochs': 6, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 31}
TOTALPREDICTION
tensor([3.4304], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
199
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00063383 0.64       0.262144   0.512
 0.8        0.0281475  0.512      0.00000731 0.16777216 0.262144
 0.00013292 0.08589935 0.022518  ]
[11.78817191 11.78817191 11.78817191 11.78817191 11.78817191 11.78817191
 11.78817191 11.78817191 11.78817191 11.78817191  5.89408596  5.89408596
 11.78817191 11.78817191 11.78817191  5.89408596  5.89408596  5.89408596
 11.78817191 11.78817191  0.        ]
original epr
4.193768365516785
index of max error on path
193
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2171, grad_fn=<MaxBackward1>)

tensor(0.1572, grad_fn=<MaxBackward1>)
random,nn steps
53
146
TOTAL REWARD
13.993270212131142
ave loss
0.4729947685895853
max_loss
0.8457827568054199
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.45255300489867606, 'num_bad_epochs': 7, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 32}
TOTALPREDICTION
tensor([3.6813], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
186
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00032452 0.64       0.512      0.64
 0.4096     0.00302231 0.32768    0.00000374 0.262144   0.512
 0.00063383 0.512      0.2097152 ]
[11.78444972 11.78444972 11.78444972 11.78444972 11.78444972 11.78444972
 11.78444972 11.78444972 11.78444972 11.78444972  5.89222486  5.89222486
 11.78444972 11.78444972 11.78444972  5.89222486  5.89222486  5.89222486
 11.78444972 11.78444972  0.        ]
original epr
4.184948893855926
index of max error on path
180
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2171, grad_fn=<MaxBackward1>)

tensor(0.1573, grad_fn=<MaxBackward1>)
random,nn steps
53
133
TOTAL REWARD
13.922320270578453
ave loss
0.4978586536261343
max_loss
0.8775524497032166
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.45255300489867606, 'num_bad_epochs': 8, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 33}
TOTALPREDICTION
tensor([3.4652], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
201
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00922337 0.2097152  0.10737418 0.262144
 0.512      0.00302231 0.512      0.00005445 0.00050706 0.4096
 0.00063383 0.64       0.16777216]
[11.79156176 11.79156176 11.79156176 11.79156176 11.79156176 11.79156176
 11.79156176 11.79156176 11.79156176 11.79156176  5.89578088  5.89578088
 11.79156176 11.79156176 11.79156176  5.89578088  5.89578088  5.89578088
 11.79156176 11.79156176  0.        ]
original epr
4.188941410211488
index of max error on path
116
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2172, grad_fn=<MaxBackward1>)

tensor(0.1575, grad_fn=<MaxBackward1>)
random,nn steps
54
147
TOTAL REWARD
13.891998714133923
ave loss
0.44618424343232493
max_loss
0.8772985935211182
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.44618424343232493, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 34}
TOTALPREDICTION
tensor([3.7095], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
192
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00063383 0.64       0.512      0.8
 0.0073787  0.01441152 0.64       0.00000239 0.4096     0.4096
 0.00302231 0.32768    0.05497558]
[11.78234114 11.78234114 11.78234114 11.78234114 11.78234114 11.78234114
 11.78234114 11.78234114 11.78234114 11.78234114  5.89117057  5.89117057
 11.78234114 11.78234114 11.78234114  5.89117057  5.89117057  5.89117057
 11.78234114 11.78234114  0.        ]
original epr
4.190171027010726
index of max error on path
186
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2172, grad_fn=<MaxBackward1>)

tensor(0.1576, grad_fn=<MaxBackward1>)
random,nn steps
52
140
TOTAL REWARD
13.98090459887456
ave loss
0.46706292242743075
max_loss
0.8493151664733887
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.44618424343232493, 'num_bad_epochs': 1, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 35}
TOTALPREDICTION
tensor([3.5388], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
187
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00193428 0.262144   0.4096     0.8
 0.04398047 0.0073787  0.4096     0.00002788 0.01152922 0.4096
 0.00241785 0.32768    0.32768   ]
[11.78770172 11.78770172 11.78770172 11.78770172 11.78770172 11.78770172
 11.78770172 11.78770172 11.78770172 11.78770172  5.89385086  5.89385086
 11.78770172 11.78770172 11.78770172  5.89385086  5.89385086  5.89385086
 11.78770172 11.78770172  0.        ]
original epr
4.180688320248729
index of max error on path
181
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2173, grad_fn=<MaxBackward1>)

tensor(0.1577, grad_fn=<MaxBackward1>)
random,nn steps
54
133
TOTAL REWARD
13.85068530395538
ave loss
0.48255271914808506
max_loss
0.8858295679092407
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.44618424343232493, 'num_bad_epochs': 2, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 36}
TOTALPREDICTION
tensor([3.4917], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
186
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.05497558 0.022518   0.262144   0.32768
 0.00590296 0.00016615 0.512      0.00000585 0.10737418 0.512
 0.16777216 0.64       0.512     ]
[11.79094975 11.79094975 11.79094975 11.79094975 11.79094975 11.79094975
 11.79094975 11.79094975 11.79094975 11.79094975  5.89547487  5.89547487
 11.79094975 11.79094975 11.79094975  5.89547487  5.89547487  5.89547487
 11.79094975 11.79094975  0.        ]
original epr
4.174825589843035
index of max error on path
180
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2173, grad_fn=<MaxBackward1>)

tensor(0.1578, grad_fn=<MaxBackward1>)
random,nn steps
45
141
TOTAL REWARD
13.94669137367698
ave loss
0.5065622695030705
max_loss
0.8981400728225708
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.44618424343232493, 'num_bad_epochs': 3, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 37}
TOTALPREDICTION
tensor([3.4628], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
193
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00013292 0.4096     0.4096     0.512
 0.64       0.262144   0.262144   0.00000153 0.4096     0.8
 0.00005445 0.262144   0.05497558]
[11.78303538 11.78303538 11.78303538 11.78303538 11.78303538 11.78303538
 11.78303538 11.78303538 11.78303538 11.78303538  5.89151769  5.89151769
 11.78303538 11.78303538 11.78303538  5.89151769  5.89151769  5.89151769
 11.78303538 11.78303538  0.        ]
original epr
4.190472410254303
index of max error on path
187
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2174, grad_fn=<MaxBackward1>)

tensor(0.1579, grad_fn=<MaxBackward1>)
random,nn steps
42
151
TOTAL REWARD
13.941643426502909
ave loss
0.4580288464541262
max_loss
0.8437249660491943
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.44618424343232493, 'num_bad_epochs': 4, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 38}
TOTALPREDICTION
tensor([3.5702], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
195
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00006806 0.64       0.512      0.32768
 0.4096     1.         0.32768    0.00000299 0.64       0.2097152
 0.00003484 0.2097152  0.04398047]
[11.78240433 11.78240433 11.78240433 11.78240433 11.78240433 11.78240433
 11.78240433 11.78240433 11.78240433 11.78240433  5.89120216  5.89120216
 11.78240433 11.78240433 11.78240433  5.89120216  5.89120216  5.89120216
 11.78240433 11.78240433  0.        ]
original epr
4.191005410980289
index of max error on path
189
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2175, grad_fn=<MaxBackward1>)

tensor(0.1581, grad_fn=<MaxBackward1>)
random,nn steps
46
149
TOTAL REWARD
14.038804809764802
ave loss
0.46045845724069157
max_loss
0.8308963775634766
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.44618424343232493, 'num_bad_epochs': 5, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 39}
TOTALPREDICTION
tensor([3.6214], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
205
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00377789 0.64       0.32768    0.512
 0.512      0.00193428 0.32768    0.00003484 0.00099035 0.2097152
 0.00099035 0.4096     0.03518437]
[11.79011568 11.79011568 11.79011568 11.79011568 11.79011568 11.79011568
 11.79011568 11.79011568 11.79011568 11.79011568  5.89505784  5.89505784
 11.79011568 11.79011568 11.79011568  5.89505784  5.89505784  5.89505784
 11.79011568 11.79011568  0.        ]
original epr
4.193851512973538
index of max error on path
126
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2175, grad_fn=<MaxBackward1>)

tensor(0.1582, grad_fn=<MaxBackward1>)
random,nn steps
53
152
TOTAL REWARD
13.855899283595916
ave loss
0.4260874366614877
max_loss
0.8388658761978149
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.4260874366614877, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 40}
TOTALPREDICTION
tensor([3.7901], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
183
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.022518   0.0073787  0.512      0.512
 0.64       0.00154743 0.4096     0.00000299 0.4096     0.32768
 0.00099035 0.512      0.512     ]
[11.78690437 11.78690437 11.78690437 11.78690437 11.78690437 11.78690437
 11.78690437 11.78690437 11.78690437 11.78690437  5.89345219  5.89345219
 11.78690437 11.78690437 11.78690437  5.89345219  5.89345219  5.89345219
 11.78690437 11.78690437  0.        ]
original epr
4.173677399522008
index of max error on path
177
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2176, grad_fn=<MaxBackward1>)

tensor(0.1583, grad_fn=<MaxBackward1>)
random,nn steps
49
134
TOTAL REWARD
13.956562790944925
ave loss
0.489501890426125
max_loss
0.8871036767959595
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.4260874366614877, 'num_bad_epochs': 1, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 41}
TOTALPREDICTION
tensor([3.4376], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
185
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00016615 0.64       0.4096     0.32768
 0.00590296 0.262144   0.32768    0.00000585 0.64       0.08589935
 0.00193428 0.512      0.512     ]
[11.78792679 11.78792679 11.78792679 11.78792679 11.78792679 11.78792679
 11.78792679 11.78792679 11.78792679 11.78792679  5.8939634   5.8939634
 11.78792679 11.78792679 11.78792679  5.8939634   5.8939634   5.8939634
 11.78792679 11.78792679  0.        ]
original epr
4.17389981240847
index of max error on path
179
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2177, grad_fn=<MaxBackward1>)

tensor(0.1584, grad_fn=<MaxBackward1>)
random,nn steps
49
136
TOTAL REWARD
14.019428723089527
ave loss
0.5086882900547337
max_loss
0.904511570930481
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.4260874366614877, 'num_bad_epochs': 2, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 42}
TOTALPREDICTION
tensor([3.4010], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
180
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.03518437 0.00922337 0.64       0.64
 0.03518437 0.022518   0.64       0.00000098 0.512      0.8
 0.00025961 0.64       0.8       ]
[11.77823036 11.77823036 11.77823036 11.77823036 11.77823036 11.77823036
 11.77823036 11.77823036 11.77823036 11.77823036  5.88911518  5.88911518
 11.77823036 11.77823036 11.77823036  5.88911518  5.88911518  5.88911518
 11.77823036 11.77823036  0.        ]
original epr
4.158704180324877
index of max error on path
174
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2177, grad_fn=<MaxBackward1>)

tensor(0.1585, grad_fn=<MaxBackward1>)
random,nn steps
30
150
TOTAL REWARD
13.946392905489422
ave loss
0.4974571368760533
max_loss
0.8889173865318298
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.4260874366614877, 'num_bad_epochs': 3, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 43}
TOTALPREDICTION
tensor([3.3370], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
204
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.0281475  0.32768    0.4096     0.32768
 0.13421773 0.10737418 0.512      0.00004356 0.00079228 0.4096
 0.06871948 0.00005445 0.03518437]
[11.79246087 11.79246087 11.79246087 11.79246087 11.79246087 11.79246087
 11.79246087 11.79246087 11.79246087 11.79246087  5.89623043  5.89623043
 11.79246087 11.79246087 11.79246087  5.89623043  5.89623043  5.89623043
 11.79246087 11.79246087  0.        ]
original epr
4.194383050224551
index of max error on path
198
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2178, grad_fn=<MaxBackward1>)

tensor(0.1586, grad_fn=<MaxBackward1>)
random,nn steps
49
155
TOTAL REWARD
14.02276463594517
ave loss
0.44209246538287283
max_loss
0.815837025642395
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.4260874366614877, 'num_bad_epochs': 4, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 44}
TOTALPREDICTION
tensor([3.8025], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
185
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00123794 0.4096     0.512      0.32768
 0.32768    0.00123794 0.08589935 0.00000153 0.64       0.4096
 0.00302231 0.8        0.4096    ]
[11.78510907 11.78510907 11.78510907 11.78510907 11.78510907 11.78510907
 11.78510907 11.78510907 11.78510907 11.78510907  5.89255454  5.89255454
 11.78510907 11.78510907 11.78510907  5.89255454  5.89255454  5.89255454
 11.78510907 11.78510907  0.        ]
original epr
4.177035663942118
index of max error on path
179
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2178, grad_fn=<MaxBackward1>)

tensor(0.1587, grad_fn=<MaxBackward1>)
random,nn steps
47
138
TOTAL REWARD
13.970666884874566
ave loss
0.4877467353601713
max_loss
0.82300865650177
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.4260874366614877, 'num_bad_epochs': 5, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 45}
TOTALPREDICTION
tensor([3.4447], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
198
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00472237 0.512      0.64       0.00193428
 0.262144   0.00922337 0.262144   0.0000223  0.01152922 0.64
 0.00079228 0.64       0.4096    ]
[11.78692373 11.78692373 11.78692373 11.78692373 11.78692373 11.78692373
 11.78692373 11.78692373 11.78692373 11.78692373  5.89346187  5.89346187
 11.78692373 11.78692373 11.78692373  5.89346187  5.89346187  5.89346187
 11.78692373 11.78692373  0.        ]
original epr
4.177371785168792
index of max error on path
193
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2179, grad_fn=<MaxBackward1>)

tensor(0.1588, grad_fn=<MaxBackward1>)
random,nn steps
45
153
TOTAL REWARD
13.979446827945091
ave loss
0.43755929683796085
max_loss
0.7996786832809448
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.4260874366614877, 'num_bad_epochs': 6, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 46}
TOTALPREDICTION
tensor([3.6461], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
187
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00063383 0.64       0.262144   0.512
 0.512      0.00302231 0.32768    0.00000468 0.13421773 0.8
 0.00123794 0.16777216 0.262144  ]
[11.7853344 11.7853344 11.7853344 11.7853344 11.7853344 11.7853344
 11.7853344 11.7853344 11.7853344 11.7853344  5.8926672  5.8926672
 11.7853344 11.7853344 11.7853344  5.8926672  5.8926672  5.8926672
 11.7853344 11.7853344  0.       ]
original epr
4.182752070408679
index of max error on path
181
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2180, grad_fn=<MaxBackward1>)

tensor(0.1589, grad_fn=<MaxBackward1>)
random,nn steps
52
135
TOTAL REWARD
13.920308054615788
ave loss
0.4695276190890348
max_loss
0.8030363917350769
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.4260874366614877, 'num_bad_epochs': 7, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 47}
TOTALPREDICTION
tensor([3.4858], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
184
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.01152922 0.10737418 0.512      0.32768
 0.512      0.16777216 0.8        0.00001142 0.05497558 0.64
 0.0180144  0.00002788 0.512     ]
[11.78661373 11.78661373 11.78661373 11.78661373 11.78661373 11.78661373
 11.78661373 11.78661373 11.78661373 11.78661373  5.89330687  5.89330687
 11.78661373 11.78661373 11.78661373  5.89330687  5.89330687  5.89330687
 11.78661373 11.78661373  0.        ]
original epr
4.17330632176754
index of max error on path
178
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2180, grad_fn=<MaxBackward1>)

tensor(0.1590, grad_fn=<MaxBackward1>)
random,nn steps
37
147
TOTAL REWARD
13.998724990758756
ave loss
0.48393135444949503
max_loss
0.8638592958450317
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.4260874366614877, 'num_bad_epochs': 8, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 48}
TOTALPREDICTION
tensor([3.4291], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
192
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00099035 0.512      0.262144   0.512
 0.06871948 0.00099035 0.512      0.00000153 0.64       0.512
 0.00472237 0.512      0.08589935]
[11.7852078 11.7852078 11.7852078 11.7852078 11.7852078 11.7852078
 11.7852078 11.7852078 11.7852078 11.7852078  5.8926039  5.8926039
 11.7852078 11.7852078 11.7852078  5.8926039  5.8926039  5.8926039
 11.7852078 11.7852078  0.       ]
original epr
4.190073472450177
index of max error on path
186
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2181, grad_fn=<MaxBackward1>)

tensor(0.1591, grad_fn=<MaxBackward1>)
random,nn steps
46
146
TOTAL REWARD
13.95266273054942
ave loss
0.44385022250935435
max_loss
0.7812936305999756
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.4260874366614877, 'num_bad_epochs': 9, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 49}
TOTALPREDICTION
tensor([3.5214], grad_fn=<AddBackward0>)
RESET epsilon ANNEALING
0.125
**************************************Path Length ds<0******************************************
189
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00099035 0.64       0.8        0.512
 0.00193428 0.05497558 0.05497558 0.00000078 0.512      1.
 0.01441152 0.512      0.10737418]
[11.77487869 11.77487869 11.77487869 11.77487869 11.77487869 11.77487869
 11.77487869 11.77487869 11.77487869 11.77487869  5.88743935  5.88743935
 11.77487869 11.77487869 11.77487869  5.88743935  5.88743935  5.88743935
 11.77487869 11.77487869  0.        ]
original epr
4.184597371256429
index of max error on path
183
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2181, grad_fn=<MaxBackward1>)

tensor(0.1592, grad_fn=<MaxBackward1>)
random,nn steps
23
166
TOTAL REWARD
14.099011868334395
ave loss
0.45702466892975346
max_loss
0.8051784634590149
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.4260874366614877, 'num_bad_epochs': 10, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 50}
TOTALPREDICTION
tensor([3.4618], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
189
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.00032452 0.64       0.4096
 0.64       0.00000153 0.512      0.00001784 0.00154743 1.
 1.         0.8        0.512     ]
[11.76769565 11.76769565 11.76769565 11.76769565 11.76769565 11.76769565
 11.76769565 11.76769565 11.76769565 11.76769565  5.88384782  5.88384782
 11.76769565 11.76769565 11.76769565  5.88384782  5.88384782  5.88384782
 11.76769565 11.76769565  0.        ]
original epr
4.166842525296096
index of max error on path
183
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2182, grad_fn=<MaxBackward1>)

tensor(0.1593, grad_fn=<MaxBackward1>)
random,nn steps
23
166
TOTAL REWARD
14.132155158691006
ave loss
0.4653645862662603
max_loss
0.8484640121459961
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.4260874366614877, 'num_bad_epochs': 11, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 51}
TOTALPREDICTION
tensor([3.5008], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
189
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00004356 0.64       0.4096     0.8
 0.022518   0.00005445 1.         0.00000374 0.13421773 0.64
 1.         1.         0.13421773]
[11.77036639 11.77036639 11.77036639 11.77036639 11.77036639 11.77036639
 11.77036639 11.77036639 11.77036639 11.77036639  5.88518319  5.88518319
 11.77036639 11.77036639 11.77036639  5.88518319  5.88518319  5.88518319
 11.77036639 11.77036639  0.        ]
original epr
4.183101281889367
index of max error on path
183
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2182, grad_fn=<MaxBackward1>)

tensor(0.1594, grad_fn=<MaxBackward1>)
random,nn steps
22
167
TOTAL REWARD
14.31693894356444
ave loss
0.45578778854438234
max_loss
0.7694851160049438
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.4260874366614877, 'num_bad_epochs': 12, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 52}
TOTALPREDICTION
tensor([3.4521], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
183
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00003484 1.         0.512      0.32768
 0.01441152 0.04398047 0.64       0.00000153 0.32768    0.8
 0.00922337 0.32768    0.64      ]
[11.78065324 11.78065324 11.78065324 11.78065324 11.78065324 11.78065324
 11.78065324 11.78065324 11.78065324 11.78065324  5.89032662  5.89032662
 11.78065324 11.78065324 11.78065324  5.89032662  5.89032662  5.89032662
 11.78065324 11.78065324  0.        ]
original epr
4.166168786616797
index of max error on path
177
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2183, grad_fn=<MaxBackward1>)

tensor(0.1595, grad_fn=<MaxBackward1>)
random,nn steps
32
151
TOTAL REWARD
14.078645628153955
ave loss
0.47400066818370196
max_loss
0.7803370356559753
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.4260874366614877, 'num_bad_epochs': 13, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 53}
TOTALPREDICTION
tensor([3.3977], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
236
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.00922337 0.16777216 0.512
 0.16777216 0.00154743 0.8        0.00003484 0.00016615 1.
 0.00040565 0.64       0.00005445]
[11.77646046 11.77646046 11.77646046 11.77646046 11.77646046 11.77646046
 11.77646046 11.77646046 11.77646046 11.77646046  5.88823023  5.88823023
 11.77646046 11.77646046 11.77646046  5.88823023  5.88823023  5.88823023
 11.77646046 11.77646046  0.        ]
original epr
4.189909821042145
index of max error on path
159
maximum_predicted_value
0.01145915687084198
MAXIMUM LAYER WEIGHTS

tensor(0.2184, grad_fn=<MaxBackward1>)

tensor(0.1598, grad_fn=<MaxBackward1>)
random,nn steps
26
210
TOTAL REWARD
14.018723914530577
ave loss
0.3146842273960474
max_loss
0.8552924394607544
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.3146842273960474, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 54}
TOTALPREDICTION
tensor([4.1651], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
193
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.01441152 0.01441152 0.64       0.4096
 0.8        0.32768    1.         0.00002788 0.0073787  0.64
 0.00000192 0.512      0.10737418]
[11.70388971 11.70388971 11.70388971 11.70388971 11.70388971 11.70388971
 11.70388971 11.70388971 11.70388971 11.70388971  5.85194485  5.85194485
 11.70388971 11.70388971 11.70388971  5.85194485  5.85194485  5.85194485
 11.70388971 11.70388971  0.        ]
original epr
4.187004700154675
index of max error on path
188
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2185, grad_fn=<MaxBackward1>)

tensor(0.1600, grad_fn=<MaxBackward1>)
random,nn steps
25
168
TOTAL REWARD
14.168953197137578
ave loss
0.41855778394585447
max_loss
0.755923867225647
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.3146842273960474, 'num_bad_epochs': 1, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 55}
TOTALPREDICTION
tensor([3.5441], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
187
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.0000223  0.262144   0.8        0.64
 0.8        1.         0.8        0.00000192 0.512      0.512
 0.00001142 0.512      0.13421773]
[11.7709455  11.7709455  11.7709455  11.7709455  11.7709455  11.7709455
 11.7709455  11.7709455  11.7709455  11.7709455   5.88547275  5.88547275
 11.7709455  11.7709455  11.7709455   5.88547275  5.88547275  5.88547275
 11.7709455  11.7709455   0.        ]
original epr
4.183454933704032
index of max error on path
181
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2185, grad_fn=<MaxBackward1>)

tensor(0.1602, grad_fn=<MaxBackward1>)
random,nn steps
22
165
TOTAL REWARD
14.074173084449534
ave loss
0.4363627911888979
max_loss
0.7844773530960083
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.3146842273960474, 'num_bad_epochs': 2, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 56}
TOTALPREDICTION
tensor([3.4403], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
184
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.05497558 0.00063383 0.512      0.32768
 0.512      0.00000239 1.         0.00000078 1.         0.512
 1.         1.         0.512     ]
[11.76739394 11.76739394 11.76739394 11.76739394 11.76739394 11.76739394
 11.76739394 11.76739394 11.76739394 11.76739394  5.88369697  5.88369697
 11.76739394 11.76739394 11.76739394  5.88369697  5.88369697  5.88369697
 11.76739394 11.76739394  0.        ]
original epr
4.166661269244447
index of max error on path
178
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2186, grad_fn=<MaxBackward1>)

tensor(0.1602, grad_fn=<MaxBackward1>)
random,nn steps
23
161
TOTAL REWARD
14.314476250773767
ave loss
0.47431301843860874
max_loss
0.8555439710617065
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.3146842273960474, 'num_bad_epochs': 3, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 57}
TOTALPREDICTION
tensor([3.4108], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
203
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.16777216 0.64
 1.         1.         1.         0.00000078 0.00099035 0.64
 0.         0.64       0.262144  ]
[11.76435034 11.76435034 11.76435034 11.76435034 11.76435034 11.76435034
 11.76435034 11.76435034 11.76435034 11.76435034  5.88217517  5.88217517
 11.76435034 11.76435034 11.76435034  5.88217517  5.88217517  5.88217517
 11.76435034 11.76435034  0.        ]
original epr
4.176513222837347
index of max error on path
106
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2187, grad_fn=<MaxBackward1>)

tensor(0.1603, grad_fn=<MaxBackward1>)
random,nn steps
21
182
TOTAL REWARD
14.238913746810706
ave loss
0.4061783512531243
max_loss
0.8546140193939209
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.3146842273960474, 'num_bad_epochs': 4, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 58}
TOTALPREDICTION
tensor([3.7723], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
186
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00001427 0.4096     0.8        0.512
 1.         1.         0.64       0.00000123 0.512      0.64
 0.00000913 0.8        0.2097152 ]
[11.76800431 11.76800431 11.76800431 11.76800431 11.76800431 11.76800431
 11.76800431 11.76800431 11.76800431 11.76800431  5.88400216  5.88400216
 11.76800431 11.76800431 11.76800431  5.88400216  5.88400216  5.88400216
 11.76800431 11.76800431  0.        ]
original epr
4.179515698794241
index of max error on path
180
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2187, grad_fn=<MaxBackward1>)

tensor(0.1605, grad_fn=<MaxBackward1>)
random,nn steps
25
161
TOTAL REWARD
14.201561490344783
ave loss
0.439229528309517
max_loss
0.7755706906318665
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.3146842273960474, 'num_bad_epochs': 5, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 59}
TOTALPREDICTION
tensor([3.4236], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
200
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00123794 0.8        0.512      0.2097152
 0.32768    0.00063383 0.512      0.00003484 0.00377789 0.8
 0.00123794 0.8        0.03518437]
[11.78166401 11.78166401 11.78166401 11.78166401 11.78166401 11.78166401
 11.78166401 11.78166401 11.78166401 11.78166401  5.89083201  5.89083201
 11.78166401 11.78166401 11.78166401  5.89083201  5.89083201  5.89083201
 11.78166401 11.78166401  0.        ]
original epr
4.190801122925666
index of max error on path
194
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2188, grad_fn=<MaxBackward1>)

tensor(0.1607, grad_fn=<MaxBackward1>)
random,nn steps
32
168
TOTAL REWARD
13.928685520407916
ave loss
0.37467647559940814
max_loss
0.6870896816253662
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.3146842273960474, 'num_bad_epochs': 6, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 60}
TOTALPREDICTION
tensor([3.6750], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
193
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00050706 0.4096     0.64       0.64
 1.         0.00123794 0.8        0.00001784 0.01152922 0.8
 0.00040565 0.512      0.06871948]
[11.77471559 11.77471559 11.77471559 11.77471559 11.77471559 11.77471559
 11.77471559 11.77471559 11.77471559 11.77471559  5.88735779  5.88735779
 11.77471559 11.77471559 11.77471559  5.88735779  5.88735779  5.88735779
 11.77471559 11.77471559  0.        ]
original epr
4.1869669100549745
index of max error on path
188
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2189, grad_fn=<MaxBackward1>)

tensor(0.1609, grad_fn=<MaxBackward1>)
random,nn steps
31
162
TOTAL REWARD
14.020044585184323
ave loss
0.3878700323016841
max_loss
0.6823986172676086
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.3146842273960474, 'num_bad_epochs': 7, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 61}
TOTALPREDICTION
tensor([3.5616], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
187
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.00193428 0.8        0.4096
 0.2097152  0.00472237 0.512      0.00000016 0.8        0.64
 0.00050706 0.13421773 0.4096    ]
[11.77455537 11.77455537 11.77455537 11.77455537 11.77455537 11.77455537
 11.77455537 11.77455537 11.77455537 11.77455537  5.88727769  5.88727769
 11.77455537 11.77455537 11.77455537  5.88727769  5.88727769  5.88727769
 11.77455537 11.77455537  0.        ]
original epr
4.17285232482209
index of max error on path
181
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2190, grad_fn=<MaxBackward1>)

tensor(0.1610, grad_fn=<MaxBackward1>)
random,nn steps
31
156
TOTAL REWARD
13.971008358195013
ave loss
0.4352118082065633
max_loss
0.7382877469062805
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.3146842273960474, 'num_bad_epochs': 8, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 62}
TOTALPREDICTION
tensor([3.4948], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
202
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00063383 1.         0.64       0.8
 0.512      0.03518437 1.         0.00000374 0.10737418 0.8
 0.00000239 1.         0.00590296]
[11.76666202 11.76666202 11.76666202 11.76666202 11.76666202 11.76666202
 11.76666202 11.76666202 11.76666202 11.76666202  5.88333101  5.88333101
 11.76666202 11.76666202 11.76666202  5.88333101  5.88333101  5.88333101
 11.76666202 11.76666202  0.        ]
original epr
4.186630944308988
index of max error on path
196
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2190, grad_fn=<MaxBackward1>)

tensor(0.1613, grad_fn=<MaxBackward1>)
random,nn steps
16
186
TOTAL REWARD
14.317910733146407
ave loss
0.36920420594956027
max_loss
0.6602084040641785
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.3146842273960474, 'num_bad_epochs': 9, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 63}
TOTALPREDICTION
tensor([3.7019], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
202
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00193428 0.262144   0.4096     0.64
 0.64       0.00193428 0.64       0.00003484 0.00079228 0.64
 0.00050706 0.8        0.03518437]
[11.78180587 11.78180587 11.78180587 11.78180587 11.78180587 11.78180587
 11.78180587 11.78180587 11.78180587 11.78180587  5.89090293  5.89090293
 11.78180587 11.78180587 11.78180587  5.89090293  5.89090293  5.89090293
 11.78180587 11.78180587  0.        ]
original epr
4.19101526831942
index of max error on path
117
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2191, grad_fn=<MaxBackward1>)

tensor(0.1615, grad_fn=<MaxBackward1>)
random,nn steps
30
172
TOTAL REWARD
13.992218621327986
ave loss
0.3621921620082737
max_loss
0.7285976409912109
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.3146842273960474, 'num_bad_epochs': 10, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 64}
TOTALPREDICTION
tensor([3.6922], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
206
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00154743 0.512      0.8        0.64
 0.4096     0.00377789 0.13421773 0.00003484 0.00063383 0.8
 0.00079228 0.8        0.01152922]
[11.70171188 11.70171188 11.70171188 11.70171188 11.70171188 11.70171188
 11.70171188 11.70171188 11.70171188 11.70171188  5.85085594  5.85085594
 11.70171188 11.70171188 11.70171188  5.85085594  5.85085594  5.85085594
 11.70171188 11.70171188  0.        ]
original epr
4.189434910477334
index of max error on path
124
maximum_predicted_value
0.0059233419597148895
MAXIMUM LAYER WEIGHTS

tensor(0.2192, grad_fn=<MaxBackward1>)

tensor(0.1616, grad_fn=<MaxBackward1>)
random,nn steps
32
174
TOTAL REWARD
13.939960806246615
ave loss
0.35663037177952894
max_loss
0.8411992192268372
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.3146842273960474, 'num_bad_epochs': 11, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 65}
TOTALPREDICTION
tensor([3.7956], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
218
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.64       0.022518   0.512      0.64
 0.05497558 0.8        0.512      0.00004356 0.00032452 0.64
 0.08589935 0.00000731 0.00123794]
[11.78189817 11.78189817 11.78189817 11.78189817 11.78189817 11.78189817
 11.78189817 11.78189817 11.78189817 11.78189817  5.89094909  5.89094909
 11.78189817 11.78189817 11.78189817  5.89094909  5.89094909  5.89094909
 11.78189817 11.78189817  0.        ]
original epr
4.192287738145942
index of max error on path
138
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2193, grad_fn=<MaxBackward1>)

tensor(0.1618, grad_fn=<MaxBackward1>)
random,nn steps
24
194
TOTAL REWARD
14.040260973542111
ave loss
0.3596923572498314
max_loss
0.8912262916564941
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.3146842273960474, 'num_bad_epochs': 12, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 66}
TOTALPREDICTION
tensor([4.0208], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
195
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00377789 0.4096     1.         0.00922337
 0.32768    0.00377789 0.64       0.00003484 0.00154743 0.64
 0.00063383 0.8        0.64      ]
[11.77897077 11.77897077 11.77897077 11.77897077 11.77897077 11.77897077
 11.77897077 11.77897077 11.77897077 11.77897077  5.88948539  5.88948539
 11.77897077 11.77897077 11.77897077  5.88948539  5.88948539  5.88948539
 11.77897077 11.77897077  0.        ]
original epr
4.165008274110042
index of max error on path
106
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2194, grad_fn=<MaxBackward1>)

tensor(0.1620, grad_fn=<MaxBackward1>)
random,nn steps
29
166
TOTAL REWARD
13.910200797208608
ave loss
0.3888472583813545
max_loss
0.779848039150238
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.3146842273960474, 'num_bad_epochs': 13, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 67}
TOTALPREDICTION
tensor([3.5516], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
225
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.022518   0.8        0.8        0.4096
 0.00013292 0.00377789 0.512      0.00004356 0.00020769 0.512
 0.08589935 0.64       0.00040565]
[11.70648813 11.70648813 11.70648813 11.70648813 11.70648813 11.70648813
 11.70648813 11.70648813 11.70648813 11.70648813  5.85324406  5.85324406
 11.70648813 11.70648813 11.70648813  5.85324406  5.85324406  5.85324406
 11.70648813 11.70648813  0.        ]
original epr
4.1919973121448
index of max error on path
145
maximum_predicted_value
0.013577654957771301
MAXIMUM LAYER WEIGHTS

tensor(0.2194, grad_fn=<MaxBackward1>)

tensor(0.1621, grad_fn=<MaxBackward1>)
random,nn steps
32
193
TOTAL REWARD
14.21091520027952
ave loss
0.33705220558266674
max_loss
0.8730599880218506
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.3146842273960474, 'num_bad_epochs': 14, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 68}
TOTALPREDICTION
tensor([3.9112], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
196
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00013292 0.8        1.         0.512
 0.8        0.00099035 0.8        0.00000123 0.64       0.64
 0.00032452 1.         0.0180144 ]
[11.76473204 11.76473204 11.76473204 11.76473204 11.76473204 11.76473204
 11.76473204 11.76473204 11.76473204 11.76473204  5.88236602  5.88236602
 11.76473204 11.76473204 11.76473204  5.88236602  5.88236602  5.88236602
 11.76473204 11.76473204  0.        ]
original epr
4.185449963040049
index of max error on path
190
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2195, grad_fn=<MaxBackward1>)

tensor(0.1623, grad_fn=<MaxBackward1>)
random,nn steps
22
174
TOTAL REWARD
14.119787348010634
ave loss
0.37298974615274644
max_loss
0.6440425515174866
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.3146842273960474, 'num_bad_epochs': 15, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 69}
TOTALPREDICTION
tensor([3.5710], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
268
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00590296 0.512      0.512      0.00590296
 0.8        0.00377789 0.512      0.00004356 0.00016615 0.64
 0.00079228 0.8        0.00000026]
[11.78349682 11.78349682 11.78349682 11.78349682 11.78349682 11.78349682
 11.78349682 11.78349682 11.78349682 11.78349682  5.89174841  5.89174841
 11.78349682 11.78349682 11.78349682  5.89174841  5.89174841  5.89174841
 11.78349682 11.78349682  0.        ]
original epr
4.193052225090057
index of max error on path
188
maximum_predicted_value
0.08748164772987366
MAXIMUM LAYER WEIGHTS

tensor(0.2196, grad_fn=<MaxBackward1>)

tensor(0.1625, grad_fn=<MaxBackward1>)
random,nn steps
34
234
TOTAL REWARD
13.872341685836254
ave loss
0.26044457066637366
max_loss
0.8349347114562988
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.26044457066637366, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 70}
TOTALPREDICTION
tensor([2.8484], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
180
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00004356 1.         1.         0.8
 0.4096     0.00004356 1.         0.00000078 1.         0.64
 0.05497558 0.4096     0.512     ]
[11.7585259  11.7585259  11.7585259  11.7585259  11.7585259  11.7585259
 11.7585259  11.7585259  11.7585259  11.7585259   5.87926295  5.87926295
 11.7585259  11.7585259  11.7585259   5.87926295  5.87926295  5.87926295
 11.7585259  11.7585259   0.        ]
original epr
4.162435585890515
index of max error on path
174
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2196, grad_fn=<MaxBackward1>)

tensor(0.1626, grad_fn=<MaxBackward1>)
random,nn steps
21
159
TOTAL REWARD
14.226884502277699
ave loss
0.4357363525364134
max_loss
0.7298531532287598
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.26044457066637366, 'num_bad_epochs': 1, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 71}
TOTALPREDICTION
tensor([3.3205], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
202
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.01441152 1.         0.8        0.512
 0.00241785 0.00013292 0.4096     0.00003484 0.01152922 0.0180144
 0.262144   0.4096     0.04398047]
[11.78329693 11.78329693 11.78329693 11.78329693 11.78329693 11.78329693
 11.78329693 11.78329693 11.78329693 11.78329693  5.89164847  5.89164847
 11.78329693 11.78329693 11.78329693  5.89164847  5.89164847  5.89164847
 11.78329693 11.78329693  0.        ]
original epr
4.190709537348345
index of max error on path
196
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2197, grad_fn=<MaxBackward1>)

tensor(0.1626, grad_fn=<MaxBackward1>)
random,nn steps
31
171
TOTAL REWARD
14.277626343634793
ave loss
0.38509518055632563
max_loss
0.733346700668335
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.26044457066637366, 'num_bad_epochs': 2, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 72}
TOTALPREDICTION
tensor([3.6766], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
195
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00050706 0.8        1.         0.512
 0.8        0.0180144  0.512      0.00000731 0.32768    0.13421773
 0.00002788 0.32768    0.0281475 ]
[11.77757428 11.77757428 11.77757428 11.77757428 11.77757428 11.77757428
 11.77757428 11.77757428 11.77757428 11.77757428  5.88878714  5.88878714
 11.77757428 11.77757428 11.77757428  5.88878714  5.88878714  5.88878714
 11.77757428 11.77757428  0.        ]
original epr
4.189332502497208
index of max error on path
189
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2198, grad_fn=<MaxBackward1>)

tensor(0.1628, grad_fn=<MaxBackward1>)
random,nn steps
28
167
TOTAL REWARD
14.0370467129335
ave loss
0.3675896232517866
max_loss
0.6702349781990051
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.26044457066637366, 'num_bad_epochs': 3, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 73}
TOTALPREDICTION
tensor([3.5902], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
223
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00123794 0.8        0.8        0.64
 0.13421773 0.00241785 0.8        0.00004356 0.00040565 0.512
 0.00063383 1.         0.00032452]
[11.77502021 11.77502021 11.77502021 11.77502021 11.77502021 11.77502021
 11.77502021 11.77502021 11.77502021 11.77502021  5.88751011  5.88751011
 11.77502021 11.77502021 11.77502021  5.88751011  5.88751011  5.88751011
 11.77502021 11.77502021  0.        ]
original epr
4.189838148923742
index of max error on path
144
maximum_predicted_value
0.0933419018983841
MAXIMUM LAYER WEIGHTS

tensor(0.2199, grad_fn=<MaxBackward1>)

tensor(0.1630, grad_fn=<MaxBackward1>)
random,nn steps
28
195
TOTAL REWARD
13.966161907280814
ave loss
0.304277698221228
max_loss
0.8324993252754211
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.26044457066637366, 'num_bad_epochs': 4, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 74}
TOTALPREDICTION
tensor([3.0012], grad_fn=<AddBackward0>)
RESET epsilon ANNEALING
0.0625
**************************************Path Length ds<0******************************************
220
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00032452 0.8        0.8        0.64
 0.03518437 1.         0.64       0.00003484 0.16777216 0.00040565
 0.00005445 1.         0.00123794]
[11.77363443 11.77363443 11.77363443 11.77363443 11.77363443 11.77363443
 11.77363443 11.77363443 11.77363443 11.77363443  5.88681721  5.88681721
 11.77363443 11.77363443 11.77363443  5.88681721  5.88681721  5.88681721
 11.77363443 11.77363443  0.        ]
original epr
4.189465497488881
index of max error on path
142
maximum_predicted_value
0.017175991088151932
MAXIMUM LAYER WEIGHTS

tensor(0.2199, grad_fn=<MaxBackward1>)

tensor(0.1632, grad_fn=<MaxBackward1>)
random,nn steps
16
204
TOTAL REWARD
14.204321235559519
ave loss
0.32378428481222893
max_loss
0.884017288684845
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.26044457066637366, 'num_bad_epochs': 5, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 75}
TOTALPREDICTION
tensor([3.9386], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
187
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00590296 0.0180144  0.8        1.
 1.         0.00063383 0.8        0.00001427 0.01441152 1.
 0.00050706 1.         0.16777216]
[11.76101961 11.76101961 11.76101961 11.76101961 11.76101961 11.76101961
 11.76101961 11.76101961 11.76101961 11.76101961  5.88050981  5.88050981
 11.76101961 11.76101961 11.76101961  5.88050981  5.88050981  5.88050981
 11.76101961 11.76101961  0.        ]
original epr
4.176905433963792
index of max error on path
181
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2200, grad_fn=<MaxBackward1>)

tensor(0.1634, grad_fn=<MaxBackward1>)
random,nn steps
12
175
TOTAL REWARD
14.294485491836465
ave loss
0.3882806642568685
max_loss
0.6546458601951599
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.26044457066637366, 'num_bad_epochs': 6, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 76}
TOTALPREDICTION
tensor([3.4157], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
226
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.022518   0.8        0.8        0.06871948
 0.8        1.         0.00000153 0.00003484 0.2097152  0.00050706
 0.04398047 0.8        0.00079228]
[11.7779919  11.7779919  11.7779919  11.7779919  11.7779919  11.7779919
 11.7779919  11.7779919  11.7779919  11.7779919   5.88899595  5.88899595
 11.7779919  11.7779919  11.7779919   5.88899595  5.88899595  5.88899595
 11.7779919  11.7779919   0.        ]
original epr
4.191025738254061
index of max error on path
149
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2201, grad_fn=<MaxBackward1>)

tensor(0.1634, grad_fn=<MaxBackward1>)
random,nn steps
13
213
TOTAL REWARD
14.257483617778764
ave loss
0.3568016562643832
max_loss
0.9351271986961365
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.26044457066637366, 'num_bad_epochs': 7, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 77}
TOTALPREDICTION
tensor([4.1301], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
205
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.64       0.8
 1.         1.         0.00377789 0.         1.         0.4096
 0.00000016 0.8        0.05497558]
[11.75512159 11.75512159 11.75512159 11.75512159 11.75512159 11.75512159
 11.75512159 11.75512159 11.75512159 11.75512159  5.87756079  5.87756079
 11.75512159 11.75512159 11.75512159  5.87756079  5.87756079  5.87756079
 11.75512159 11.75512159  0.        ]
original epr
4.180699309973728
index of max error on path
199
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2202, grad_fn=<MaxBackward1>)

tensor(0.1636, grad_fn=<MaxBackward1>)
random,nn steps
16
189
TOTAL REWARD
14.315310645094652
ave loss
0.3593615709644992
max_loss
0.6256721615791321
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.26044457066637366, 'num_bad_epochs': 8, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 78}
TOTALPREDICTION
tensor([3.8016], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
250
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.01152922 0.64       0.8
 0.01152922 0.00020769 0.64       0.00002788 0.00020769 0.8
 0.0180144  0.64       0.00000123]
[11.69814399 11.69814399 11.69814399 11.69814399 11.69814399 11.69814399
 11.69814399 11.69814399 11.69814399 11.69814399  5.849072    5.849072
 11.69814399 11.69814399 11.69814399  5.849072    5.849072    5.849072
 11.69814399 11.69814399  0.        ]
original epr
4.188742441588468
index of max error on path
175
maximum_predicted_value
0.10392186045646667
MAXIMUM LAYER WEIGHTS

tensor(0.2202, grad_fn=<MaxBackward1>)

tensor(0.1637, grad_fn=<MaxBackward1>)
random,nn steps
18
232
TOTAL REWARD
14.179026486306835
ave loss
0.268767402857542
max_loss
0.7705698609352112
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.26044457066637366, 'num_bad_epochs': 9, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 79}
TOTALPREDICTION
tensor([2.8378], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
198
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.00050706 1.         0.8
 0.03518437 0.4096     0.8        0.00000005 1.         1.
 0.00001142 0.8        0.0281475 ]
[11.75248455 11.75248455 11.75248455 11.75248455 11.75248455 11.75248455
 11.75248455 11.75248455 11.75248455 11.75248455  5.87624227  5.87624227
 11.75248455 11.75248455 11.75248455  5.87624227  5.87624227  5.87624227
 11.75248455 11.75248455  0.        ]
original epr
4.1791712319034096
index of max error on path
192
maximum_predicted_value
0.025948531925678253
MAXIMUM LAYER WEIGHTS

tensor(0.2203, grad_fn=<MaxBackward1>)

tensor(0.1639, grad_fn=<MaxBackward1>)
random,nn steps
11
187
TOTAL REWARD
14.176848474573356
ave loss
0.35134271165412484
max_loss
0.597946286201477
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.26044457066637366, 'num_bad_epochs': 10, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 80}
TOTALPREDICTION
tensor([3.6305], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
198
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.00079228 1.         1.
 1.         0.00099035 1.         0.00000008 0.64       0.8
 0.00010634 0.64       0.0281475 ]
[11.7533071  11.7533071  11.7533071  11.7533071  11.7533071  11.7533071
 11.7533071  11.7533071  11.7533071  11.7533071   5.87665355  5.87665355
 11.7533071  11.7533071  11.7533071   5.87665355  5.87665355  5.87665355
 11.7533071  11.7533071   0.        ]
original epr
4.180133053185519
index of max error on path
192
maximum_predicted_value
0.028700120747089386
MAXIMUM LAYER WEIGHTS

tensor(0.2204, grad_fn=<MaxBackward1>)

tensor(0.1642, grad_fn=<MaxBackward1>)
random,nn steps
15
183
TOTAL REWARD
14.242502909604815
ave loss
0.341646459047692
max_loss
0.5613164901733398
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.26044457066637366, 'num_bad_epochs': 11, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 81}
TOTALPREDICTION
tensor([3.6364], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
249
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00193428 0.8        0.8        1.
 1.         0.00472237 0.64       0.00004356 0.16777216 0.00050706
 0.00005445 0.8        0.00000123]
[11.76991145 11.76991145 11.76991145 11.76991145 11.76991145 11.76991145
 11.76991145 11.76991145 11.76991145 11.76991145  5.88495573  5.88495573
 11.76991145 11.76991145 11.76991145  5.88495573  5.88495573  5.88495573
 11.76991145 11.76991145  0.        ]
original epr
4.187614165724197
index of max error on path
174
maximum_predicted_value
0.06464694440364838
MAXIMUM LAYER WEIGHTS

tensor(0.2205, grad_fn=<MaxBackward1>)

tensor(0.1643, grad_fn=<MaxBackward1>)
random,nn steps
15
234
TOTAL REWARD
14.2156319799996
ave loss
0.269635588476756
max_loss
0.8268209099769592
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.26044457066637366, 'num_bad_epochs': 12, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 82}
TOTALPREDICTION
tensor([3.0638], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
238
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.0073787  0.512      1.
 0.16777216 0.01152922 1.         0.00003484 0.00032452 0.512
 0.00001784 0.8        0.00001427]
[11.77134018 11.77134018 11.77134018 11.77134018 11.77134018 11.77134018
 11.77134018 11.77134018 11.77134018 11.77134018  5.88567009  5.88567009
 11.77134018 11.77134018 11.77134018  5.88567009  5.88567009  5.88567009
 11.77134018 11.77134018  0.        ]
original epr
4.188215951365539
index of max error on path
159
maximum_predicted_value
0.12262550741434097
MAXIMUM LAYER WEIGHTS

tensor(0.2205, grad_fn=<MaxBackward1>)

tensor(0.1645, grad_fn=<MaxBackward1>)
random,nn steps
19
219
TOTAL REWARD
14.050941942065373
ave loss
0.26863072873601895
max_loss
0.8169698715209961
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.26044457066637366, 'num_bad_epochs': 13, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 83}
TOTALPREDICTION
tensor([2.7671], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
187
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00000731 0.8        1.         0.64
 0.8        1.         0.8        0.0000005  1.         0.8
 0.00000731 0.8        0.13421773]
[11.75253797 11.75253797 11.75253797 11.75253797 11.75253797 11.75253797
 11.75253797 11.75253797 11.75253797 11.75253797  5.87626899  5.87626899
 11.75253797 11.75253797 11.75253797  5.87626899  5.87626899  5.87626899
 11.75253797 11.75253797  0.        ]
original epr
4.17598003562002
index of max error on path
181
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2206, grad_fn=<MaxBackward1>)

tensor(0.1647, grad_fn=<MaxBackward1>)
random,nn steps
13
174
TOTAL REWARD
14.253430321969738
ave loss
0.37344111964345617
max_loss
0.6368772983551025
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.26044457066637366, 'num_bad_epochs': 14, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 84}
TOTALPREDICTION
tensor([3.4165], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
276
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.262144   0.64
 1.         0.00004356 1.         0.00001427 0.00016615 0.8
 0.00001427 1.         0.00000001]
[11.76379041 11.76379041 11.76379041 11.76379041 11.76379041 11.76379041
 11.76379041 11.76379041 11.76379041 11.76379041  5.8818952   5.8818952
 11.76379041 11.76379041 11.76379041  5.8818952   5.8818952   5.8818952
 11.76379041 11.76379041 -0.        ]
original epr
4.186412641834669
index of max error on path
202
maximum_predicted_value
0.155997633934021
MAXIMUM LAYER WEIGHTS

tensor(0.2206, grad_fn=<MaxBackward1>)

tensor(0.1648, grad_fn=<MaxBackward1>)
random,nn steps
8
268
TOTAL REWARD
14.19972856554314
ave loss
0.23277531593930031
max_loss
0.7227627635002136
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.23277531593930031, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 85}
TOTALPREDICTION
tensor([2.0225], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
197
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.00302231 0.8        0.64
 0.64       0.05497558 1.         0.00000021 0.64       0.64
 0.00000063 0.8        0.03518437]
[11.7659957  11.7659957  11.7659957  11.7659957  11.7659957  11.7659957
 11.7659957  11.7659957  11.7659957  11.7659957   5.88299785  5.88299785
 11.7659957  11.7659957  11.7659957   5.88299785  5.88299785  5.88299785
 11.7659957  11.7659957   0.        ]
original epr
4.185513049371797
index of max error on path
191
maximum_predicted_value
0.04407171532511711
MAXIMUM LAYER WEIGHTS

tensor(0.2207, grad_fn=<MaxBackward1>)

tensor(0.1651, grad_fn=<MaxBackward1>)
random,nn steps
15
182
TOTAL REWARD
14.059195493640578
ave loss
0.3366120035575731
max_loss
0.559689998626709
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.23277531593930031, 'num_bad_epochs': 1, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 86}
TOTALPREDICTION
tensor([3.6254], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
277
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.04398047 1.         0.64       1.
 0.64       0.00241785 0.64       0.00004356 0.00013292 1.
 0.00000468 0.8        0.        ]
[11.68835028 11.68835028 11.68835028 11.68835028 11.68835028 11.68835028
 11.68835028 11.68835028 11.68835028 11.68835028  5.84417514  5.84417514
 11.68835028 11.68835028 11.68835028  5.84417514  5.84417514  5.84417514
 11.68835028 11.68835028 -0.        ]
original epr
4.184747091852666
index of max error on path
199
maximum_predicted_value
0.1412569135427475
MAXIMUM LAYER WEIGHTS

tensor(0.2208, grad_fn=<MaxBackward1>)

tensor(0.1652, grad_fn=<MaxBackward1>)
random,nn steps
9
268
TOTAL REWARD
14.179657218884588
ave loss
0.23349424572627897
max_loss
0.8089259266853333
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.23277531593930031, 'num_bad_epochs': 2, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 87}
TOTALPREDICTION
tensor([1.9435], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
201
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00154743 0.01441152 0.64       0.03518437
 0.0073787  0.00123794 0.8        0.00000063 1.         0.8
 1.         0.64       0.0281475 ]
[11.76934226 11.76934226 11.76934226 11.76934226 11.76934226 11.76934226
 11.76934226 11.76934226 11.76934226 11.76934226  5.88467113  5.88467113
 11.76934226 11.76934226 11.76934226  5.88467113  5.88467113  5.88467113
 11.76934226 11.76934226  0.        ]
original epr
4.185995669656918
index of max error on path
195
maximum_predicted_value
0.011668248102068901
MAXIMUM LAYER WEIGHTS

tensor(0.2208, grad_fn=<MaxBackward1>)

tensor(0.1654, grad_fn=<MaxBackward1>)
random,nn steps
19
182
TOTAL REWARD
14.16065581518076
ave loss
0.33881971403140926
max_loss
0.6216453909873962
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.23277531593930031, 'num_bad_epochs': 3, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 88}
TOTALPREDICTION
tensor([3.6684], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
202
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         0.13421773
 1.         1.         0.00590296 0.0000004  0.00922337 1.
 0.00000011 0.8        0.10737418]
[11.75723735 11.75723735 11.75723735 11.75723735 11.75723735 11.75723735
 11.75723735 11.75723735 11.75723735 11.75723735  5.87861867  5.87861867
 11.75723735 11.75723735 11.75723735  5.87861867  5.87861867  5.87861867
 11.75723735 11.75723735  0.        ]
original epr
4.178746004363787
index of max error on path
196
maximum_predicted_value
0.0728558748960495
MAXIMUM LAYER WEIGHTS

tensor(0.2209, grad_fn=<MaxBackward1>)

tensor(0.1656, grad_fn=<MaxBackward1>)
random,nn steps
9
193
TOTAL REWARD
14.330891222620304
ave loss
0.32611570415077823
max_loss
0.5510464906692505
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.23277531593930031, 'num_bad_epochs': 4, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 89}
TOTALPREDICTION
tensor([3.7193], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
264
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00922337 1.         0.262144   0.8
 1.         0.00032452 1.         0.00003484 0.00020769 0.8
 0.00013292 0.8        0.00000007]
[11.76822441 11.76822441 11.76822441 11.76822441 11.76822441 11.76822441
 11.76822441 11.76822441 11.76822441 11.76822441  5.88411221  5.88411221
 11.76822441 11.76822441 11.76822441  5.88411221  5.88411221  5.88411221
 11.76822441 11.76822441  0.        ]
original epr
4.18749738883459
index of max error on path
185
maximum_predicted_value
0.17267684638500214
MAXIMUM LAYER WEIGHTS

tensor(0.2210, grad_fn=<MaxBackward1>)

tensor(0.1657, grad_fn=<MaxBackward1>)
random,nn steps
12
252
TOTAL REWARD
14.116745002692412
ave loss
0.2337062680127212
max_loss
0.7884164452552795
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.23277531593930031, 'num_bad_epochs': 5, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 90}
TOTALPREDICTION
tensor([2.1564], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
206
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.00241785 0.8        0.8
 0.64       0.01441152 0.8        0.00000374 0.01441152 0.8
 0.00000374 1.         0.00590296]
[11.76563056 11.76563056 11.76563056 11.76563056 11.76563056 11.76563056
 11.76563056 11.76563056 11.76563056 11.76563056  5.88281528  5.88281528
 11.76563056 11.76563056 11.76563056  5.88281528  5.88281528  5.88281528
 11.76563056 11.76563056  0.        ]
original epr
4.186105192982206
index of max error on path
81
maximum_predicted_value
0.11980375647544861
MAXIMUM LAYER WEIGHTS

tensor(0.2210, grad_fn=<MaxBackward1>)

tensor(0.1659, grad_fn=<MaxBackward1>)
random,nn steps
10
196
TOTAL REWARD
14.058991884787922
ave loss
0.2924989991260747
max_loss
0.5474089980125427
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.23277531593930031, 'num_bad_epochs': 6, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 91}
TOTALPREDICTION
tensor([3.4883], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
202
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.0180144  1.         0.8
 1.         0.8        0.00010634 0.00000007 1.         1.
 0.00003484 1.         0.00922337]
[11.82296036 11.82296036 11.82296036 11.82296036 11.82296036 11.82296036
 11.82296036 11.82296036 11.82296036 11.82296036  5.91148018  5.91148018
 11.82296036 11.82296036 11.82296036  5.91148018  5.91148018  5.91148018
 11.82296036 11.82296036  0.        ]
original epr
4.178483174398618
index of max error on path
77
maximum_predicted_value
0.04327194392681122
MAXIMUM LAYER WEIGHTS

tensor(0.2211, grad_fn=<MaxBackward1>)

tensor(0.1661, grad_fn=<MaxBackward1>)
random,nn steps
8
194
TOTAL REWARD
14.120449736052798
ave loss
0.33051037382666426
max_loss
0.6359660625457764
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.23277531593930031, 'num_bad_epochs': 7, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 92}
TOTALPREDICTION
tensor([3.6244], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
229
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.8        0.512
 0.32768    0.01441152 0.00302231 0.00000731 0.00016615 1.
 0.00004356 0.8        0.00025961]
[11.76737911 11.76737911 11.76737911 11.76737911 11.76737911 11.76737911
 11.76737911 11.76737911 11.76737911 11.76737911  5.88368955  5.88368955
 11.76737911 11.76737911 11.76737911  5.88368955  5.88368955  5.88368955
 11.76737911 11.76737911  0.        ]
original epr
4.186642685541383
index of max error on path
147
maximum_predicted_value
0.12227150797843933
MAXIMUM LAYER WEIGHTS

tensor(0.2212, grad_fn=<MaxBackward1>)

tensor(0.1662, grad_fn=<MaxBackward1>)
random,nn steps
10
219
TOTAL REWARD
14.075906797110317
ave loss
0.2703074735943147
max_loss
0.8112745881080627
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.23277531593930031, 'num_bad_epochs': 8, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 93}
TOTALPREDICTION
tensor([3.0743], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
264
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.01441152 0.04398047 1.
 0.8        0.00079228 0.8        0.00004356 0.00016615 1.
 0.00008507 1.         0.00000013]
[11.76400532 11.76400532 11.76400532 11.76400532 11.76400532 11.76400532
 11.76400532 11.76400532 11.76400532 11.76400532  5.88200266  5.88200266
 11.76400532 11.76400532 11.76400532  5.88200266  5.88200266  5.88200266
 11.76400532 11.76400532  0.        ]
original epr
4.185095526710206
index of max error on path
186
maximum_predicted_value
0.1831698715686798
MAXIMUM LAYER WEIGHTS

tensor(0.2212, grad_fn=<MaxBackward1>)

tensor(0.1664, grad_fn=<MaxBackward1>)
random,nn steps
9
255
TOTAL REWARD
14.083695727836764
ave loss
0.2361770524276477
max_loss
0.7842627167701721
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.23277531593930031, 'num_bad_epochs': 9, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 94}
TOTALPREDICTION
tensor([2.0087], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
204
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00079228 0.8        0.4096     0.64
 0.8        0.022518   0.8        0.00000098 0.4096     1.
 0.00000468 0.8        0.00472237]
[11.76969673 11.76969673 11.76969673 11.76969673 11.76969673 11.76969673
 11.76969673 11.76969673 11.76969673 11.76969673  5.88484836  5.88484836
 11.76969673 11.76969673 11.76969673  5.88484836  5.88484836  5.88484836
 11.76969673 11.76969673  0.        ]
original epr
4.18782268545828
index of max error on path
87
maximum_predicted_value
0.11939340829849243
MAXIMUM LAYER WEIGHTS

tensor(0.2213, grad_fn=<MaxBackward1>)

tensor(0.1666, grad_fn=<MaxBackward1>)
random,nn steps
13
191
TOTAL REWARD
14.034166978698133
ave loss
0.28767720210895525
max_loss
0.486167848110199
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.23277531593930031, 'num_bad_epochs': 10, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 95}
TOTALPREDICTION
tensor([3.4118], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
279
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00154743 0.64       1.         0.4096
 0.13421773 0.00241785 1.         0.00004356 0.00020769 0.8
 0.00063383 1.         0.        ]
[11.76984751 11.76984751 11.76984751 11.76984751 11.76984751 11.76984751
 11.76984751 11.76984751 11.76984751 11.76984751  5.88492376  5.88492376
 11.76984751 11.76984751 11.76984751  5.88492376  5.88492376  5.88492376
 11.76984751 11.76984751 -0.        ]
original epr
4.187397712807539
index of max error on path
200
maximum_predicted_value
0.1942896693944931
MAXIMUM LAYER WEIGHTS

tensor(0.2213, grad_fn=<MaxBackward1>)

tensor(0.1667, grad_fn=<MaxBackward1>)
random,nn steps
12
267
TOTAL REWARD
14.180000132191198
ave loss
0.22502000778779974
max_loss
0.7850780487060547
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.22502000778779974, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 96}
TOTALPREDICTION
tensor([1.7183], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
218
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00472237 0.8        0.8        1.
 1.         0.00003484 0.8        0.00004356 0.13421773 0.00040565
 0.00472237 0.512      0.00154743]
[11.77072938 11.77072938 11.77072938 11.77072938 11.77072938 11.77072938
 11.77072938 11.77072938 11.77072938 11.77072938  5.88536469  5.88536469
 11.77072938 11.77072938 11.77072938  5.88536469  5.88536469  5.88536469
 11.77072938 11.77072938  0.        ]
original epr
4.187772310832656
index of max error on path
140
maximum_predicted_value
0.12009724229574203
MAXIMUM LAYER WEIGHTS

tensor(0.2214, grad_fn=<MaxBackward1>)

tensor(0.1669, grad_fn=<MaxBackward1>)
random,nn steps
18
200
TOTAL REWARD
14.153821600835748
ave loss
0.2842811161754738
max_loss
0.8462743759155273
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.22502000778779974, 'num_bad_epochs': 1, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 97}
TOTALPREDICTION
tensor([2.9651], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
205
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.32768    1.         0.64
 0.64       0.         1.         0.00000063 0.00922337 0.8
 1.         0.64       0.022518  ]
[11.76021965 11.76021965 11.76021965 11.76021965 11.76021965 11.76021965
 11.76021965 11.76021965 11.76021965 11.76021965  5.88010982  5.88010982
 11.76021965 11.76021965 11.76021965  5.88010982  5.88010982  5.88010982
 11.76021965 11.76021965  0.        ]
original epr
4.183701469062522
index of max error on path
200
maximum_predicted_value
0.08481873571872711
MAXIMUM LAYER WEIGHTS

tensor(0.2215, grad_fn=<MaxBackward1>)

tensor(0.1670, grad_fn=<MaxBackward1>)
random,nn steps
16
189
TOTAL REWARD
14.133333234613158
ave loss
0.3026799862704626
max_loss
0.641911506652832
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.22502000778779974, 'num_bad_epochs': 2, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 98}
TOTALPREDICTION
tensor([3.7437], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
187
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00377789 1.         0.64       1.
 1.         1.         1.         0.00000063 0.8        1.
 0.08589935 0.00000007 0.10737418]
[11.82665405 11.82665405 11.82665405 11.82665405 11.82665405 11.82665405
 11.82665405 11.82665405 11.82665405 11.82665405  5.91332703  5.91332703
 11.82665405 11.82665405 11.82665405  5.91332703  5.91332703  5.91332703
 11.82665405 11.82665405  0.        ]
original epr
4.176457345343197
index of max error on path
65
maximum_predicted_value
0.035137929022312164
MAXIMUM LAYER WEIGHTS

tensor(0.2215, grad_fn=<MaxBackward1>)

tensor(0.1672, grad_fn=<MaxBackward1>)
random,nn steps
11
176
TOTAL REWARD
14.209077128298892
ave loss
0.3606534513998478
max_loss
0.6248748302459717
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.22502000778779974, 'num_bad_epochs': 3, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 99}
TOTALPREDICTION
tensor([3.4462], grad_fn=<AddBackward0>)
RESET epsilon ANNEALING
0.03125
**************************************Path Length ds<0******************************************
249
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00040565 1.         0.64       1.
 1.         0.00050706 1.         0.00004356 0.10737418 0.00099035
 1.         0.00099035 0.00000123]
[11.76590802 11.76590802 11.76590802 11.76590802 11.76590802 11.76590802
 11.76590802 11.76590802 11.76590802 11.76590802  5.88295401  5.88295401
 11.76590802 11.76590802 11.76590802  5.88295401  5.88295401  5.88295401
 11.76590802 11.76590802  0.        ]
original epr
4.186368856213971
index of max error on path
171
maximum_predicted_value
0.07318571954965591
MAXIMUM LAYER WEIGHTS

tensor(0.2216, grad_fn=<MaxBackward1>)

tensor(0.1673, grad_fn=<MaxBackward1>)
random,nn steps
9
240
TOTAL REWARD
14.259710298402434
ave loss
0.261837644330469
max_loss
0.8412846922874451
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.22502000778779974, 'num_bad_epochs': 4, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 100}
TOTALPREDICTION
tensor([2.8417], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
370
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.00000013 1.
 1.         0.00922337 0.01152922 0.00004356 0.00016615 0.8
 0.00377789 1.         0.        ]
[11.7638528 11.7638528 11.7638528 11.7638528 11.7638528 11.7638528
 11.7638528 11.7638528 11.7638528 11.7638528  5.8819264  5.8819264
 11.7638528 11.7638528 11.7638528  5.8819264  5.8819264  5.8819264
 11.7638528 11.7638528  0.       ]
original epr
4.185426982743419
index of max error on path
292
maximum_predicted_value
0.16335028409957886
MAXIMUM LAYER WEIGHTS

tensor(0.2216, grad_fn=<MaxBackward1>)

tensor(0.1674, grad_fn=<MaxBackward1>)
random,nn steps
9
361
TOTAL REWARD
14.2628950755122
ave loss
0.18588270411600133
max_loss
0.8000974059104919
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18588270411600133, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 101}
TOTALPREDICTION
tensor([1.3165], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
240
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.8        0.8
 1.         0.00123794 1.         0.00000585 0.00013292 1.
 0.0000004  1.         0.0000223 ]
[11.75284691 11.75284691 11.75284691 11.75284691 11.75284691 11.75284691
 11.75284691 11.75284691 11.75284691 11.75284691  5.87642345  5.87642345
 11.75284691 11.75284691 11.75284691  5.87642345  5.87642345  5.87642345
 11.75284691 11.75284691  0.        ]
original epr
4.181755681713001
index of max error on path
157
maximum_predicted_value
0.18921063840389252
MAXIMUM LAYER WEIGHTS

tensor(0.2217, grad_fn=<MaxBackward1>)

tensor(0.1675, grad_fn=<MaxBackward1>)
random,nn steps
6
234
TOTAL REWARD
14.348058865933073
ave loss
0.24301556088030338
max_loss
0.7798271179199219
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18588270411600133, 'num_bad_epochs': 1, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 102}
TOTALPREDICTION
tensor([2.5219], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
251
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00154743 1.         0.512      0.8
 0.8        0.00472237 1.         0.00004356 0.00016615 1.
 0.00003484 1.         0.00000078]
[11.7630438 11.7630438 11.7630438 11.7630438 11.7630438 11.7630438
 11.7630438 11.7630438 11.7630438 11.7630438  5.8815219  5.8815219
 11.7630438 11.7630438 11.7630438  5.8815219  5.8815219  5.8815219
 11.7630438 11.7630438  0.       ]
original epr
4.185297294100474
index of max error on path
173
maximum_predicted_value
0.22060371935367584
MAXIMUM LAYER WEIGHTS

tensor(0.2217, grad_fn=<MaxBackward1>)

tensor(0.1677, grad_fn=<MaxBackward1>)
random,nn steps
8
243
TOTAL REWARD
14.337630408169634
ave loss
0.2362740514688639
max_loss
0.773247241973877
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18588270411600133, 'num_bad_epochs': 2, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 103}
TOTALPREDICTION
tensor([1.9607], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
315
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.512      1.
 1.         0.00004356 0.8        0.00000585 0.00013292 0.8
 0.00001784 1.         0.        ]
[11.75817477 11.75817477 11.75817477 11.75817477 11.75817477 11.75817477
 11.75817477 11.75817477 11.75817477 11.75817477  5.87908739  5.87908739
 11.75817477 11.75817477 11.75817477  5.87908739  5.87908739  5.87908739
 11.75817477 11.75817477  0.        ]
original epr
4.1838858072558365
index of max error on path
235
maximum_predicted_value
0.21683059632778168
MAXIMUM LAYER WEIGHTS

tensor(0.2217, grad_fn=<MaxBackward1>)

tensor(0.1677, grad_fn=<MaxBackward1>)
random,nn steps
10
305
TOTAL REWARD
14.170981060040177
ave loss
0.20610748328978107
max_loss
0.7411880493164062
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18588270411600133, 'num_bad_epochs': 3, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 104}
TOTALPREDICTION
tensor([1.0521], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
235
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00922337 0.00000374 1.         1.
 1.         1.         1.         0.00004356 0.00016615 1.
 0.00377789 1.         0.00001784]
[11.75109202 11.75109202 11.75109202 11.75109202 11.75109202 11.75109202
 11.75109202 11.75109202 11.75109202 11.75109202  5.87554601  5.87554601
 11.75109202 11.75109202 11.75109202  5.87554601  5.87554601  5.87554601
 11.75109202 11.75109202  0.        ]
original epr
4.180018943565719
index of max error on path
160
maximum_predicted_value
0.14624115824699402
MAXIMUM LAYER WEIGHTS

tensor(0.2218, grad_fn=<MaxBackward1>)

tensor(0.1679, grad_fn=<MaxBackward1>)
random,nn steps
6
229
TOTAL REWARD
14.422863932209292
ave loss
0.2658544641780726
max_loss
0.7824532985687256
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18588270411600133, 'num_bad_epochs': 4, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 105}
TOTALPREDICTION
tensor([2.5049], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
302
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00000299 1.         0.8        1.
 0.8        0.01441152 1.         0.00003484 0.00020769 0.8
 0.00472237 1.         0.        ]
[11.7594632 11.7594632 11.7594632 11.7594632 11.7594632 11.7594632
 11.7594632 11.7594632 11.7594632 11.7594632  5.8797316  5.8797316
 11.7594632 11.7594632 11.7594632  5.8797316  5.8797316  5.8797316
 11.7594632 11.7594632  0.       ]
original epr
4.183789718150793
index of max error on path
223
maximum_predicted_value
0.19581779837608337
MAXIMUM LAYER WEIGHTS

tensor(0.2218, grad_fn=<MaxBackward1>)

tensor(0.1680, grad_fn=<MaxBackward1>)
random,nn steps
14
288
TOTAL REWARD
14.357137172089212
ave loss
0.2140853473645271
max_loss
0.7857657670974731
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18588270411600133, 'num_bad_epochs': 5, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 106}
TOTALPREDICTION
tensor([1.0677], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
295
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00302231 0.8        1.         1.
 1.         0.03518437 1.         0.00003484 0.00016615 0.8
 0.00000192 1.         0.        ]
[11.75614586 11.75614586 11.75614586 11.75614586 11.75614586 11.75614586
 11.75614586 11.75614586 11.75614586 11.75614586  5.87807293  5.87807293
 11.75614586 11.75614586 11.75614586  5.87807293  5.87807293  5.87807293
 11.75614586 11.75614586  0.        ]
original epr
4.182216458373127
index of max error on path
214
maximum_predicted_value
0.20923198759555817
MAXIMUM LAYER WEIGHTS

tensor(0.2218, grad_fn=<MaxBackward1>)

tensor(0.1680, grad_fn=<MaxBackward1>)
random,nn steps
11
284
TOTAL REWARD
14.372411416096377
ave loss
0.21394751518333363
max_loss
0.7727842926979065
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18588270411600133, 'num_bad_epochs': 6, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 107}
TOTALPREDICTION
tensor([1.2367], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
405
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.512      0.8
 0.8        0.00020769 0.8        0.00000731 0.00016615 1.
 0.00000374 1.         0.        ]
[11.75991638 11.75991638 11.75991638 11.75991638 11.75991638 11.75991638
 11.75991638 11.75991638 11.75991638 11.75991638  5.87995819  5.87995819
 11.75991638 11.75991638 11.75991638  5.87995819  5.87995819  5.87995819
 11.75991638 11.75991638  0.        ]
original epr
4.184506295251232
index of max error on path
323
maximum_predicted_value
0.21914184093475342
MAXIMUM LAYER WEIGHTS

tensor(0.2218, grad_fn=<MaxBackward1>)

tensor(0.1680, grad_fn=<MaxBackward1>)
random,nn steps
7
398
TOTAL REWARD
14.179264019224407
ave loss
0.18028995151413077
max_loss
0.7740867137908936
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18028995151413077, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 108}
TOTALPREDICTION
tensor([0.6982], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
252
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         0.00241785 0.8        0.00000913 0.16777216 0.00032452
 0.00000032 0.8        0.00000153]
[11.75888071 11.75888071 11.75888071 11.75888071 11.75888071 11.75888071
 11.75888071 11.75888071 11.75888071 11.75888071  5.87944035  5.87944035
 11.75888071 11.75888071 11.75888071  5.87944035  5.87944035  5.87944035
 11.75888071 11.75888071  0.        ]
original epr
4.183651511523
index of max error on path
172
maximum_predicted_value
0.13216166198253632
MAXIMUM LAYER WEIGHTS

tensor(0.2218, grad_fn=<MaxBackward1>)

tensor(0.1681, grad_fn=<MaxBackward1>)
random,nn steps
10
242
TOTAL REWARD
14.228834983375743
ave loss
0.24106689277918092
max_loss
0.8305822610855103
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18028995151413077, 'num_bad_epochs': 1, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 109}
TOTALPREDICTION
tensor([2.2735], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
199
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.00590296 1.         0.8
 0.8        0.00020769 1.         0.00000007 0.8        1.
 0.00006806 0.8        0.022518  ]
[11.75175394 11.75175394 11.75175394 11.75175394 11.75175394 11.75175394
 11.75175394 11.75175394 11.75175394 11.75175394  5.87587697  5.87587697
 11.75175394 11.75175394 11.75175394  5.87587697  5.87587697  5.87587697
 11.75175394 11.75175394  0.        ]
original epr
4.179674710627324
index of max error on path
193
maximum_predicted_value
0.1535327285528183
MAXIMUM LAYER WEIGHTS

tensor(0.2219, grad_fn=<MaxBackward1>)

tensor(0.1683, grad_fn=<MaxBackward1>)
random,nn steps
12
187
TOTAL REWARD
14.168952643177336
ave loss
0.28115917842404625
max_loss
0.45103225111961365
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18028995151413077, 'num_bad_epochs': 2, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 110}
TOTALPREDICTION
tensor([3.3867], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
212
Final STATE
[1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.64      1.        1.        1.
 1.        0.        1.        1.        0.        1.        0.0281475]
[11.8136707  11.8136707  11.8136707  11.8136707  11.8136707  11.8136707
 11.8136707  11.8136707  11.8136707  11.8136707   5.90683535  5.90683535
 11.8136707  11.8136707  11.8136707   5.90683535  5.90683535  5.90683535
 11.8136707  11.8136707   0.        ]
original epr
4.175271602672568
index of max error on path
17
maximum_predicted_value
0.14102450013160706
MAXIMUM LAYER WEIGHTS

tensor(0.2220, grad_fn=<MaxBackward1>)

tensor(0.1686, grad_fn=<MaxBackward1>)
random,nn steps
4
208
TOTAL REWARD
14.518911972897202
ave loss
0.2771055490252966
max_loss
0.4399035573005676
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18028995151413077, 'num_bad_epochs': 3, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 111}
TOTALPREDICTION
tensor([3.5983], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
340
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.00590296 0.8        1.
 1.         0.01441152 1.         0.00003484 0.00020769 0.8
 0.00922337 0.00020769 0.        ]
[11.76259057 11.76259057 11.76259057 11.76259057 11.76259057 11.76259057
 11.76259057 11.76259057 11.76259057 11.76259057  5.88129529  5.88129529
 11.76259057 11.76259057 11.76259057  5.88129529  5.88129529  5.88129529
 11.76259057 11.76259057  0.        ]
original epr
4.184580927839589
index of max error on path
264
maximum_predicted_value
0.18866735696792603
MAXIMUM LAYER WEIGHTS

tensor(0.2220, grad_fn=<MaxBackward1>)

tensor(0.1685, grad_fn=<MaxBackward1>)
random,nn steps
7
333
TOTAL REWARD
14.24859376714974
ave loss
0.20576975506127756
max_loss
0.785057783126831
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18028995151413077, 'num_bad_epochs': 4, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 112}
TOTALPREDICTION
tensor([0.2931], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
208
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.00010634 0.8        0.512
 1.         1.         1.         0.00000913 0.00472237 1.
 0.00000078 1.         0.00472237]
[11.75643219 11.75643219 11.75643219 11.75643219 11.75643219 11.75643219
 11.75643219 11.75643219 11.75643219 11.75643219  5.87821609  5.87821609
 11.75643219 11.75643219 11.75643219  5.87821609  5.87821609  5.87821609
 11.75643219 11.75643219  0.        ]
original epr
4.183075912833879
index of max error on path
114
maximum_predicted_value
0.19538161158561707
MAXIMUM LAYER WEIGHTS

tensor(0.2221, grad_fn=<MaxBackward1>)

tensor(0.1688, grad_fn=<MaxBackward1>)
random,nn steps
4
204
TOTAL REWARD
14.266611619960255
ave loss
0.2651137728960468
max_loss
0.5659056901931763
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18028995151413077, 'num_bad_epochs': 5, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 113}
TOTALPREDICTION
tensor([3.1150], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
288
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00099035 0.64       0.512      0.64
 1.         0.00099035 1.         0.00004356 0.00016615 0.8
 0.00040565 1.         0.        ]
[11.76963578 11.76963578 11.76963578 11.76963578 11.76963578 11.76963578
 11.76963578 11.76963578 11.76963578 11.76963578  5.88481789  5.88481789
 11.76963578 11.76963578 11.76963578  5.88481789  5.88481789  5.88481789
 11.76963578 11.76963578  0.        ]
original epr
4.1881749649886935
index of max error on path
209
maximum_predicted_value
0.2535358965396881
MAXIMUM LAYER WEIGHTS

tensor(0.2221, grad_fn=<MaxBackward1>)

tensor(0.1689, grad_fn=<MaxBackward1>)
random,nn steps
11
277
TOTAL REWARD
14.150488813698898
ave loss
0.21054965884347135
max_loss
0.758363664150238
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18028995151413077, 'num_bad_epochs': 6, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 114}
TOTALPREDICTION
tensor([1.0398], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
196
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00020769 0.512      1.         1.
 1.         0.00193428 1.         0.0000005  1.         1.
 0.00010634 0.8        0.01152922]
[11.82323173 11.82323173 11.82323173 11.82323173 11.82323173 11.82323173
 11.82323173 11.82323173 11.82323173 11.82323173  5.91161587  5.91161587
 11.82323173 11.82323173 11.82323173  5.91161587  5.91161587  5.91161587
 11.82323173 11.82323173  0.        ]
original epr
4.178002029365015
index of max error on path
77
maximum_predicted_value
0.17384381592273712
MAXIMUM LAYER WEIGHTS

tensor(0.2222, grad_fn=<MaxBackward1>)

tensor(0.1691, grad_fn=<MaxBackward1>)
random,nn steps
9
187
TOTAL REWARD
14.264141665475567
ave loss
0.28179590734748206
max_loss
0.5996643900871277
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18028995151413077, 'num_bad_epochs': 7, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 115}
TOTALPREDICTION
tensor([3.0355], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
268
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.05497558 1.         0.022518
 0.03518437 0.00013292 1.         0.00003484 0.00016615 1.
 0.00590296 0.64       0.00000008]
[11.76824265 11.76824265 11.76824265 11.76824265 11.76824265 11.76824265
 11.76824265 11.76824265 11.76824265 11.76824265  5.88412132  5.88412132
 11.76824265 11.76824265 11.76824265  5.88412132  5.88412132  5.88412132
 11.76824265 11.76824265  0.        ]
original epr
4.186246624356166
index of max error on path
190
maximum_predicted_value
0.21706777811050415
MAXIMUM LAYER WEIGHTS

tensor(0.2222, grad_fn=<MaxBackward1>)

tensor(0.1692, grad_fn=<MaxBackward1>)
random,nn steps
11
257
TOTAL REWARD
14.205930574308164
ave loss
0.22329493003216253
max_loss
0.7743210792541504
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18028995151413077, 'num_bad_epochs': 8, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 116}
TOTALPREDICTION
tensor([1.8033], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
198
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         0.8        0.         0.0000004  1.         0.00154743
 1.         1.         0.2097152 ]
[11.81936577 11.81936577 11.81936577 11.81936577 11.81936577 11.81936577
 11.81936577 11.81936577 11.81936577 11.81936577  5.90968288  5.90968288
 11.81936577 11.81936577 11.81936577  5.90968288  5.90968288  5.90968288
 11.81936577 11.81936577  0.        ]
original epr
4.169970209028246
index of max error on path
103
maximum_predicted_value
0.08010663092136383
MAXIMUM LAYER WEIGHTS

tensor(0.2223, grad_fn=<MaxBackward1>)

tensor(0.1692, grad_fn=<MaxBackward1>)
random,nn steps
6
192
TOTAL REWARD
14.27718911755707
ave loss
0.34955448135169165
max_loss
0.7741864323616028
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18028995151413077, 'num_bad_epochs': 9, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 117}
TOTALPREDICTION
tensor([3.5986], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
200
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00032452 0.8        1.         1.
 1.         0.0180144  1.         0.00000063 0.8        1.
 0.00000374 1.         0.00472237]
[11.82296036 11.82296036 11.82296036 11.82296036 11.82296036 11.82296036
 11.82296036 11.82296036 11.82296036 11.82296036  5.91148018  5.91148018
 11.82296036 11.82296036 11.82296036  5.91148018  5.91148018  5.91148018
 11.82296036 11.82296036  0.        ]
original epr
4.178662235659372
index of max error on path
82
maximum_predicted_value
0.18713559210300446
MAXIMUM LAYER WEIGHTS

tensor(0.2223, grad_fn=<MaxBackward1>)

tensor(0.1695, grad_fn=<MaxBackward1>)
random,nn steps
5
195
TOTAL REWARD
14.344484013251272
ave loss
0.27277604982256887
max_loss
0.5914295315742493
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18028995151413077, 'num_bad_epochs': 10, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 118}
TOTALPREDICTION
tensor([2.9099], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
359
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.512      0.00010634 0.00079228
 1.         0.00193428 1.         0.00004356 0.2097152  0.00063383
 0.00050706 1.         0.        ]
[11.77767438 11.77767438 11.77767438 11.77767438 11.77767438 11.77767438
 11.77767438 11.77767438 11.77767438 11.77767438  5.88883719  5.88883719
 11.77767438 11.77767438 11.77767438  5.88883719  5.88883719  5.88883719
 11.77767438 11.77767438 -0.        ]
original epr
4.191219403780064
index of max error on path
283
maximum_predicted_value
0.17609316110610962
MAXIMUM LAYER WEIGHTS

tensor(0.2224, grad_fn=<MaxBackward1>)

tensor(0.1695, grad_fn=<MaxBackward1>)
random,nn steps
12
347
TOTAL REWARD
14.32049957321624
ave loss
0.18925868455206452
max_loss
0.8102328777313232
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18028995151413077, 'num_bad_epochs': 11, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 119}
TOTALPREDICTION
tensor([1.4522], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
237
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.8        0.8
 0.022518   0.00025961 1.         0.00000585 0.00016615 0.8
 0.00008507 1.         0.00004356]
[11.76103122 11.76103122 11.76103122 11.76103122 11.76103122 11.76103122
 11.76103122 11.76103122 11.76103122 11.76103122  5.88051561  5.88051561
 11.76103122 11.76103122 11.76103122  5.88051561  5.88051561  5.88051561
 11.76103122 11.76103122  0.        ]
original epr
4.184742172619024
index of max error on path
154
maximum_predicted_value
0.25268200039863586
MAXIMUM LAYER WEIGHTS

tensor(0.2224, grad_fn=<MaxBackward1>)

tensor(0.1697, grad_fn=<MaxBackward1>)
random,nn steps
4
233
TOTAL REWARD
14.078567447733604
ave loss
0.22592087149745804
max_loss
0.7498869895935059
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18028995151413077, 'num_bad_epochs': 12, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 120}
TOTALPREDICTION
tensor([1.9677], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
212
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.8        1.
 1.         1.         1.         0.00000016 0.00050706 1.
 0.         1.         0.0281475 ]
[11.82093307 11.82093307 11.82093307 11.82093307 11.82093307 11.82093307
 11.82093307 11.82093307 11.82093307 11.82093307  5.91046653  5.91046653
 11.82093307 11.82093307 11.82093307  5.91046653  5.91046653  5.91046653
 11.82093307 11.82093307  0.        ]
original epr
4.1781160157468795
index of max error on path
17
maximum_predicted_value
0.18992702662944794
MAXIMUM LAYER WEIGHTS

tensor(0.2225, grad_fn=<MaxBackward1>)

tensor(0.1699, grad_fn=<MaxBackward1>)
random,nn steps
5
207
TOTAL REWARD
14.415971877652169
ave loss
0.2535062677595975
max_loss
0.42359328269958496
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18028995151413077, 'num_bad_epochs': 13, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 121}
TOTALPREDICTION
tensor([3.4888], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
397
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.00922337 1.         0.8
 0.8        0.13421773 0.00000468 0.00003484 0.00016615 1.
 0.03518437 1.         0.        ]
[11.76092828 11.76092828 11.76092828 11.76092828 11.76092828 11.76092828
 11.76092828 11.76092828 11.76092828 11.76092828  5.88046414  5.88046414
 11.76092828 11.76092828 11.76092828  5.88046414  5.88046414  5.88046414
 11.76092828 11.76092828  0.        ]
original epr
4.183632058331264
index of max error on path
319
maximum_predicted_value
0.18600468337535858
MAXIMUM LAYER WEIGHTS

tensor(0.2225, grad_fn=<MaxBackward1>)

tensor(0.1699, grad_fn=<MaxBackward1>)
random,nn steps
9
388
TOTAL REWARD
14.277636416434115
ave loss
0.18258629474666918
max_loss
0.7894382476806641
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18028995151413077, 'num_bad_epochs': 14, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 122}
TOTALPREDICTION
tensor([0.8090], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
317
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.64       1.
 1.         0.00020769 0.8        0.00000585 0.00016615 0.8
 0.00000299 1.         0.        ]
[11.75676315 11.75676315 11.75676315 11.75676315 11.75676315 11.75676315
 11.75676315 11.75676315 11.75676315 11.75676315  5.87838158  5.87838158
 11.75676315 11.75676315 11.75676315  5.87838158  5.87838158  5.87838158
 11.75676315 11.75676315 -0.        ]
original epr
4.18332424408974
index of max error on path
235
maximum_predicted_value
0.2578582465648651
MAXIMUM LAYER WEIGHTS

tensor(0.2225, grad_fn=<MaxBackward1>)

tensor(0.1699, grad_fn=<MaxBackward1>)
random,nn steps
6
311
TOTAL REWARD
14.187732212806058
ave loss
0.19999189450396723
max_loss
0.7548220157623291
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18028995151413077, 'num_bad_epochs': 15, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 123}
TOTALPREDICTION
tensor([0.4576], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
205
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.8        0.64
 0.00000063 0.00099035 1.         0.00000098 1.         0.00099035
 1.         0.8        0.05497558]
[11.75676314 11.75676314 11.75676314 11.75676314 11.75676314 11.75676314
 11.75676314 11.75676314 11.75676314 11.75676314  5.87838157  5.87838157
 11.75676314 11.75676314 11.75676314  5.87838157  5.87838157  5.87838157
 11.75676314 11.75676314  0.        ]
original epr
4.1811200131136665
index of max error on path
114
maximum_predicted_value
0.12616170942783356
MAXIMUM LAYER WEIGHTS

tensor(0.2225, grad_fn=<MaxBackward1>)

tensor(0.1700, grad_fn=<MaxBackward1>)
random,nn steps
8
197
TOTAL REWARD
14.294762711577489
ave loss
0.29792091971853885
max_loss
0.7729950547218323
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18028995151413077, 'num_bad_epochs': 16, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 124}
TOTALPREDICTION
tensor([3.3533], grad_fn=<AddBackward0>)
RESET epsilon ANNEALING
0.015625
**************************************Path Length ds<0******************************************
212
Final STATE
[1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.        1.        0.8       0.        1.        0.0281475]
[11.81150138 11.81150138 11.81150138 11.81150138 11.81150138 11.81150138
 11.81150138 11.81150138 11.81150138 11.81150138  5.90575069  5.90575069
 11.81150138 11.81150138 11.81150138  5.90575069  5.90575069  5.90575069
 11.81150138 11.81150138  0.        ]
original epr
4.174338001200205
index of max error on path
17
maximum_predicted_value
0.1792321354150772
MAXIMUM LAYER WEIGHTS

tensor(0.2226, grad_fn=<MaxBackward1>)

tensor(0.1703, grad_fn=<MaxBackward1>)
random,nn steps
2
210
TOTAL REWARD
14.517670371059642
ave loss
0.2601706893271152
max_loss
0.41890400648117065
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18028995151413077, 'num_bad_epochs': 17, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 125}
TOTALPREDICTION
tensor([3.4461], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
268
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.0281475  0.64       1.
 1.         0.00241785 1.         0.00003484 0.00013292 1.
 0.00000374 0.8        0.00000002]
[11.75831949 11.75831949 11.75831949 11.75831949 11.75831949 11.75831949
 11.75831949 11.75831949 11.75831949 11.75831949  5.87915974  5.87915974
 11.75831949 11.75831949 11.75831949  5.87915974  5.87915974  5.87915974
 11.75831949 11.75831949  0.        ]
original epr
4.183162816762053
index of max error on path
190
maximum_predicted_value
0.27113187313079834
MAXIMUM LAYER WEIGHTS

tensor(0.2226, grad_fn=<MaxBackward1>)

tensor(0.1703, grad_fn=<MaxBackward1>)
random,nn steps
5
263
TOTAL REWARD
14.251130038549011
ave loss
0.21783552808103276
max_loss
0.7482849955558777
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18028995151413077, 'num_bad_epochs': 18, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 126}
TOTALPREDICTION
tensor([1.1828], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
207
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.00154743 1.         1.
 1.         0.00922337 1.         0.00000007 1.         0.8
 0.00000374 1.         0.00302231]
[11.82122547 11.82122547 11.82122547 11.82122547 11.82122547 11.82122547
 11.82122547 11.82122547 11.82122547 11.82122547  5.91061273  5.91061273
 11.82122547 11.82122547 11.82122547  5.91061273  5.91061273  5.91061273
 11.82122547 11.82122547  0.        ]
original epr
4.1781180721465425
index of max error on path
83
maximum_predicted_value
0.21397022902965546
MAXIMUM LAYER WEIGHTS

tensor(0.2227, grad_fn=<MaxBackward1>)

tensor(0.1706, grad_fn=<MaxBackward1>)
random,nn steps
4
203
TOTAL REWARD
14.288774564211135
ave loss
0.2570355630295288
max_loss
0.5788816213607788
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18028995151413077, 'num_bad_epochs': 19, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 127}
TOTALPREDICTION
tensor([2.8697], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
380
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.64       1.
 0.8        0.00016615 1.         0.00000585 0.00016615 0.8
 0.00000374 1.         0.        ]
[11.75676315 11.75676315 11.75676315 11.75676315 11.75676315 11.75676315
 11.75676315 11.75676315 11.75676315 11.75676315  5.87838158  5.87838158
 11.75676315 11.75676315 11.75676315  5.87838158  5.87838158  5.87838158
 11.75676315 11.75676315  0.        ]
original epr
4.183324244009921
index of max error on path
298
maximum_predicted_value
0.2729880213737488
MAXIMUM LAYER WEIGHTS

tensor(0.2227, grad_fn=<MaxBackward1>)

tensor(0.1705, grad_fn=<MaxBackward1>)
random,nn steps
4
376
TOTAL REWARD
14.180005331730696
ave loss
0.18685907071554347
max_loss
0.7485570907592773
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18028995151413077, 'num_bad_epochs': 20, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 128}
TOTALPREDICTION
tensor([0.6955], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
286
Final STATE
[1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.  0.  1.  1.
 0.8 1.  1. ]
[11.81450415 11.81450415 11.81450415 11.81450415 11.81450415 11.81450415
 11.81450415 11.81450415 11.81450415 11.81450415  5.90725207  5.90725207
 11.81450415 11.81450415 11.81450415  5.90725207  5.90725207  5.90725207
 11.81450415 11.81450415  0.        ]
original epr
4.13753591696158
index of max error on path
280
maximum_predicted_value
0.07184373587369919
MAXIMUM LAYER WEIGHTS

tensor(0.2228, grad_fn=<MaxBackward1>)

tensor(0.1707, grad_fn=<MaxBackward1>)
random,nn steps
2
284
TOTAL REWARD
14.85907738561418
ave loss
0.23221328187655735
max_loss
0.43958088755607605
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.18028995151413077, 'num_bad_epochs': 21, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 129}
TOTALPREDICTION
tensor([5.2389], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
620
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.0073787  0.8        0.8
 0.8        0.00922337 1.         0.00003484 0.00013292 1.
 0.00000374 1.         0.        ]
[11.75946365 11.75946365 11.75946365 11.75946365 11.75946365 11.75946365
 11.75946365 11.75946365 11.75946365 11.75946365  5.87973182  5.87973182
 11.75946365 11.75946365 11.75946365  5.87973182  5.87973182  5.87973182
 11.75946365 11.75946365  0.        ]
original epr
4.18378957459993
index of max error on path
542
maximum_predicted_value
0.28216856718063354
MAXIMUM LAYER WEIGHTS

tensor(0.2227, grad_fn=<MaxBackward1>)

tensor(0.1702, grad_fn=<MaxBackward1>)
random,nn steps
10
610
TOTAL REWARD
14.220597825444507
ave loss
0.16721473877588588
max_loss
0.7475938200950623
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.16721473877588588, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 130}
TOTALPREDICTION
tensor([5.0229], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
544
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.01152922 0.4096     1.
 0.64       0.03518437 1.         0.00002788 0.00016615 1.
 0.00000098 1.         0.        ]
[11.76176074 11.76176074 11.76176074 11.76176074 11.76176074 11.76176074
 11.76176074 11.76176074 11.76176074 11.76176074  5.88088037  5.88088037
 11.76176074 11.76176074 11.76176074  5.88088037  5.88088037  5.88088037
 11.76176074 11.76176074  0.        ]
original epr
4.184411311744167
index of max error on path
465
maximum_predicted_value
0.2610626518726349
MAXIMUM LAYER WEIGHTS

tensor(0.2226, grad_fn=<MaxBackward1>)

tensor(0.1698, grad_fn=<MaxBackward1>)
random,nn steps
8
536
TOTAL REWARD
14.276508969961322
ave loss
0.16785632121130167
max_loss
0.7502524256706238
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.16721473877588588, 'num_bad_epochs': 1, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 131}
TOTALPREDICTION
tensor([3.6893], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
268
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00377789 1.         1.         0.8
 1.         0.10737418 1.         0.00004356 0.00013292 1.
 0.0000005  0.8        0.00000001]
[11.75609514 11.75609514 11.75609514 11.75609514 11.75609514 11.75609514
 11.75609514 11.75609514 11.75609514 11.75609514  5.87804757  5.87804757
 11.75609514 11.75609514 11.75609514  5.87804757  5.87804757  5.87804757
 11.75609514 11.75609514 -0.        ]
original epr
4.182219380231234
index of max error on path
190
maximum_predicted_value
0.2519228160381317
MAXIMUM LAYER WEIGHTS

tensor(0.2226, grad_fn=<MaxBackward1>)

tensor(0.1699, grad_fn=<MaxBackward1>)
random,nn steps
4
264
TOTAL REWARD
14.443850411130114
ave loss
0.22088898359728393
max_loss
0.7506700754165649
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.16721473877588588, 'num_bad_epochs': 2, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 132}
TOTALPREDICTION
tensor([1.3108], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
307
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.64       0.8
 1.         0.00020769 1.         0.00000585 0.00013292 0.8
 0.00000299 1.         0.        ]
[11.75833355 11.75833355 11.75833355 11.75833355 11.75833355 11.75833355
 11.75833355 11.75833355 11.75833355 11.75833355  5.87916678  5.87916678
 11.75833355 11.75833355 11.75833355  5.87916678  5.87916678  5.87916678
 11.75833355 11.75833355 -0.        ]
original epr
4.184278189269091
index of max error on path
224
maximum_predicted_value
0.2703988552093506
MAXIMUM LAYER WEIGHTS

tensor(0.2226, grad_fn=<MaxBackward1>)

tensor(0.1700, grad_fn=<MaxBackward1>)
random,nn steps
4
303
TOTAL REWARD
14.31657364764474
ave loss
0.20270506270739466
max_loss
0.7491404414176941
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.16721473877588588, 'num_bad_epochs': 3, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 133}
TOTALPREDICTION
tensor([0.6277], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
242
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00050706 1.         1.         0.8
 1.         0.00099035 1.         0.00004356 0.00020769 1.
 0.00025961 1.         0.00000374]
[11.75440882 11.75440882 11.75440882 11.75440882 11.75440882 11.75440882
 11.75440882 11.75440882 11.75440882 11.75440882  5.87720441  5.87720441
 11.75440882 11.75440882 11.75440882  5.87720441  5.87720441  5.87720441
 11.75440882 11.75440882  0.        ]
original epr
4.181594035619541
index of max error on path
164
maximum_predicted_value
0.28354185819625854
MAXIMUM LAYER WEIGHTS

tensor(0.2226, grad_fn=<MaxBackward1>)

tensor(0.1701, grad_fn=<MaxBackward1>)
random,nn steps
3
239
TOTAL REWARD
14.343389360686658
ave loss
0.22710269506374173
max_loss
0.738373875617981
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.16721473877588588, 'num_bad_epochs': 4, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 134}
TOTALPREDICTION
tensor([1.5725], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
454
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.64       1.
 1.         0.00013292 1.         0.00000585 0.00013292 1.
 0.00000468 0.8        0.        ]
[11.7534486 11.7534486 11.7534486 11.7534486 11.7534486 11.7534486
 11.7534486 11.7534486 11.7534486 11.7534486  5.8767243  5.8767243
 11.7534486 11.7534486 11.7534486  5.8767243  5.8767243  5.8767243
 11.7534486 11.7534486  0.       ]
original epr
4.181749583233463
index of max error on path
372
maximum_predicted_value
0.2719755172729492
MAXIMUM LAYER WEIGHTS

tensor(0.2226, grad_fn=<MaxBackward1>)

tensor(0.1699, grad_fn=<MaxBackward1>)
random,nn steps
5
449
TOTAL REWARD
14.21317654805314
ave loss
0.1770525514127662
max_loss
0.7502448558807373
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.16721473877588588, 'num_bad_epochs': 5, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 135}
TOTALPREDICTION
tensor([1.9922], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
317
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00004356 1.         1.         0.8
 0.32768    1.         0.262144   0.00003484 0.00025961 0.64
 0.00004356 1.         0.        ]
[11.76389521 11.76389521 11.76389521 11.76389521 11.76389521 11.76389521
 11.76389521 11.76389521 11.76389521 11.76389521  5.8819476   5.8819476
 11.76389521 11.76389521 11.76389521  5.8819476   5.8819476   5.8819476
 11.76389521 11.76389521  0.        ]
original epr
4.185448306065627
index of max error on path
239
maximum_predicted_value
0.2374861240386963
MAXIMUM LAYER WEIGHTS

tensor(0.2226, grad_fn=<MaxBackward1>)

tensor(0.1699, grad_fn=<MaxBackward1>)
random,nn steps
6
311
TOTAL REWARD
14.220782476813971
ave loss
0.20505433440302448
max_loss
0.76690274477005
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.16721473877588588, 'num_bad_epochs': 6, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 136}
TOTALPREDICTION
tensor([0.4370], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
218
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.8        0.8
 1.         0.00020769 1.         0.00000585 0.00020769 0.64
 0.00000299 0.8        0.00302231]
[11.76007513 11.76007513 11.76007513 11.76007513 11.76007513 11.76007513
 11.76007513 11.76007513 11.76007513 11.76007513  5.88003756  5.88003756
 11.76007513 11.76007513 11.76007513  5.88003756  5.88003756  5.88003756
 11.76007513 11.76007513  0.        ]
original epr
4.1847773709174545
index of max error on path
139
maximum_predicted_value
0.25561344623565674
MAXIMUM LAYER WEIGHTS

tensor(0.2226, grad_fn=<MaxBackward1>)

tensor(0.1701, grad_fn=<MaxBackward1>)
random,nn steps
6
212
TOTAL REWARD
14.221546392254027
ave loss
0.23600423057486705
max_loss
0.6740403771400452
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.16721473877588588, 'num_bad_epochs': 7, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 137}
TOTALPREDICTION
tensor([2.2338], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
392
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         0.512
 0.8        0.00154743 1.         0.00000731 0.00013292 1.
 0.0000004  1.         0.        ]
[11.75486133 11.75486133 11.75486133 11.75486133 11.75486133 11.75486133
 11.75486133 11.75486133 11.75486133 11.75486133  5.87743067  5.87743067
 11.75486133 11.75486133 11.75486133  5.87743067  5.87743067  5.87743067
 11.75486133 11.75486133  0.        ]
original epr
4.18231126482305
index of max error on path
309
maximum_predicted_value
0.2590717077255249
MAXIMUM LAYER WEIGHTS

tensor(0.2226, grad_fn=<MaxBackward1>)

tensor(0.1700, grad_fn=<MaxBackward1>)
random,nn steps
8
384
TOTAL REWARD
14.318085166183717
ave loss
0.18312462794651485
max_loss
0.7488926649093628
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.16721473877588588, 'num_bad_epochs': 8, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 138}
TOTALPREDICTION
tensor([0.6295], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
200
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00302231 1.         1.         1.
 1.         0.00154743 1.         0.0000005  1.         1.
 0.00000374 1.         0.00472237]
[11.81792129 11.81792129 11.81792129 11.81792129 11.81792129 11.81792129
 11.81792129 11.81792129 11.81792129 11.81792129  5.90896065  5.90896065
 11.81792129 11.81792129 11.81792129  5.90896065  5.90896065  5.90896065
 11.81792129 11.81792129  0.        ]
original epr
4.1764974221574205
index of max error on path
82
maximum_predicted_value
0.2146414816379547
MAXIMUM LAYER WEIGHTS

tensor(0.2227, grad_fn=<MaxBackward1>)

tensor(0.1702, grad_fn=<MaxBackward1>)
random,nn steps
2
198
TOTAL REWARD
14.440380048060097
ave loss
0.26423134103417395
max_loss
0.5787712335586548
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.16721473877588588, 'num_bad_epochs': 9, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 139}
TOTALPREDICTION
tensor([2.7765], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
331
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.8        0.8
 0.0281475  0.00025961 0.8        0.00000585 0.00013292 1.
 0.00008507 1.         0.        ]
[11.75946043 11.75946043 11.75946043 11.75946043 11.75946043 11.75946043
 11.75946043 11.75946043 11.75946043 11.75946043  5.87973022  5.87973022
 11.75946043 11.75946043 11.75946043  5.87973022  5.87973022  5.87973022
 11.75946043 11.75946043  0.        ]
original epr
4.183790407133573
index of max error on path
249
maximum_predicted_value
0.27745944261550903
MAXIMUM LAYER WEIGHTS

tensor(0.2227, grad_fn=<MaxBackward1>)

tensor(0.1702, grad_fn=<MaxBackward1>)
random,nn steps
6
325
TOTAL REWARD
14.127887096012895
ave loss
0.19518580772770497
max_loss
0.7456028461456299
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.16721473877588588, 'num_bad_epochs': 10, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 140}
TOTALPREDICTION
tensor([0.1778], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
224
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.8        1.
 0.512      0.00154743 0.00123794 0.00000374 0.00016615 1.
 0.00050706 1.         0.00079228]
[11.75799525 11.75799525 11.75799525 11.75799525 11.75799525 11.75799525
 11.75799525 11.75799525 11.75799525 11.75799525  5.87899763  5.87899763
 11.75799525 11.75799525 11.75799525  5.87899763  5.87899763  5.87899763
 11.75799525 11.75799525  0.        ]
original epr
4.182744010543087
index of max error on path
140
maximum_predicted_value
0.21992965042591095
MAXIMUM LAYER WEIGHTS

tensor(0.2227, grad_fn=<MaxBackward1>)

tensor(0.1703, grad_fn=<MaxBackward1>)
random,nn steps
6
218
TOTAL REWARD
14.219268347331631
ave loss
0.25511227415076326
max_loss
0.7594143152236938
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.16721473877588588, 'num_bad_epochs': 11, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 141}
TOTALPREDICTION
tensor([2.5706], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
257
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.01441152 1.         0.262144
 1.         0.0281475  1.         0.00002788 0.00016615 1.
 0.00000078 1.         0.00000032]
[11.75986573 11.75986573 11.75986573 11.75986573 11.75986573 11.75986573
 11.75986573 11.75986573 11.75986573 11.75986573  5.87993286  5.87993286
 11.75986573 11.75986573 11.75986573  5.87993286  5.87993286  5.87993286
 11.75986573 11.75986573  0.        ]
original epr
4.183730608422797
index of max error on path
178
maximum_predicted_value
0.2703537046909332
MAXIMUM LAYER WEIGHTS

tensor(0.2228, grad_fn=<MaxBackward1>)

tensor(0.1704, grad_fn=<MaxBackward1>)
random,nn steps
4
253
TOTAL REWARD
14.386051290336388
ave loss
0.22163687091219286
max_loss
0.7428852319717407
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.16721473877588588, 'num_bad_epochs': 12, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 142}
TOTALPREDICTION
tensor([1.3531], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
290
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00154743 1.         1.         0.64
 0.512      0.00377789 1.         0.00003484 0.2097152  0.00040565
 0.00010634 0.8        0.        ]
[11.77090303 11.77090303 11.77090303 11.77090303 11.77090303 11.77090303
 11.77090303 11.77090303 11.77090303 11.77090303  5.88545152  5.88545152
 11.77090303 11.77090303 11.77090303  5.88545152  5.88545152  5.88545152
 11.77090303 11.77090303 -0.        ]
original epr
4.188110401148048
index of max error on path
213
maximum_predicted_value
0.20988278090953827
MAXIMUM LAYER WEIGHTS

tensor(0.2228, grad_fn=<MaxBackward1>)

tensor(0.1705, grad_fn=<MaxBackward1>)
random,nn steps
7
283
TOTAL REWARD
14.338670477167119
ave loss
0.21155438155963502
max_loss
0.7945713400840759
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.16721473877588588, 'num_bad_epochs': 13, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 143}
TOTALPREDICTION
tensor([1.0376], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
206
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         0.13421773 0.         1.         1.
 0.         1.         0.0281475 ]
[11.81296958 11.81296958 11.81296958 11.81296958 11.81296958 11.81296958
 11.81296958 11.81296958 11.81296958 11.81296958  5.90648479  5.90648479
 11.81296958 11.81296958 11.81296958  5.90648479  5.90648479  5.90648479
 11.81296958 11.81296958  0.        ]
original epr
4.174179868746484
index of max error on path
17
maximum_predicted_value
0.2015174776315689
MAXIMUM LAYER WEIGHTS

tensor(0.2229, grad_fn=<MaxBackward1>)

tensor(0.1707, grad_fn=<MaxBackward1>)
random,nn steps
2
204
TOTAL REWARD
14.33263516991619
ave loss
0.2545550506272652
max_loss
0.40815073251724243
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.16721473877588588, 'num_bad_epochs': 14, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 144}
TOTALPREDICTION
tensor([3.3469], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
455
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.8        0.8
 1.         0.00013292 1.         0.00000731 0.00010634 1.
 0.00000374 1.         0.        ]
[11.75284692 11.75284692 11.75284692 11.75284692 11.75284692 11.75284692
 11.75284692 11.75284692 11.75284692 11.75284692  5.87642346  5.87642346
 11.75284692 11.75284692 11.75284692  5.87642346  5.87642346  5.87642346
 11.75284692 11.75284692  0.        ]
original epr
4.181756569561689
index of max error on path
373
maximum_predicted_value
0.2883148789405823
MAXIMUM LAYER WEIGHTS

tensor(0.2228, grad_fn=<MaxBackward1>)

tensor(0.1705, grad_fn=<MaxBackward1>)
random,nn steps
8
447
TOTAL REWARD
14.302851234107404
ave loss
0.17942877523191683
max_loss
0.7427422404289246
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.16721473877588588, 'num_bad_epochs': 15, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 145}
TOTALPREDICTION
tensor([2.0882], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
245
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.00590296 0.8        1.
 1.         0.00000299 1.         0.00003484 0.00016615 1.
 0.00922337 1.         0.00000239]
[11.75440824 11.75440824 11.75440824 11.75440824 11.75440824 11.75440824
 11.75440824 11.75440824 11.75440824 11.75440824  5.87720412  5.87720412
 11.75440824 11.75440824 11.75440824  5.87720412  5.87720412  5.87720412
 11.75440824 11.75440824  0.        ]
original epr
4.181594383496318
index of max error on path
169
maximum_predicted_value
0.27608561515808105
MAXIMUM LAYER WEIGHTS

tensor(0.2229, grad_fn=<MaxBackward1>)

tensor(0.1706, grad_fn=<MaxBackward1>)
random,nn steps
4
241
TOTAL REWARD
14.291333411076907
ave loss
0.23024793851132297
max_loss
0.743773877620697
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.16721473877588588, 'num_bad_epochs': 16, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 146}
TOTALPREDICTION
tensor([1.5507], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
232
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.01152922 0.8        0.8
 1.         0.00472237 1.         0.00002788 0.00016615 1.
 0.00000374 1.         0.00005445]
[11.7577218 11.7577218 11.7577218 11.7577218 11.7577218 11.7577218
 11.7577218 11.7577218 11.7577218 11.7577218  5.8788609  5.8788609
 11.7577218 11.7577218 11.7577218  5.8788609  5.8788609  5.8788609
 11.7577218 11.7577218  0.       ]
original epr
4.1831669097602555
index of max error on path
152
maximum_predicted_value
0.2844764292240143
MAXIMUM LAYER WEIGHTS

tensor(0.2229, grad_fn=<MaxBackward1>)

tensor(0.1708, grad_fn=<MaxBackward1>)
random,nn steps
4
228
TOTAL REWARD
14.32786611971049
ave loss
0.22798751969018888
max_loss
0.7360683083534241
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.16721473877588588, 'num_bad_epochs': 17, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 147}
TOTALPREDICTION
tensor([1.8091], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
270
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00010634 0.8        0.64       0.8
 1.         1.         1.         0.00003484 0.00016615 1.
 0.00000239 1.         0.00000001]
[11.75676315 11.75676315 11.75676315 11.75676315 11.75676315 11.75676315
 11.75676315 11.75676315 11.75676315 11.75676315  5.87838158  5.87838158
 11.75676315 11.75676315 11.75676315  5.87838158  5.87838158  5.87838158
 11.75676315 11.75676315  0.        ]
original epr
4.183324243482873
index of max error on path
192
maximum_predicted_value
0.2818721532821655
MAXIMUM LAYER WEIGHTS

tensor(0.2229, grad_fn=<MaxBackward1>)

tensor(0.1708, grad_fn=<MaxBackward1>)
random,nn steps
5
265
TOTAL REWARD
14.394246827418366
ave loss
0.21534089688901548
max_loss
0.7445515394210815
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.16721473877588588, 'num_bad_epochs': 18, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 148}
TOTALPREDICTION
tensor([1.0137], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
319
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.8        0.8
 1.         0.00013292 1.         0.00000585 0.00013292 1.
 0.00000374 1.         0.        ]
[11.75284692 11.75284692 11.75284692 11.75284692 11.75284692 11.75284692
 11.75284692 11.75284692 11.75284692 11.75284692  5.87642346  5.87642346
 11.75284692 11.75284692 11.75284692  5.87642346  5.87642346  5.87642346
 11.75284692 11.75284692  0.        ]
original epr
4.181756569626955
index of max error on path
237
maximum_predicted_value
0.2911311388015747
MAXIMUM LAYER WEIGHTS

tensor(0.2229, grad_fn=<MaxBackward1>)

tensor(0.1709, grad_fn=<MaxBackward1>)
random,nn steps
1
318
TOTAL REWARD
14.308970428922883
ave loss
0.19902800827003944
max_loss
0.7397187948226929
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.16721473877588588, 'num_bad_epochs': 19, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 149}
TOTALPREDICTION
tensor([0.2679], grad_fn=<AddBackward0>)
RESET epsilon ANNEALING
0.0078125
**************************************Path Length ds<0******************************************
426
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.8        0.8
 1.         0.00013292 1.         0.00000585 0.00013292 1.
 0.00000374 1.         0.        ]
[11.75284692 11.75284692 11.75284692 11.75284692 11.75284692 11.75284692
 11.75284692 11.75284692 11.75284692 11.75284692  5.87642346  5.87642346
 11.75284692 11.75284692 11.75284692  5.87642346  5.87642346  5.87642346
 11.75284692 11.75284692  0.        ]
original epr
4.181756569624539
index of max error on path
344
maximum_predicted_value
0.29141807556152344
MAXIMUM LAYER WEIGHTS

tensor(0.2229, grad_fn=<MaxBackward1>)

tensor(0.1707, grad_fn=<MaxBackward1>)
random,nn steps
1
425
TOTAL REWARD
14.308970428907493
ave loss
0.18292905981411955
max_loss
0.7409631013870239
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.16721473877588588, 'num_bad_epochs': 20, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 150}
TOTALPREDICTION
tensor([1.6131], grad_fn=<AddBackward0>)
index of max error on path
84
maximum_predicted_value
0.2888166010379791
MAXIMUM LAYER WEIGHTS

tensor(0.2226, grad_fn=<MaxBackward1>)

tensor(0.1694, grad_fn=<MaxBackward1>)
random,nn steps
3
997
TOTAL REWARD
6.36721333663629
ave loss
0.1358661464635451
max_loss
0.47988080978393555
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.1358661464635451, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 151}
TOTALPREDICTION
tensor([14.4107], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
213
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         0.00013292 1.         0.         1.         1.
 0.00000468 0.8        0.0073787 ]
[11.81479774 11.81479774 11.81479774 11.81479774 11.81479774 11.81479774
 11.81479774 11.81479774 11.81479774 11.81479774  5.90739887  5.90739887
 11.81479774 11.81479774 11.81479774  5.90739887  5.90739887  5.90739887
 11.81479774 11.81479774  0.        ]
original epr
4.1756125053763276
index of max error on path
80
maximum_predicted_value
0.20542126893997192
MAXIMUM LAYER WEIGHTS

tensor(0.2227, grad_fn=<MaxBackward1>)

tensor(0.1696, grad_fn=<MaxBackward1>)
random,nn steps
2
211
TOTAL REWARD
14.365058237052965
ave loss
0.24334022985167905
max_loss
0.5832562446594238
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.1358661464635451, 'num_bad_epochs': 1, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 152}
TOTALPREDICTION
tensor([2.8206], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
287
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00241785 1.         0.8        0.8
 1.         0.022518   1.         0.00003484 0.00013292 1.
 0.00000374 1.         0.        ]
[11.75772004 11.75772004 11.75772004 11.75772004 11.75772004 11.75772004
 11.75772004 11.75772004 11.75772004 11.75772004  5.87886002  5.87886002
 11.75772004 11.75772004 11.75772004  5.87886002  5.87886002  5.87886002
 11.75772004 11.75772004  0.        ]
original epr
4.183169599504398
index of max error on path
209
maximum_predicted_value
0.2707706391811371
MAXIMUM LAYER WEIGHTS

tensor(0.2227, grad_fn=<MaxBackward1>)

tensor(0.1697, grad_fn=<MaxBackward1>)
random,nn steps
2
285
TOTAL REWARD
14.387116556225822
ave loss
0.21164479292280167
max_loss
0.7490741014480591
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.1358661464635451, 'num_bad_epochs': 2, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 153}
TOTALPREDICTION
tensor([0.8069], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
213
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.00000001 1.         0.0073787
 0.         1.         0.022518  ]
[11.8176276 11.8176276 11.8176276 11.8176276 11.8176276 11.8176276
 11.8176276 11.8176276 11.8176276 11.8176276  5.9088138  5.9088138
 11.8176276 11.8176276 11.8176276  5.9088138  5.9088138  5.9088138
 11.8176276 11.8176276  0.       ]
original epr
4.17678758376472
index of max error on path
101
maximum_predicted_value
0.19699060916900635
MAXIMUM LAYER WEIGHTS

tensor(0.2228, grad_fn=<MaxBackward1>)

tensor(0.1699, grad_fn=<MaxBackward1>)
random,nn steps
2
211
TOTAL REWARD
14.412130094490735
ave loss
0.262838292552132
max_loss
0.5331946015357971
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.1358661464635451, 'num_bad_epochs': 3, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 154}
TOTALPREDICTION
tensor([3.4177], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
299
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.0073787  0.8        0.8
 1.         0.00922337 0.8        0.00003484 0.00013292 1.
 0.00000374 1.         0.        ]
[11.75946365 11.75946365 11.75946365 11.75946365 11.75946365 11.75946365
 11.75946365 11.75946365 11.75946365 11.75946365  5.87973182  5.87973182
 11.75946365 11.75946365 11.75946365  5.87973182  5.87973182  5.87973182
 11.75946365 11.75946365  0.        ]
original epr
4.183789574599254
index of max error on path
226
maximum_predicted_value
0.27349594235420227
MAXIMUM LAYER WEIGHTS

tensor(0.2228, grad_fn=<MaxBackward1>)

tensor(0.1699, grad_fn=<MaxBackward1>)
random,nn steps
5
294
TOTAL REWARD
14.364106934067536
ave loss
0.20909146575824075
max_loss
0.6910543441772461
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.1358661464635451, 'num_bad_epochs': 4, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 155}
TOTALPREDICTION
tensor([0.6243], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
425
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00002788 0.8        1.         0.32768
 1.         1.         1.         0.00004356 0.00020769 1.
 0.00000913 1.         0.        ]
[11.75636268 11.75636268 11.75636268 11.75636268 11.75636268 11.75636268
 11.75636268 11.75636268 11.75636268 11.75636268  5.87818134  5.87818134
 11.75636268 11.75636268 11.75636268  5.87818134  5.87818134  5.87818134
 11.75636268 11.75636268  0.        ]
original epr
4.1828298479749835
index of max error on path
347
maximum_predicted_value
0.283975213766098
MAXIMUM LAYER WEIGHTS

tensor(0.2228, grad_fn=<MaxBackward1>)

tensor(0.1697, grad_fn=<MaxBackward1>)
random,nn steps
5
420
TOTAL REWARD
14.238812967095578
ave loss
0.1840578331754488
max_loss
0.7400546073913574
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.1358661464635451, 'num_bad_epochs': 5, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 156}
TOTALPREDICTION
tensor([1.6274], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
278
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.8        0.64
 1.         0.00154743 1.         0.00001142 0.2097152  0.00025961
 0.0000004  1.         0.00000001]
[11.76403253 11.76403253 11.76403253 11.76403253 11.76403253 11.76403253
 11.76403253 11.76403253 11.76403253 11.76403253  5.88201627  5.88201627
 11.76403253 11.76403253 11.76403253  5.88201627  5.88201627  5.88201627
 11.76403253 11.76403253 -0.        ]
original epr
4.1864729151085545
index of max error on path
199
maximum_predicted_value
0.20123954117298126
MAXIMUM LAYER WEIGHTS

tensor(0.2228, grad_fn=<MaxBackward1>)

tensor(0.1698, grad_fn=<MaxBackward1>)
random,nn steps
5
273
TOTAL REWARD
14.347481474368436
ave loss
0.21542919771544797
max_loss
0.8093053698539734
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.1358661464635451, 'num_bad_epochs': 6, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 157}
TOTALPREDICTION
tensor([1.3553], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
484
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.8        0.8
 0.8        0.00016615 1.         0.00000731 0.00010634 1.
 0.00000374 1.         0.        ]
[11.75459083 11.75459083 11.75459083 11.75459083 11.75459083 11.75459083
 11.75459083 11.75459083 11.75459083 11.75459083  5.87729542  5.87729542
 11.75459083 11.75459083 11.75459083  5.87729542  5.87729542  5.87729542
 11.75459083 11.75459083  0.        ]
original epr
4.182377311227147
index of max error on path
402
maximum_predicted_value
0.2766526937484741
MAXIMUM LAYER WEIGHTS

tensor(0.2229, grad_fn=<MaxBackward1>)

tensor(0.1696, grad_fn=<MaxBackward1>)
random,nn steps
3
481
TOTAL REWARD
14.285835856551698
ave loss
0.17459310147880522
max_loss
0.7488141059875488
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.1358661464635451, 'num_bad_epochs': 7, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 158}
TOTALPREDICTION
tensor([2.5356], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
268
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.32768    1.
 1.         0.00099035 1.         0.00000731 0.00013292 1.
 0.00000063 1.         0.00000005]
[11.75461957 11.75461957 11.75461957 11.75461957 11.75461957 11.75461957
 11.75461957 11.75461957 11.75461957 11.75461957  5.87730978  5.87730978
 11.75461957 11.75461957 11.75461957  5.87730978  5.87730978  5.87730978
 11.75461957 11.75461957  0.        ]
original epr
4.18220921027735
index of max error on path
186
maximum_predicted_value
0.262418270111084
MAXIMUM LAYER WEIGHTS

tensor(0.2229, grad_fn=<MaxBackward1>)

tensor(0.1697, grad_fn=<MaxBackward1>)
random,nn steps
2
266
TOTAL REWARD
14.310342248473592
ave loss
0.2121335779136019
max_loss
0.7466505765914917
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.1358661464635451, 'num_bad_epochs': 8, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 159}
TOTALPREDICTION
tensor([1.2653], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
296
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.8        0.8
 1.         0.00016615 1.         0.00000585 0.00013292 1.
 0.00000299 1.         0.        ]
[11.75284692 11.75284692 11.75284692 11.75284692 11.75284692 11.75284692
 11.75284692 11.75284692 11.75284692 11.75284692  5.87642346  5.87642346
 11.75284692 11.75284692 11.75284692  5.87642346  5.87642346  5.87642346
 11.75284692 11.75284692 -0.        ]
original epr
4.181756569674276
index of max error on path
214
maximum_predicted_value
0.2744591236114502
MAXIMUM LAYER WEIGHTS

tensor(0.2229, grad_fn=<MaxBackward1>)

tensor(0.1697, grad_fn=<MaxBackward1>)
random,nn steps
3
293
TOTAL REWARD
14.308952022646508
ave loss
0.20484894332853523
max_loss
0.7474819421768188
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.1358661464635451, 'num_bad_epochs': 9, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 160}
TOTALPREDICTION
tensor([0.7822], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
521
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.8        0.8
 1.         0.00013292 1.         0.00000585 0.00013292 1.
 0.00000374 1.         0.        ]
[11.75284692 11.75284692 11.75284692 11.75284692 11.75284692 11.75284692
 11.75284692 11.75284692 11.75284692 11.75284692  5.87642346  5.87642346
 11.75284692 11.75284692 11.75284692  5.87642346  5.87642346  5.87642346
 11.75284692 11.75284692  0.        ]
original epr
4.1817565696245405
index of max error on path
439
maximum_predicted_value
0.2755216062068939
MAXIMUM LAYER WEIGHTS

tensor(0.2229, grad_fn=<MaxBackward1>)

tensor(0.1694, grad_fn=<MaxBackward1>)
random,nn steps
1
520
TOTAL REWARD
14.3089704289075
ave loss
0.17119637248240369
max_loss
0.7498602867126465
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.1358661464635451, 'num_bad_epochs': 10, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 161}
TOTALPREDICTION
tensor([3.1673], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
397
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.64       1.
 1.         0.00003484 1.         0.00000731 0.00010634 1.
 0.00001427 1.         0.        ]
[11.75170421 11.75170421 11.75170421 11.75170421 11.75170421 11.75170421
 11.75170421 11.75170421 11.75170421 11.75170421  5.8758521   5.8758521
 11.75170421 11.75170421 11.75170421  5.8758521   5.8758521   5.8758521
 11.75170421 11.75170421  0.        ]
original epr
4.1811288005273965
index of max error on path
315
maximum_predicted_value
0.2789612114429474
MAXIMUM LAYER WEIGHTS

tensor(0.2229, grad_fn=<MaxBackward1>)

tensor(0.1693, grad_fn=<MaxBackward1>)
random,nn steps
4
393
TOTAL REWARD
14.298778300325313
ave loss
0.1854409642742773
max_loss
0.7410699725151062
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.1358661464635451, 'num_bad_epochs': 11, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 162}
TOTALPREDICTION
tensor([0.8131], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
213
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         0.8
 1.         0.00013292 1.         0.         1.         1.
 0.00000374 1.         0.0073787 ]
[11.81636663 11.81636663 11.81636663 11.81636663 11.81636663 11.81636663
 11.81636663 11.81636663 11.81636663 11.81636663  5.90818332  5.90818332
 11.81636663 11.81636663 11.81636663  5.90818332  5.90818332  5.90818332
 11.81636663 11.81636663  0.        ]
original epr
4.176553951811744
index of max error on path
80
maximum_predicted_value
0.21103696525096893
MAXIMUM LAYER WEIGHTS

tensor(0.2230, grad_fn=<MaxBackward1>)

tensor(0.1696, grad_fn=<MaxBackward1>)
random,nn steps
2
211
TOTAL REWARD
14.419880404494137
ave loss
0.24190220147581168
max_loss
0.5808138847351074
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.1358661464635451, 'num_bad_epochs': 12, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 163}
TOTALPREDICTION
tensor([3.1204], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
905
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         0.00079228 1.         1.         0.2097152
 1.         1.         0.8        0.00003484 0.00013292 0.8
 0.00000063 1.         0.        ]
[11.76029494 11.76029494 11.76029494 11.76029494 11.76029494 11.76029494
 11.76029494 11.76029494 11.76029494 11.76029494  5.88014747  5.88014747
 11.76029494 11.76029494 11.76029494  5.88014747  5.88014747  5.88014747
 11.76029494 11.76029494  0.        ]
original epr
4.184572507199632
index of max error on path
831
maximum_predicted_value
0.2645168602466583
MAXIMUM LAYER WEIGHTS

tensor(0.2230, grad_fn=<MaxBackward1>)

tensor(0.1686, grad_fn=<MaxBackward1>)
random,nn steps
6
899
TOTAL REWARD
14.312699912896282
ave loss
0.1480281754422583
max_loss
0.6961132287979126
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.1358661464635451, 'num_bad_epochs': 13, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 164}
TOTALPREDICTION
tensor([10.1073], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
344
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.64       1.
 1.         0.00013292 1.         0.00000585 0.00013292 1.
 0.00000374 1.         0.        ]
[11.75170421 11.75170421 11.75170421 11.75170421 11.75170421 11.75170421
 11.75170421 11.75170421 11.75170421 11.75170421  5.8758521   5.8758521
 11.75170421 11.75170421 11.75170421  5.8758521   5.8758521   5.8758521
 11.75170421 11.75170421  0.        ]
original epr
4.18112880068376
index of max error on path
262
maximum_predicted_value
0.2581065595149994
MAXIMUM LAYER WEIGHTS

tensor(0.2230, grad_fn=<MaxBackward1>)

tensor(0.1686, grad_fn=<MaxBackward1>)
random,nn steps
2
342
TOTAL REWARD
14.309804747700214
ave loss
0.1934178416660532
max_loss
0.755914032459259
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.1358661464635451, 'num_bad_epochs': 14, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 165}
TOTALPREDICTION
tensor([0.0413], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
381
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.64       1.
 1.         0.00013292 1.         0.00000585 0.00013292 1.
 0.00000374 1.         0.        ]
[11.75170421 11.75170421 11.75170421 11.75170421 11.75170421 11.75170421
 11.75170421 11.75170421 11.75170421 11.75170421  5.8758521   5.8758521
 11.75170421 11.75170421 11.75170421  5.8758521   5.8758521   5.8758521
 11.75170421 11.75170421  0.        ]
original epr
4.181128800683763
index of max error on path
299
maximum_predicted_value
0.25792914628982544
MAXIMUM LAYER WEIGHTS

tensor(0.2230, grad_fn=<MaxBackward1>)

tensor(0.1686, grad_fn=<MaxBackward1>)
random,nn steps
2
379
TOTAL REWARD
14.309804747700186
ave loss
0.18666677764590017
max_loss
0.756482720375061
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.1358661464635451, 'num_bad_epochs': 15, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 166}
TOTALPREDICTION
tensor([0.6786], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
282
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.00590296 0.8        1.
 1.         0.00922337 1.         0.00002788 0.00013292 1.
 0.00000374 1.         0.        ]
[11.75440824 11.75440824 11.75440824 11.75440824 11.75440824 11.75440824
 11.75440824 11.75440824 11.75440824 11.75440824  5.87720412  5.87720412
 11.75440824 11.75440824 11.75440824  5.87720412  5.87720412  5.87720412
 11.75440824 11.75440824 -0.        ]
original epr
4.181594479363707
index of max error on path
203
maximum_predicted_value
0.2525193393230438
MAXIMUM LAYER WEIGHTS

tensor(0.2231, grad_fn=<MaxBackward1>)

tensor(0.1686, grad_fn=<MaxBackward1>)
random,nn steps
2
280
TOTAL REWARD
14.383710548513323
ave loss
0.21525944213230983
max_loss
0.7519236207008362
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.1358661464635451, 'num_bad_epochs': 16, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 167}
TOTALPREDICTION
tensor([0.9543], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
213
Final STATE
[1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       1.       1.       1.       1.       1.       0.
 1.       1.       0.       1.       0.022518]
[11.80818899 11.80818899 11.80818899 11.80818899 11.80818899 11.80818899
 11.80818899 11.80818899 11.80818899 11.80818899  5.90409449  5.90409449
 11.80818899 11.80818899 11.80818899  5.90409449  5.90409449  5.90409449
 11.80818899 11.80818899  0.        ]
original epr
4.173008273156482
index of max error on path
18
maximum_predicted_value
0.18230678141117096
MAXIMUM LAYER WEIGHTS

tensor(0.2231, grad_fn=<MaxBackward1>)

tensor(0.1689, grad_fn=<MaxBackward1>)
random,nn steps
1
212
TOTAL REWARD
14.581995827355312
ave loss
0.2568047836492879
max_loss
0.4162484407424927
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.1358661464635451, 'num_bad_epochs': 17, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 168}
TOTALPREDICTION
tensor([3.4220], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
307
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.64       1.
 1.         0.00016615 1.         0.00000585 0.00013292 1.
 0.00000299 1.         0.        ]
[11.75170421 11.75170421 11.75170421 11.75170421 11.75170421 11.75170421
 11.75170421 11.75170421 11.75170421 11.75170421  5.8758521   5.8758521
 11.75170421 11.75170421 11.75170421  5.8758521   5.8758521   5.8758521
 11.75170421 11.75170421 -0.        ]
original epr
4.18112880073663
index of max error on path
225
maximum_predicted_value
0.2617352604866028
MAXIMUM LAYER WEIGHTS

tensor(0.2232, grad_fn=<MaxBackward1>)

tensor(0.1689, grad_fn=<MaxBackward1>)
random,nn steps
3
304
TOTAL REWARD
14.309786991165145
ave loss
0.20183075031308087
max_loss
0.753757894039154
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.1358661464635451, 'num_bad_epochs': 18, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 169}
TOTALPREDICTION
tensor([0.5931], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
458
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.64       1.
 1.         0.00154743 1.         0.00000913 0.2097152  0.00025961
 0.0000004  1.         0.        ]
[11.76072371 11.76072371 11.76072371 11.76072371 11.76072371 11.76072371
 11.76072371 11.76072371 11.76072371 11.76072371  5.88036186  5.88036186
 11.76072371 11.76072371 11.76072371  5.88036186  5.88036186  5.88036186
 11.76072371 11.76072371  0.        ]
original epr
4.184898765007805
index of max error on path
379
maximum_predicted_value
0.18787965178489685
MAXIMUM LAYER WEIGHTS

tensor(0.2231, grad_fn=<MaxBackward1>)

tensor(0.1688, grad_fn=<MaxBackward1>)
random,nn steps
5
453
TOTAL REWARD
14.429986355944825
ave loss
0.16451749142958869
max_loss
0.8160547614097595
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.1358661464635451, 'num_bad_epochs': 19, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 170}
TOTALPREDICTION
tensor([1.8471], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
213
Final STATE
[1.       1.       1.       1.       1.       1.       1.       1.
 1.       1.       0.8      0.8      1.       1.       1.       0.
 1.       1.       0.       0.8      0.022518]
[11.81655012 11.81655012 11.81655012 11.81655012 11.81655012 11.81655012
 11.81655012 11.81655012 11.81655012 11.81655012  5.90827506  5.90827506
 11.81655012 11.81655012 11.81655012  5.90827506  5.90827506  5.90827506
 11.81655012 11.81655012  0.        ]
original epr
4.17672601316807
index of max error on path
18
maximum_predicted_value
0.18817950785160065
MAXIMUM LAYER WEIGHTS

tensor(0.2232, grad_fn=<MaxBackward1>)

tensor(0.1691, grad_fn=<MaxBackward1>)
random,nn steps
4
209
TOTAL REWARD
14.343713327132386
ave loss
0.2500320166314432
max_loss
0.41464486718177795
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.1358661464635451, 'num_bad_epochs': 20, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 171}
TOTALPREDICTION
tensor([3.4336], grad_fn=<AddBackward0>)
index of max error on path
86
maximum_predicted_value
0.26547864079475403
MAXIMUM LAYER WEIGHTS

tensor(0.2232, grad_fn=<MaxBackward1>)

tensor(0.1678, grad_fn=<MaxBackward1>)
random,nn steps
2
998
TOTAL REWARD
6.367232025155275
ave loss
0.12660372451546803
max_loss
0.48768094182014465
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.12660372451546803, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 172}
TOTALPREDICTION
tensor([14.2062], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
747
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.00000374 1.         1.
 1.         1.         1.         0.00002788 0.00016615 0.8
 0.00005445 1.         0.        ]
[11.82578696 11.82578696 11.82578696 11.82578696 11.82578696 11.82578696
 11.82578696 11.82578696 11.82578696 11.82578696  5.91289348  5.91289348
 11.82578696 11.82578696 11.82578696  5.91289348  5.91289348  5.91289348
 11.82578696 11.82578696  0.        ]
original epr
4.180625883915326
index of max error on path
668
maximum_predicted_value
0.17844398319721222
MAXIMUM LAYER WEIGHTS

tensor(0.2232, grad_fn=<MaxBackward1>)

tensor(0.1671, grad_fn=<MaxBackward1>)
random,nn steps
3
744
TOTAL REWARD
14.34705083560046
ave loss
0.13459483937047412
max_loss
0.7936461567878723
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.12660372451546803, 'num_bad_epochs': 1, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 173}
TOTALPREDICTION
tensor([7.1625], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
610
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.64       1.
 1.         0.00013292 1.         0.00000585 0.00013292 1.
 0.00000374 1.         0.        ]
[11.75170421 11.75170421 11.75170421 11.75170421 11.75170421 11.75170421
 11.75170421 11.75170421 11.75170421 11.75170421  5.8758521   5.8758521
 11.75170421 11.75170421 11.75170421  5.8758521   5.8758521   5.8758521
 11.75170421 11.75170421  0.        ]
original epr
4.181128800683762
index of max error on path
528
maximum_predicted_value
0.23305469751358032
MAXIMUM LAYER WEIGHTS

tensor(0.2233, grad_fn=<MaxBackward1>)

tensor(0.1667, grad_fn=<MaxBackward1>)
random,nn steps
3
607
TOTAL REWARD
14.309804747700186
ave loss
0.1556593622035179
max_loss
0.7712976932525635
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.12660372451546803, 'num_bad_epochs': 2, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 174}
TOTALPREDICTION
tensor([4.4816], grad_fn=<AddBackward0>)
RESET epsilon ANNEALING
0.00390625
**************************************Path Length ds<0******************************************
298
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.64       1.
 1.         0.00013292 0.8        0.00000585 0.00013292 1.
 0.00000468 1.         0.        ]
[11.7534486 11.7534486 11.7534486 11.7534486 11.7534486 11.7534486
 11.7534486 11.7534486 11.7534486 11.7534486  5.8767243  5.8767243
 11.7534486 11.7534486 11.7534486  5.8767243  5.8767243  5.8767243
 11.7534486 11.7534486 -0.       ]
original epr
4.181749583231331
index of max error on path
216
maximum_predicted_value
0.22410883009433746
MAXIMUM LAYER WEIGHTS

tensor(0.2233, grad_fn=<MaxBackward1>)

tensor(0.1668, grad_fn=<MaxBackward1>)
random,nn steps
2
296
TOTAL REWARD
14.2090568948484
ave loss
0.20625854336700383
max_loss
0.7715456485748291
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.12660372451546803, 'num_bad_epochs': 3, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 175}
TOTALPREDICTION
tensor([1.0348], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
788
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.0073787  0.8        1.
 0.8        0.01152922 0.8        0.00002788 0.00013292 1.
 0.00000374 1.         0.        ]
[11.75789349 11.75789349 11.75789349 11.75789349 11.75789349 11.75789349
 11.75789349 11.75789349 11.75789349 11.75789349  5.87894675  5.87894675
 11.75789349 11.75789349 11.75789349  5.87894675  5.87894675  5.87894675
 11.75789349 11.75789349  0.        ]
original epr
4.182835800743777
index of max error on path
709
maximum_predicted_value
0.22324591875076294
MAXIMUM LAYER WEIGHTS

tensor(0.2233, grad_fn=<MaxBackward1>)

tensor(0.1661, grad_fn=<MaxBackward1>)
random,nn steps
8
780
TOTAL REWARD
14.259669627246046
ave loss
0.14219490812410635
max_loss
0.7723530530929565
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.12660372451546803, 'num_bad_epochs': 4, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 176}
TOTALPREDICTION
tensor([7.7103], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
682
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.64       1.
 1.         0.00013292 1.         0.00000585 0.00013292 1.
 0.00000374 1.         0.        ]
[11.75170421 11.75170421 11.75170421 11.75170421 11.75170421 11.75170421
 11.75170421 11.75170421 11.75170421 11.75170421  5.8758521   5.8758521
 11.75170421 11.75170421 11.75170421  5.8758521   5.8758521   5.8758521
 11.75170421 11.75170421  0.        ]
original epr
4.181128800683763
index of max error on path
600
maximum_predicted_value
0.2156331092119217
MAXIMUM LAYER WEIGHTS

tensor(0.2233, grad_fn=<MaxBackward1>)

tensor(0.1656, grad_fn=<MaxBackward1>)
random,nn steps
1
681
TOTAL REWARD
14.309804747700186
ave loss
0.1463149820462612
max_loss
0.7805104851722717
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.12660372451546803, 'num_bad_epochs': 5, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 177}
TOTALPREDICTION
tensor([5.6946], grad_fn=<AddBackward0>)
index of max error on path
983
maximum_predicted_value
0.20657941699028015
MAXIMUM LAYER WEIGHTS

tensor(0.2233, grad_fn=<MaxBackward1>)

tensor(0.1643, grad_fn=<MaxBackward1>)
random,nn steps
4
996
TOTAL REWARD
9.007839399935616
ave loss
0.11155757407409761
max_loss
0.7908573746681213
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.11155757407409761, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 178}
TOTALPREDICTION
tensor([13.5160], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
686
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.64       1.
 1.         0.00013292 1.         0.00000585 0.00013292 1.
 0.00000374 1.         0.        ]
[11.75170421 11.75170421 11.75170421 11.75170421 11.75170421 11.75170421
 11.75170421 11.75170421 11.75170421 11.75170421  5.8758521   5.8758521
 11.75170421 11.75170421 11.75170421  5.8758521   5.8758521   5.8758521
 11.75170421 11.75170421  0.        ]
original epr
4.181128800683763
index of max error on path
604
maximum_predicted_value
0.18635287880897522
MAXIMUM LAYER WEIGHTS

tensor(0.2233, grad_fn=<MaxBackward1>)

tensor(0.1638, grad_fn=<MaxBackward1>)
random,nn steps
2
684
TOTAL REWARD
14.309804747700182
ave loss
0.1395920790275749
max_loss
0.7944427132606506
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.11155757407409761, 'num_bad_epochs': 1, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 179}
TOTALPREDICTION
tensor([5.5456], grad_fn=<AddBackward0>)
index of max error on path
88
maximum_predicted_value
0.17920152842998505
MAXIMUM LAYER WEIGHTS

tensor(0.2234, grad_fn=<MaxBackward1>)

tensor(0.1627, grad_fn=<MaxBackward1>)
random,nn steps
2
998
TOTAL REWARD
6.350527347978598
ave loss
0.093193675021655
max_loss
0.527056872844696
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.093193675021655, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 180}
TOTALPREDICTION
tensor([13.4617], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
891
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.64       1.
 1.         0.00013292 1.         0.00000585 0.00013292 1.
 0.00000374 1.         0.        ]
[11.75170421 11.75170421 11.75170421 11.75170421 11.75170421 11.75170421
 11.75170421 11.75170421 11.75170421 11.75170421  5.8758521   5.8758521
 11.75170421 11.75170421 11.75170421  5.8758521   5.8758521   5.8758521
 11.75170421 11.75170421  0.        ]
original epr
4.181128800683763
index of max error on path
809
maximum_predicted_value
0.156734898686409
MAXIMUM LAYER WEIGHTS

tensor(0.2234, grad_fn=<MaxBackward1>)

tensor(0.1619, grad_fn=<MaxBackward1>)
random,nn steps
1
890
TOTAL REWARD
14.30980474770019
ave loss
0.11797939482804568
max_loss
0.8111139535903931
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.093193675021655, 'num_bad_epochs': 1, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 181}
TOTALPREDICTION
tensor([9.1184], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
918
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.00590296 0.64       1.
 1.         0.00922337 1.         0.00003484 0.00013292 1.
 0.00000374 1.         0.        ]
[11.75658059 11.75658059 11.75658059 11.75658059 11.75658059 11.75658059
 11.75658059 11.75658059 11.75658059 11.75658059  5.87829029  5.87829029
 11.75658059 11.75658059 11.75658059  5.87829029  5.87829029  5.87829029
 11.75658059 11.75658059  0.        ]
original epr
4.182541383962294
index of max error on path
840
maximum_predicted_value
0.14316214621067047
MAXIMUM LAYER WEIGHTS

tensor(0.2234, grad_fn=<MaxBackward1>)

tensor(0.1611, grad_fn=<MaxBackward1>)
random,nn steps
4
914
TOTAL REWARD
14.367027764205169
ave loss
0.11387765154847165
max_loss
0.8179616332054138
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.093193675021655, 'num_bad_epochs': 2, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 182}
TOTALPREDICTION
tensor([9.3403], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
222
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         0.00013292 1.         0.00000016 0.00377789 1.
 0.00000374 1.         0.00099035]
[11.82248579 11.82248579 11.82248579 11.82248579 11.82248579 11.82248579
 11.82248579 11.82248579 11.82248579 11.82248579  5.91124289  5.91124289
 11.82248579 11.82248579 11.82248579  5.91124289  5.91124289  5.91124289
 11.82248579 11.82248579  0.        ]
original epr
4.179033856782446
index of max error on path
94
maximum_predicted_value
0.09032939374446869
MAXIMUM LAYER WEIGHTS

tensor(0.2235, grad_fn=<MaxBackward1>)

tensor(0.1613, grad_fn=<MaxBackward1>)
random,nn steps
1
221
TOTAL REWARD
14.33260155218143
ave loss
0.28032732079107614
max_loss
0.5360886454582214
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.093193675021655, 'num_bad_epochs': 3, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 183}
TOTALPREDICTION
tensor([3.5680], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
813
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.64       1.
 1.         0.00013292 1.         0.00000585 0.00013292 1.
 0.00000374 1.         0.        ]
[11.75170421 11.75170421 11.75170421 11.75170421 11.75170421 11.75170421
 11.75170421 11.75170421 11.75170421 11.75170421  5.8758521   5.8758521
 11.75170421 11.75170421 11.75170421  5.8758521   5.8758521   5.8758521
 11.75170421 11.75170421  0.        ]
original epr
4.181128800683762
index of max error on path
731
maximum_predicted_value
0.13379400968551636
MAXIMUM LAYER WEIGHTS

tensor(0.2235, grad_fn=<MaxBackward1>)

tensor(0.1607, grad_fn=<MaxBackward1>)
random,nn steps
2
811
TOTAL REWARD
14.309804747700193
ave loss
0.11724368300114794
max_loss
0.8210557103157043
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.093193675021655, 'num_bad_epochs': 4, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 184}
TOTALPREDICTION
tensor([7.2478], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
365
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.64       1.
 1.         0.00013292 1.         0.00000585 0.00013292 1.
 0.00000374 1.         0.        ]
[11.75170421 11.75170421 11.75170421 11.75170421 11.75170421 11.75170421
 11.75170421 11.75170421 11.75170421 11.75170421  5.8758521   5.8758521
 11.75170421 11.75170421 11.75170421  5.8758521   5.8758521   5.8758521
 11.75170421 11.75170421  0.        ]
original epr
4.181128800683764
index of max error on path
283
maximum_predicted_value
0.1224726140499115
MAXIMUM LAYER WEIGHTS

tensor(0.2235, grad_fn=<MaxBackward1>)

tensor(0.1607, grad_fn=<MaxBackward1>)
random,nn steps
1
364
TOTAL REWARD
14.309804747700193
ave loss
0.1901858818066651
max_loss
0.8207431435585022
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.093193675021655, 'num_bad_epochs': 5, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 185}
TOTALPREDICTION
tensor([0.6336], grad_fn=<AddBackward0>)
index of max error on path
929
maximum_predicted_value
0.1231667697429657
MAXIMUM LAYER WEIGHTS

tensor(0.2235, grad_fn=<MaxBackward1>)

tensor(0.1598, grad_fn=<MaxBackward1>)
random,nn steps
3
997
TOTAL REWARD
13.193463898202165
ave loss
0.09790421428729841
max_loss
0.828641951084137
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.093193675021655, 'num_bad_epochs': 6, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 186}
TOTALPREDICTION
tensor([10.9360], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
243
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.8        0.2097152
 1.         1.         1.         0.00000192 0.00016615 1.
 0.         0.8        0.00003484]
[11.75542239 11.75542239 11.75542239 11.75542239 11.75542239 11.75542239
 11.75542239 11.75542239 11.75542239 11.75542239  5.87771119  5.87771119
 11.75542239 11.75542239 11.75542239  5.87771119  5.87771119  5.87771119
 11.75542239 11.75542239  0.        ]
original epr
4.183159271785384
index of max error on path
158
maximum_predicted_value
0.09881402552127838
MAXIMUM LAYER WEIGHTS

tensor(0.2236, grad_fn=<MaxBackward1>)

tensor(0.1600, grad_fn=<MaxBackward1>)
random,nn steps
3
240
TOTAL REWARD
14.242008232137719
ave loss
0.26202869957979813
max_loss
0.8248093128204346
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.093193675021655, 'num_bad_epochs': 7, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 187}
TOTALPREDICTION
tensor([2.9993], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
566
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.64       1.
 0.8        0.00016615 1.         0.00000585 0.00013292 1.
 0.00000374 1.         0.        ]
[11.7534486 11.7534486 11.7534486 11.7534486 11.7534486 11.7534486
 11.7534486 11.7534486 11.7534486 11.7534486  5.8767243  5.8767243
 11.7534486 11.7534486 11.7534486  5.8767243  5.8767243  5.8767243
 11.7534486 11.7534486  0.       ]
original epr
4.181749583286533
index of max error on path
484
maximum_predicted_value
0.11042502522468567
MAXIMUM LAYER WEIGHTS

tensor(0.2236, grad_fn=<MaxBackward1>)

tensor(0.1597, grad_fn=<MaxBackward1>)
random,nn steps
2
564
TOTAL REWARD
14.236338376815652
ave loss
0.13960072263259138
max_loss
0.8290608525276184
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.093193675021655, 'num_bad_epochs': 8, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 188}
TOTALPREDICTION
tensor([2.8643], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
543
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.64       1.
 1.         0.00013292 1.         0.00000585 0.00013292 1.
 0.00000374 1.         0.        ]
[11.75170421 11.75170421 11.75170421 11.75170421 11.75170421 11.75170421
 11.75170421 11.75170421 11.75170421 11.75170421  5.8758521   5.8758521
 11.75170421 11.75170421 11.75170421  5.8758521   5.8758521   5.8758521
 11.75170421 11.75170421  0.        ]
original epr
4.181128800683762
index of max error on path
461
maximum_predicted_value
0.10583814978599548
MAXIMUM LAYER WEIGHTS

tensor(0.2236, grad_fn=<MaxBackward1>)

tensor(0.1595, grad_fn=<MaxBackward1>)
random,nn steps
4
539
TOTAL REWARD
14.30980474770019
ave loss
0.14372788986420984
max_loss
0.8309627771377563
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.093193675021655, 'num_bad_epochs': 9, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 189}
TOTALPREDICTION
tensor([2.4169], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
449
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.512      1.
 1.         0.00013292 1.         0.00000585 0.00016615 1.
 0.00000374 1.         0.        ]
[11.75311757 11.75311757 11.75311757 11.75311757 11.75311757 11.75311757
 11.75311757 11.75311757 11.75311757 11.75311757  5.87655879  5.87655879
 11.75311757 11.75311757 11.75311757  5.87655879  5.87655879  5.87655879
 11.75311757 11.75311757  0.        ]
original epr
4.181690541514117
index of max error on path
367
maximum_predicted_value
0.10355912148952484
MAXIMUM LAYER WEIGHTS

tensor(0.2237, grad_fn=<MaxBackward1>)

tensor(0.1594, grad_fn=<MaxBackward1>)
random,nn steps
1
448
TOTAL REWARD
14.308365147291854
ave loss
0.16395911832810908
max_loss
0.830854058265686
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.093193675021655, 'num_bad_epochs': 10, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 190}
TOTALPREDICTION
tensor([0.7375], grad_fn=<AddBackward0>)
index of max error on path
91
maximum_predicted_value
0.09983380138874054
MAXIMUM LAYER WEIGHTS

tensor(0.2237, grad_fn=<MaxBackward1>)

tensor(0.1582, grad_fn=<MaxBackward1>)
random,nn steps
2
998
TOTAL REWARD
6.328102038950718
ave loss
0.06358162206995427
max_loss
0.5606542229652405
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.06358162206995427, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 191}
TOTALPREDICTION
tensor([13.1471], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
774
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.262144   0.8
 1.         1.         1.         0.00000153 0.00016615 1.
 0.         1.         0.        ]
[11.75343604 11.75343604 11.75343604 11.75343604 11.75343604 11.75343604
 11.75343604 11.75343604 11.75343604 11.75343604  5.87671802  5.87671802
 11.75343604 11.75343604 11.75343604  5.87671802  5.87671802  5.87671802
 11.75343604 11.75343604  0.        ]
original epr
4.182479623485743
index of max error on path
689
maximum_predicted_value
0.07419343292713165
MAXIMUM LAYER WEIGHTS

tensor(0.2237, grad_fn=<MaxBackward1>)

tensor(0.1576, grad_fn=<MaxBackward1>)
random,nn steps
2
772
TOTAL REWARD
14.327182442048608
ave loss
0.10681059476209549
max_loss
0.8487985134124756
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.06358162206995427, 'num_bad_epochs': 1, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 192}
TOTALPREDICTION
tensor([6.5593], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
405
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.262144   0.8
 1.         1.         1.         0.00000153 0.00016615 1.
 0.         1.         0.        ]
[11.75343604 11.75343604 11.75343604 11.75343604 11.75343604 11.75343604
 11.75343604 11.75343604 11.75343604 11.75343604  5.87671802  5.87671802
 11.75343604 11.75343604 11.75343604  5.87671802  5.87671802  5.87671802
 11.75343604 11.75343604  0.        ]
original epr
4.182479623485743
index of max error on path
320
maximum_predicted_value
0.06480628252029419
MAXIMUM LAYER WEIGHTS

tensor(0.2238, grad_fn=<MaxBackward1>)

tensor(0.1576, grad_fn=<MaxBackward1>)
random,nn steps
1
404
TOTAL REWARD
14.327182442048608
ave loss
0.17669855742312876
max_loss
0.8486141562461853
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.06358162206995427, 'num_bad_epochs': 2, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 193}
TOTALPREDICTION
tensor([0.4468], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
214
Final STATE
[1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.        1.        1.        0.        1.        0.0180144]
[11.80818899 11.80818899 11.80818899 11.80818899 11.80818899 11.80818899
 11.80818899 11.80818899 11.80818899 11.80818899  5.90409449  5.90409449
 11.80818899 11.80818899 11.80818899  5.90409449  5.90409449  5.90409449
 11.80818899 11.80818899  0.        ]
original epr
4.1731869599082225
index of max error on path
208
maximum_predicted_value
0.003448653966188431
MAXIMUM LAYER WEIGHTS

tensor(0.2239, grad_fn=<MaxBackward1>)

tensor(0.1579, grad_fn=<MaxBackward1>)
random,nn steps
2
212
TOTAL REWARD
14.58319866754988
ave loss
0.33581026848927836
max_loss
0.5474448800086975
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.06358162206995427, 'num_bad_epochs': 3, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 194}
TOTALPREDICTION
tensor([3.9226], grad_fn=<AddBackward0>)
index of max error on path
93
maximum_predicted_value
0.07141898572444916
MAXIMUM LAYER WEIGHTS

tensor(0.2239, grad_fn=<MaxBackward1>)

tensor(0.1567, grad_fn=<MaxBackward1>)
random,nn steps
3
997
TOTAL REWARD
6.268103627748925
ave loss
0.05254260134419904
max_loss
0.5676309466362
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.05254260134419904, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 195}
TOTALPREDICTION
tensor([12.9552], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
643
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.2097152  0.8
 1.         1.         1.         0.00000192 0.00016615 1.
 0.         1.         0.        ]
[11.75367881 11.75367881 11.75367881 11.75367881 11.75367881 11.75367881
 11.75367881 11.75367881 11.75367881 11.75367881  5.8768394   5.8768394
 11.75367881 11.75367881 11.75367881  5.8768394   5.8768394   5.8768394
 11.75367881 11.75367881  0.        ]
original epr
4.182539956659983
index of max error on path
558
maximum_predicted_value
0.052422620356082916
MAXIMUM LAYER WEIGHTS

tensor(0.2239, grad_fn=<MaxBackward1>)

tensor(0.1563, grad_fn=<MaxBackward1>)
random,nn steps
2
641
TOTAL REWARD
14.279444951750571
ave loss
0.11892009581385606
max_loss
0.8516255021095276
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.05254260134419904, 'num_bad_epochs': 1, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 196}
TOTALPREDICTION
tensor([3.8512], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
274
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.262144   0.8
 1.         1.         1.         0.00000153 0.00016615 1.
 0.         1.         0.00000003]
[11.75343604 11.75343604 11.75343604 11.75343604 11.75343604 11.75343604
 11.75343604 11.75343604 11.75343604 11.75343604  5.87671802  5.87671802
 11.75343604 11.75343604 11.75343604  5.87671802  5.87671802  5.87671802
 11.75343604 11.75343604  0.        ]
original epr
4.182479622102054
index of max error on path
189
maximum_predicted_value
0.045750368386507034
MAXIMUM LAYER WEIGHTS

tensor(0.2240, grad_fn=<MaxBackward1>)

tensor(0.1565, grad_fn=<MaxBackward1>)
random,nn steps
2
272
TOTAL REWARD
14.327182441910239
ave loss
0.2525833964901874
max_loss
0.856173038482666
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.05254260134419904, 'num_bad_epochs': 2, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 197}
TOTALPREDICTION
tensor([3.1635], grad_fn=<AddBackward0>)
**************************************Path Length ds<0******************************************
214
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.00000032 1.
 0.00000003 1.         1.         0.0000004  1.         1.
 1.         1.         0.4096    ]
[11.81762813 11.81762813 11.81762813 11.81762813 11.81762813 11.81762813
 11.81762813 11.81762813 11.81762813 11.81762813  5.90881407  5.90881407
 11.81762813 11.81762813 11.81762813  5.90881407  5.90881407  5.90881407
 11.81762813 11.81762813  0.        ]
original epr
4.161460326209692
index of max error on path
208
maximum_predicted_value
0
MAXIMUM LAYER WEIGHTS

tensor(0.2241, grad_fn=<MaxBackward1>)

tensor(0.1567, grad_fn=<MaxBackward1>)
random,nn steps
3
211
TOTAL REWARD
14.63385284852507
ave loss
0.3831608033625879
max_loss
0.7253787517547607
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.05254260134419904, 'num_bad_epochs': 3, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 198}
TOTALPREDICTION
tensor([3.8564], grad_fn=<AddBackward0>)
index of max error on path
93
maximum_predicted_value
0.05484134703874588
MAXIMUM LAYER WEIGHTS

tensor(0.2241, grad_fn=<MaxBackward1>)

tensor(0.1555, grad_fn=<MaxBackward1>)
random,nn steps
1
999
TOTAL REWARD
6.366566755414436
ave loss
0.04730055538759609
max_loss
0.5775963068008423
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.04730055538759609, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 199}
TOTALPREDICTION
tensor([12.6353], grad_fn=<AddBackward0>)
RESET epsilon ANNEALING
0.001953125
**************************************Path Length ds<0******************************************
303
Final STATE
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.262144   0.8
 1.         1.         1.         0.00000153 0.00016615 1.
 0.         1.         0.        ]
[11.75343604 11.75343604 11.75343604 11.75343604 11.75343604 11.75343604
 11.75343604 11.75343604 11.75343604 11.75343604  5.87671802  5.87671802
 11.75343604 11.75343604 11.75343604  5.87671802  5.87671802  5.87671802
 11.75343604 11.75343604 -0.        ]
original epr
4.182479623483605
index of max error on path
218
maximum_predicted_value
0.0356680229306221
MAXIMUM LAYER WEIGHTS

tensor(0.2242, grad_fn=<MaxBackward1>)

tensor(0.1557, grad_fn=<MaxBackward1>)
random,nn steps
1
302
TOTAL REWARD
14.327182442048425
ave loss
0.23252979368309523
max_loss
0.8613095283508301
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.04730055538759609, 'num_bad_epochs': 1, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 200}
TOTALPREDICTION
tensor([2.5210], grad_fn=<AddBackward0>)
index of max error on path
94
maximum_predicted_value
0.03664231672883034
MAXIMUM LAYER WEIGHTS

tensor(0.2242, grad_fn=<MaxBackward1>)

tensor(0.1546, grad_fn=<MaxBackward1>)
random,nn steps
3
997
TOTAL REWARD
6.33672187373843
ave loss
0.040716118396648286
max_loss
0.5843726992607117
<bound method Optimizer.state_dict of SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)>
{'factor': 0.1, 'min_lrs': [1e-10], 'patience': 500, 'verbose': True, 'cooldown': 10, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 1e-05, 'threshold_mode': 'rel', 'best': 0.040716118396648286, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 201}
TOTALPREDICTION
tensor([12.2369], grad_fn=<AddBackward0>)
value_tau
tensor([0.], grad_fn=<AddBackward0>)
value_tau_n
tensor([0.], grad_fn=<AddBackward0>)
estimate_value
tensor([0.])
loss
tensor(0., grad_fn=<SqrtBackward>)
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.10179283449242149
reward_vec[i]
0.10176943037076214
reward_vec[i]
0.10173949218615164
reward_vec[i]
0.10170315156486609
reward_vec[i]
0.10166019056974918
reward_vec[i]
0.10161011808844123
reward_vec[i]
0.1015522139591134
reward_vec[i]
0.10148555107291557
reward_vec[i]
0.10140900210830495
reward_vec[i]
0.10132123518193481
reward_vec[i]
0.10122070113643389
reward_vec[i]
0.10110561415697461
reward_vec[i]
0.10097392673603878
reward_vec[i]
0.10082329957523228
reward_vec[i]
0.10065106674839086
reward_vec[i]
0.10045419630675312
reward_vec[i]
0.1002292464569905
reward_vec[i]
0.09997231747405522
reward_vec[i]
0.09967899961922555
reward_vec[i]
0.09934431752389017
reward_vec[i]
0.09896267178124063
reward_vec[i]
0.0985277788754999
reward_vec[i]
0.09803261108842065
reward_vec[i]
0.09746933867597818
reward_vec[i]
0.0968292774178785
reward_vec[i]
0.09610284562576865
reward_vec[i]
0.09527953584993654
reward_vec[i]
0.0943479078332814
reward_vec[i]
0.09329561067968228
reward_vec[i]
0.09210944364221874
reward_vec[i]
0.09077546625233168
reward_vec[i]
0.08927916948859504
reward_vec[i]
0.08760572002573852
reward_vec[i]
0.08574028893239216
reward_vec[i]
0.0836684740489737
reward_vec[i]
0.08137682119782141
reward_vec[i]
0.07885344293372398
reward_vec[i]
0.076088724473788
reward_vec[i]
0.07307609483054733
reward_vec[i]
0.06981282758898288
reward_vec[i]
0.06630082146232041
reward_vec[i]
0.06254729770158463
reward_vec[i]
0.05856534221944898
reward_vec[i]
0.054374217807517056
reward_vec[i]
0.049999378678187156
reward_vec[i]
0.04547213729242472
reward_vec[i]
0.04082896178191575
reward_vec[i]
0.03611041867417342
reward_vec[i]
0.03135981527017151
reward_vec[i]
0.026621632564179265
reward_vec[i]
0.02193986649465529
reward_vec[i]
0.017356407424689024
reward_vec[i]
0.0129095826732879
reward_vec[i]
0.008632965664219228
reward_vec[i]
0.004554521970735692
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.00041250204369802645
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.14039832611818426
reward_vec[i]
0.13373106391010836
reward_vec[i]
0.12673708447553267
reward_vec[i]
0.11952586884936878
reward_vec[i]
0.11220605199291711
reward_vec[i]
0.10488373787125482
reward_vec[i]
0.09765935532020364
reward_vec[i]
0.09062401445494572
reward_vec[i]
0.08385616451039724
reward_vec[i]
0.07741912632675252
reward_vec[i]
0.07135980931920116
reward_vec[i]
0.06570866900353778
reward_vec[i]
0.0604807582182012
reward_vec[i]
0.05567759744960554
reward_vec[i]
0.05128954039519584
reward_vec[i]
0.04729832618594898
reward_vec[i]
0.04367956669411299
reward_vec[i]
0.04194925339674782
reward_vec[i]
0.04015450379580443
reward_vec[i]
0.03810869196677302
reward_vec[i]
0.03656887669569642
reward_vec[i]
0.034182567497950345
reward_vec[i]
0.032972960668022466
reward_vec[i]
0.03006936923486947
reward_vec[i]
0.029579963460911074
reward_vec[i]
0.026679235267746293
reward_vec[i]
0.025590540911267112
reward_vec[i]
0.023395727631744023
reward_vec[i]
0.021724583471474546
reward_vec[i]
0.020259608317932276
reward_vec[i]
0.018158961971884935
reward_vec[i]
0.01717715063859515
reward_vec[i]
0.015385478796453356
reward_vec[i]
0.01368479861783456
reward_vec[i]
0.012854296691639178
reward_vec[i]
0.011282230957778694
reward_vec[i]
0.009921013647097965
reward_vec[i]
0.008881221121708194
reward_vec[i]
0.007876329905268875
reward_vec[i]
0.006796522157781482
reward_vec[i]
0.005833659996724805
reward_vec[i]
0.0049713000090285675
reward_vec[i]
0.0041954538356314686
reward_vec[i]
0.002140882340587069
reward_vec[i]
0.001726639574176403
reward_vec[i]
0.00273134355676774
reward_vec[i]
0.0009713981893568757
reward_vec[i]
0.0006045139309875935
reward_vec[i]
0.0
reward_vec[i]
0.0011335990971375054
reward_vec[i]
0.00061161812217847
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.00014057254875154968
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
value_tau
tensor([0.], grad_fn=<AddBackward0>)
value_tau_n
tensor([0.], grad_fn=<AddBackward0>)
estimate_value
tensor([0.])
loss
tensor(0., grad_fn=<SqrtBackward>)
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.10179283449242149
reward_vec[i]
0.10176943037076214
reward_vec[i]
0.10173949218615164
reward_vec[i]
0.10170315156486609
reward_vec[i]
0.10166019056974918
reward_vec[i]
0.10161011808844123
reward_vec[i]
0.1015522139591134
reward_vec[i]
0.10148555107291557
reward_vec[i]
0.10140900210830495
reward_vec[i]
0.10132123518193481
reward_vec[i]
0.10122070113643389
reward_vec[i]
0.10110561415697461
reward_vec[i]
0.10097392673603878
reward_vec[i]
0.10082329957523228
reward_vec[i]
0.10065106674839086
reward_vec[i]
0.10045419630675312
reward_vec[i]
0.1002292464569905
reward_vec[i]
0.09997231747405522
reward_vec[i]
0.09967899961922555
reward_vec[i]
0.09934431752389017
reward_vec[i]
0.09896267178124063
reward_vec[i]
0.0985277788754999
reward_vec[i]
0.09803261108842065
reward_vec[i]
0.09746933867597818
reward_vec[i]
0.0968292774178785
reward_vec[i]
0.09610284562576865
reward_vec[i]
0.09527953584993654
reward_vec[i]
0.0943479078332814
reward_vec[i]
0.09329561067968228
reward_vec[i]
0.09210944364221874
reward_vec[i]
0.09077546625233168
reward_vec[i]
0.08927916948859504
reward_vec[i]
0.08760572002573852
reward_vec[i]
0.08574028893239216
reward_vec[i]
0.0836684740489737
reward_vec[i]
0.08137682119782141
reward_vec[i]
0.07885344293372398
reward_vec[i]
0.076088724473788
reward_vec[i]
0.07307609483054733
reward_vec[i]
0.06981282758898288
reward_vec[i]
0.06630082146232041
reward_vec[i]
0.06254729770158463
reward_vec[i]
0.05856534221944898
reward_vec[i]
0.054374217807517056
reward_vec[i]
0.049999378678187156
reward_vec[i]
0.04547213729242472
reward_vec[i]
0.04082896178191575
reward_vec[i]
0.03611041867417342
reward_vec[i]
0.03135981527017151
reward_vec[i]
0.026621632564179265
reward_vec[i]
0.02193986649465529
reward_vec[i]
0.017356407424689024
reward_vec[i]
0.0129095826732879
reward_vec[i]
0.008632965664219228
reward_vec[i]
0.004554521970735692
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.00041250204369802645
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.14039832611818426
reward_vec[i]
0.13373106391010836
reward_vec[i]
0.12673708447553267
reward_vec[i]
0.11952586884936878
reward_vec[i]
0.11220605199291711
reward_vec[i]
0.10488373787125482
reward_vec[i]
0.09765935532020364
reward_vec[i]
0.09062401445494572
reward_vec[i]
0.08385616451039724
reward_vec[i]
0.07741912632675252
reward_vec[i]
0.07135980931920116
reward_vec[i]
0.06570866900353778
reward_vec[i]
0.0604807582182012
reward_vec[i]
0.05567759744960554
reward_vec[i]
0.05128954039519584
reward_vec[i]
0.04729832618594898
reward_vec[i]
0.04367956669411299
reward_vec[i]
0.04194925339674782
reward_vec[i]
0.04015450379580443
reward_vec[i]
0.03810869196677302
reward_vec[i]
0.03656887669569642
reward_vec[i]
0.034182567497950345
reward_vec[i]
0.032972960668022466
reward_vec[i]
0.03006936923486947
reward_vec[i]
0.029579963460911074
reward_vec[i]
0.026679235267746293
reward_vec[i]
0.025590540911267112
reward_vec[i]
0.023395727631744023
reward_vec[i]
0.021724583471474546
reward_vec[i]
0.020259608317932276
reward_vec[i]
0.018158961971884935
reward_vec[i]
0.01717715063859515
reward_vec[i]
0.015385478796453356
reward_vec[i]
0.01368479861783456
reward_vec[i]
0.012854296691639178
reward_vec[i]
0.011282230957778694
reward_vec[i]
0.009921013647097965
reward_vec[i]
0.008881221121708194
reward_vec[i]
0.007876329905268875
reward_vec[i]
0.006796522157781482
reward_vec[i]
0.005833659996724805
reward_vec[i]
0.0049713000090285675
reward_vec[i]
0.0041954538356314686
reward_vec[i]
0.002140882340587069
reward_vec[i]
0.001726639574176403
reward_vec[i]
0.00273134355676774
reward_vec[i]
0.0009713981893568757
reward_vec[i]
0.0006045139309875935
reward_vec[i]
0.0
reward_vec[i]
0.0011335990971375054
reward_vec[i]
0.00061161812217847
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.00014057254875154968
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
reward_vec[i]
0.0
********************************************************************
********************************************************************
********************************************************************
begining state
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.262144   0.8
 1.         1.         1.         1.         0.00016615 1.
 0.0000005  1.         0.        ]
trial_states
[0.8        1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.262144   0.8
 1.         1.         1.         1.         0.00016615 1.
 0.0000005  1.         0.        ]
[1.         0.8        1.         1.         1.         1.
 1.         1.         1.         1.         0.262144   0.8
 1.         1.         1.         1.         0.00016615 1.
 0.0000005  1.         0.        ]
[1.         1.         0.8        1.         1.         1.
 1.         1.         1.         1.         0.262144   0.8
 1.         1.         1.         1.         0.00016615 1.
 0.0000005  1.         0.        ]
[1.         1.         1.         0.8        1.         1.
 1.         1.         1.         1.         0.262144   0.8
 1.         1.         1.         1.         0.00016615 1.
 0.0000005  1.         0.        ]
[1.         1.         1.         1.         0.8        1.
 1.         1.         1.         1.         0.262144   0.8
 1.         1.         1.         1.         0.00016615 1.
 0.0000005  1.         0.        ]
[1.         1.         1.         1.         1.         0.8
 1.         1.         1.         1.         0.262144   0.8
 1.         1.         1.         1.         0.00016615 1.
 0.0000005  1.         0.        ]
[1.         1.         1.         1.         1.         1.
 0.8        1.         1.         1.         0.262144   0.8
 1.         1.         1.         1.         0.00016615 1.
 0.0000005  1.         0.        ]
[1.         1.         1.         1.         1.         1.
 1.         0.8        1.         1.         0.262144   0.8
 1.         1.         1.         1.         0.00016615 1.
 0.0000005  1.         0.        ]
[1.         1.         1.         1.         1.         1.
 1.         1.         0.8        1.         0.262144   0.8
 1.         1.         1.         1.         0.00016615 1.
 0.0000005  1.         0.        ]
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.8        0.262144   0.8
 1.         1.         1.         1.         0.00016615 1.
 0.0000005  1.         0.        ]
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.2097152  0.8
 1.         1.         1.         1.         0.00016615 1.
 0.0000005  1.         0.        ]
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.262144   0.64
 1.         1.         1.         1.         0.00016615 1.
 0.0000005  1.         0.        ]
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.262144   0.8
 0.8        1.         1.         1.         0.00016615 1.
 0.0000005  1.         0.        ]
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.262144   0.8
 1.         0.8        1.         1.         0.00016615 1.
 0.0000005  1.         0.        ]
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.262144   0.8
 1.         1.         0.8        1.         0.00016615 1.
 0.0000005  1.         0.        ]
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.262144   0.8
 1.         1.         1.         0.8        0.00016615 1.
 0.0000005  1.         0.        ]
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.262144   0.8
 1.         1.         1.         1.         0.00013292 1.
 0.0000005  1.         0.        ]
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.262144   0.8
 1.         1.         1.         1.         0.00016615 0.8
 0.0000005  1.         0.        ]
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.262144   0.8
 1.         1.         1.         1.         0.00016615 1.
 0.0000004  1.         0.        ]
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.262144   0.8
 1.         1.         1.         1.         0.00016615 1.
 0.0000005  0.8        0.        ]
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.262144   0.8
 1.         1.         1.         1.         0.00016615 1.
 0.0000005  1.         0.        ]
log_metabolites
[-52.79518961 -39.41977766   5.32344458  15.59568778  13.14640101
   8.15460801  18.4687691   -0.71946363 -40.95430304 -39.160467
  13.23666835   9.69288284 -35.27597056  21.22746308 -52.84055602
   9.01637872 -43.2526997   -2.14847962 -36.9897114   14.57216388
  15.57013138  24.23250658  14.00151547  10.9649612   16.30410056
  12.72854979  10.81945361  14.26387973  15.57013138  16.30410056
  12.72854979  11.00578319  10.81945361  14.26387973  13.64484052
  24.23250658  14.64599747]
current_reward_vec
[-10. -10. -10. -10. -10. -10. -10. -10. -10. -10. -10. -10. -10. -10.
 -10.   0. -10. -10. -10. -10.   0.]
state_value_vec
[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan]
v_log_counts_matrix
[-52.75067104 -39.41341798   5.34236627  15.63363117  13.19079395
   8.23715984  18.58952401  -0.68779031 -40.9225041  -39.14138769
  13.33193981   9.76271504 -35.28233051  21.24005287 -52.8596356
   9.04173232 -43.28449891  -2.04044434 -37.03423024  14.62927645]
[-52.77848506 -39.44123201   5.34236627  15.63363117  13.19079395
   8.23715984  18.58952401  -0.68779031 -40.95031813 -39.16920172
  13.33193981   9.76271504 -35.31014454  21.24005287 -52.88744963
   9.04173232 -43.31231294  -2.04044434 -36.83953232  14.62927645]
[-52.80629908 -39.46904602   5.34236627  15.63363117  13.19079395
   8.23715984  18.58952401  -0.68779031 -40.97813214 -39.19701574
  13.33193981   9.76271504 -35.33795855  21.24005287 -52.91526365
   9.04173232 -43.11761501  -2.04044434 -36.86734633  14.62927645]
[-52.83411309 -39.49686003   5.34236627  15.63363117  13.19079395
   8.23715984  18.58952401  -0.68779031 -41.00594615 -39.22482974
  13.33193981   9.76271504 -35.36577256  21.24005287 -52.7205657
   9.04173232 -43.14542901  -2.04044434 -36.89516034  14.62927645]
[-52.86192708 -39.52467403   5.34236627  15.63363117  13.19079395
   8.23715984  18.58952401  -0.68779031 -41.03376015 -39.25264374
  13.33193981   9.76271504 -35.17107461  21.24005287 -52.7483797
   9.04173232 -43.17324301  -2.04044434 -36.92297434  14.62927645]
[-52.88974107 -39.32997607   5.34236627  15.63363117  13.19079395
   8.23715984  18.58952401  -0.68779031 -41.06157413 -39.28045773
  13.33193981   9.76271504 -35.1988886   21.24005287 -52.77619369
   9.04173232 -43.201057    -2.04044434 -36.95078832  14.62927645]
[-52.91755505 -39.35779005   5.34236627  15.63363117  13.19079395
   8.23715984  18.58952401  -0.68779031 -41.08938812 -39.08575976
  13.33193981   9.76271504 -35.22670258  21.24005287 -52.80400767
   9.04173232 -43.22887098  -2.04044434 -36.97860231  14.62927645]
[-52.94536903 -39.38560402   5.34236627  15.63363117  13.19079395
   8.23715984  18.58952401  -0.68779031 -40.89469014 -39.11357373
  13.33193981   9.76271504 -35.25451655  21.24005287 -52.83182164
   9.04173232 -43.25668495  -2.04044434 -37.00641628  14.62927645]
[-52.75067067 -39.41341761   5.34236627  15.63363117  12.968282
   8.01464789  18.36701206  -0.68779031 -40.92250373 -39.14138732
  13.10942786   9.54020309 -35.28233014  21.24005287 -52.85963523
   9.04173232 -43.28449854  -2.26295629 -37.03422987  14.4067645 ]
[-52.7506707  -39.41341764   5.34236627  15.63363117  13.19079395
   8.01464789  18.36701206  -0.68779031 -40.92250376 -39.14138735
  13.10942786   9.54020309 -35.28233017  21.24005287 -52.85963526
   9.04173232 -43.28449857  -2.26295629 -37.0342299   14.4067645 ]
[-52.7728842  -39.41659107   5.44441124  15.61469929  13.05715787
   8.08448369  18.4177856   -0.8150797  -40.93837057 -39.15090748
  13.17291697   9.61638558 -35.27915691  21.23377137 -52.85011531
   9.02908194 -43.26863193  -2.20583607 -37.01201656  14.48929368]
[-52.77302564 -39.41661127   5.22208648  15.61457874  13.05772379
   8.08492837  18.4181089   -0.81447337 -40.93847159 -39.15096808
  13.17332123   9.61687067 -35.27913669  21.23373137 -52.85005468
   9.02900139 -43.26853089  -2.20547235 -37.01187511  14.48981918]
[-52.75067083 -39.41341778   5.34236627  15.63363117  13.19079395
   8.23715984  18.36701206  -0.68779031 -40.92250389 -39.14138749
  13.10942786   9.76271504 -35.28233031  21.24005287 -52.8596354
   9.04173232 -43.28449871  -2.26295629 -37.03423003  14.62927645]
[-52.75067074 -39.41341768   5.34236627  15.63363117  13.19079395
   8.01464789  18.36701206  -0.68779031 -40.9225038  -39.14138739
  13.10942786   9.54020309 -35.28233021  21.24005287 -52.8596353
   9.04173232 -43.28449861  -2.26295629 -37.03422994  14.62927645]
[-52.75067078 -39.41341772   5.34236627  15.63363117  13.19079395
   8.01464789  18.36701206  -0.68779031 -40.92250384 -39.14138743
  13.10942786   9.76271504 -35.28233025  21.24005287 -52.85963535
   9.04173232 -43.28449866  -2.26295629 -37.03422998  14.62927645]
[-52.77311331 -39.41662375   5.22248768  15.39382326  13.05807479
   8.08520417  18.41830942  -0.8140973  -40.93853421 -39.15100563
  13.17357198   9.61717155 -35.27912411  21.01302586 -52.85001703
   8.80827072 -43.26846817  -2.20524677 -37.01178733  14.49014512]
[-52.77286695 -39.41658856   5.22136098  15.3915704   13.05708905
   8.08442961  18.41774628  -0.81515344 -40.93835823 -39.15090005
  13.1728678    9.61632659 -35.27915931  21.23377624 -52.85012263
   8.80594819 -43.26864416  -2.2058803  -37.01203371  14.48922977]
[-52.77311334 -39.41662377   5.22248768  15.39382326  13.05807479
   8.08520417  18.41830942  -0.8140973  -40.93853423 -39.15100566
  13.17357198   9.61717155 -35.27912413  21.23370656 -52.85001706
   9.02895143 -43.2684682   -2.20524677 -37.01178735  14.49014512]
[-52.75054453 -39.41339978   5.34241998  15.63373887  13.19091996
   8.23739416  18.36672322  -0.68770041 -40.92241369 -39.14133339
  13.33221024   9.76291326 -35.28234842  21.24008861 -52.85968962
   9.04180428 -43.28458903  -2.26328124 -37.03435646  14.62943856]
[-52.75067096 -39.41341791   5.34236627  15.63363117  13.19079395
   8.23715984  18.36701206  -0.68779031 -40.92250402 -39.14138762
  13.33193981   9.76271504 -35.28233043  21.24005287 -52.85963553
   9.04173232 -43.28449884  -2.04044434 -37.03423016  14.62927645]
[-52.79518961 -39.41977766   5.32344458  15.59568778  13.14640101
   8.15460801  18.4687691   -0.71946363 -40.95430304 -39.160467
  13.23666835   9.69288284 -35.27597056  21.22746308 -52.84055602
   9.01637872 -43.2526997   -2.14847962 -36.9897114   14.57216388]
KQ_f
[      29.81190399       23.86459136       23.86459136       23.86459136
       23.86459136       23.86459136       23.86459136       23.86459136
       23.86459136       23.86459136       45.46016919       14.95604278
       23.86459136       23.86459136       23.86459136       11.99471419
    71688.79486733       11.99471419 47439664.99200319       23.86459136
        1.01926276]
[      23.86459136       29.81190399       23.86459136       23.86459136
       23.86459136       23.86459136       23.86459136       23.86459136
       23.86459136       23.86459136       45.46016919       14.95604278
       23.86459136       23.86459136       23.86459136       11.99471419
    71688.79486733       11.99471419 47439664.99200319       23.86459136
        1.0480105 ]
[      23.86459136       23.86459136       29.81190399       23.86459136
       23.86459136       23.86459136       23.86459136       23.86459136
       23.86459136       23.86459136       45.46016919       14.95604278
       23.86459136       23.86459136       23.86459136       11.99471419
    71688.79486733       11.99471419 47439664.99200319       23.86459136
        1.07756905]
[      23.86459136       23.86459136       23.86459136       29.81190399
       23.86459136       23.86459136       23.86459136       23.86459136
       23.86459136       23.86459136       45.46016919       14.95604278
       23.86459136       23.86459136       23.86459136       11.99471419
    71688.79486733       11.99471419 47439664.99200319       23.86459136
        0.88692902]
[      23.86459136       23.86459136       23.86459136       23.86459136
       29.81190399       23.86459136       23.86459136       23.86459136
       23.86459136       23.86459136       45.46016919       14.95604278
       23.86459136       23.86459136       23.86459136       11.99471419
    71688.79486733       11.99471419 47439664.99200311       23.86459136
        0.91194434]
[      23.86459136       23.86459136       23.86459136       23.86459136
       23.86459136       29.81190399       23.86459136       23.86459136
       23.86459136       23.86459136       45.46016919       14.95604278
       23.86459136       23.86459136       23.86459136       11.99471419
    71688.79486733       11.99471419 47439664.99200319       23.86459136
        0.93766519]
[      23.86459136       23.86459136       23.86459136       23.86459136
       23.86459136       23.86459136       29.81190399       23.86459136
       23.86459136       23.86459136       45.46016919       14.95604278
       23.86459136       23.86459136       23.86459136       11.99471419
    71688.79486733       11.99471419 47439664.99200311       23.86459136
        0.96411147]
[      23.86459136       23.86459136       23.86459136       23.86459136
       23.86459136       23.86459136       23.86459136       29.81190399
       23.86459136       23.86459136       45.46016919       14.95604278
       23.86459136       23.86459136       23.86459136       11.99471419
    71688.79486733       11.99471419 47439664.99200319       23.86459136
        0.99130365]
[      23.86459136       23.86459136       23.86459136       23.86459136
       23.86459136       23.86459136       23.86459136       23.86459136
       29.81190399       23.86459136       45.46016919       14.95604278
       23.86459136       23.86459136       23.86459136       11.99471419
    71688.79486733       11.99471419 47439664.99200319       23.86459136
        1.01926238]
[      23.86459136       23.86459136       23.86459136       23.86459136
       23.86459136       23.86459136       23.86459136       23.86459136
       23.86459136       29.81190399       45.46016919       14.95604278
       23.86459136       23.86459136       23.86459136       11.99471419
    71688.79486733       11.99471419 47439664.99200311       23.86459136
        1.01926241]
[      24.01653423       24.01653423       24.01653423       24.01653423
       24.01653423       24.01653423       24.01653423       24.01653423
       24.01653423       24.01653423       57.17809618       15.05075202
       24.01653423       24.01653423       24.01653423       12.07029613
    72146.82906537       12.07029613 47742766.59886877       24.01653423
        1.00960512]
[      24.01750481       24.01750481       24.01750481       24.01750481
       24.01750481       24.01750481       24.01750481       24.01750481
       24.01750481       24.01750481       45.75219691       18.78438299
       24.01750481       24.01750481       24.01750481       12.07077895
    72149.75488001       12.07077895 47744702.74058617       24.01750481
        1.00954391]
[      23.86459136       23.86459136       23.86459136       23.86459136
       23.86459136       23.86459136       23.86459136       23.86459136
       23.86459136       23.86459136       45.46016919       14.95604278
       29.81190399       23.86459136       23.86459136       11.99471419
    71688.79486733       11.99471419 47439664.99200319       23.86459136
        1.01926255]
[      23.86459136       23.86459136       23.86459136       23.86459136
       23.86459136       23.86459136       23.86459136       23.86459136
       23.86459136       23.86459136       45.46016919       14.95604278
       23.86459136       29.81190399       23.86459136       11.99471419
    71688.79486733       11.99471419 47439664.99200311       23.86459136
        1.01926245]
[      23.86459136       23.86459136       23.86459136       23.86459136
       23.86459136       23.86459136       23.86459136       23.86459136
       23.86459136       23.86459136       45.46016919       14.95604278
       23.86459136       23.86459136       29.81190399       11.99471419
    71688.79486733       11.99471419 47439664.99200311       23.86459136
        1.01926249]
[      24.01810683       24.01810683       24.01810683       24.01810683
       24.01810683       24.01810683       24.01810683       24.01810683
       24.01810683       24.01810683       45.75334661       15.05173227
       24.01810683       24.01810683       24.01810683       15.05173227
    72151.56965487       12.07107843 47745903.65784842       24.01810683
        1.0095059 ]
[      24.01641619       24.01641619       24.01641619       24.01641619
       24.01641619       24.01641619       24.01641619       24.01641619
       24.01641619       24.01641619       45.75011791       15.05067844
       24.01641619       24.01641619       24.01641619       12.07023741
    90183.09154942       12.07023741 47742531.13638457       24.01641619
        1.00961251]
[      24.01810683       24.01810683       24.01810683       24.01810683
       24.01810683       24.01810683       24.01810683       24.01810683
       24.01810683       24.01810683       45.75334661       15.05173227
       24.01810683       24.01810683       24.01810683       12.07107843
    72151.56965487       15.05173227 47745903.65784833       24.01810683
        1.00950593]
[      23.86372975       23.86372975       23.86372975       23.86372975
       23.86372975       23.86372975       23.86372975       23.86372975
       23.86372975       23.86372975       45.4585237        14.95550573
       23.86372975       23.86372975       23.86372975       11.99428561
    71686.19748861       11.99428561 59297432.73868405       23.86372975
        1.01931781]
[      23.86459136       23.86459136       23.86459136       23.86459136
       23.86459136       23.86459136       23.86459136       23.86459136
       23.86459136       23.86459136       45.46016919       14.95604278
       23.86459136       23.86459136       23.86459136       11.99471419
    71688.79486733       11.99471419 47439664.99200319       29.81190399
        1.01926268]
[      24.17007887       24.17007887       24.17007887       24.17007887
       24.17007887       24.17007887       24.17007887       24.17007887
       24.17007887       24.17007887       46.04357181       15.14646289
       24.17007887       24.17007887       24.17007887       12.14667972
    72609.68164442       12.14667972 48049056.74281288       24.17007887
        1.        ]
KQ_r
[0.03354365 0.04190308 0.04190308 0.04190308 0.04190308 0.04190308
 0.04190308 0.04190308 0.04190308 0.04190308 0.02199728 0.06686261
 0.04190308 0.04190308 0.04190308 0.08337006 0.00001395 0.08337006
 0.00000002 0.04190308 0.98110128]
[0.04190308 0.03354365 0.04190308 0.04190308 0.04190308 0.04190308
 0.04190308 0.04190308 0.04190308 0.04190308 0.02199728 0.06686261
 0.04190308 0.04190308 0.04190308 0.08337006 0.00001395 0.08337006
 0.00000002 0.04190308 0.95418891]
[0.04190308 0.04190308 0.03354365 0.04190308 0.04190308 0.04190308
 0.04190308 0.04190308 0.04190308 0.04190308 0.02199728 0.06686261
 0.04190308 0.04190308 0.04190308 0.08337006 0.00001395 0.08337006
 0.00000002 0.04190308 0.92801478]
[0.04190308 0.04190308 0.04190308 0.03354365 0.04190308 0.04190308
 0.04190308 0.04190308 0.04190308 0.04190308 0.02199728 0.06686261
 0.04190308 0.04190308 0.04190308 0.08337006 0.00001395 0.08337006
 0.00000002 0.04190308 1.12748594]
[0.04190308 0.04190308 0.04190308 0.04190308 0.03354365 0.04190308
 0.04190308 0.04190308 0.04190308 0.04190308 0.02199728 0.06686261
 0.04190308 0.04190308 0.04190308 0.08337006 0.00001395 0.08337006
 0.00000002 0.04190308 1.09655816]
[0.04190308 0.04190308 0.04190308 0.04190308 0.04190308 0.03354365
 0.04190308 0.04190308 0.04190308 0.04190308 0.02199728 0.06686261
 0.04190308 0.04190308 0.04190308 0.08337006 0.00001395 0.08337006
 0.00000002 0.04190308 1.06647875]
[0.04190308 0.04190308 0.04190308 0.04190308 0.04190308 0.04190308
 0.03354365 0.04190308 0.04190308 0.04190308 0.02199728 0.06686261
 0.04190308 0.04190308 0.04190308 0.08337006 0.00001395 0.08337006
 0.00000002 0.04190308 1.03722446]
[0.04190308 0.04190308 0.04190308 0.04190308 0.04190308 0.04190308
 0.04190308 0.03354365 0.04190308 0.04190308 0.02199728 0.06686261
 0.04190308 0.04190308 0.04190308 0.08337006 0.00001395 0.08337006
 0.00000002 0.04190308 1.00877264]
[0.04190308 0.04190308 0.04190308 0.04190308 0.04190308 0.04190308
 0.04190308 0.04190308 0.03354365 0.04190308 0.02199728 0.06686261
 0.04190308 0.04190308 0.04190308 0.08337006 0.00001395 0.08337006
 0.00000002 0.04190308 0.98110165]
[0.04190308 0.04190308 0.04190308 0.04190308 0.04190308 0.04190308
 0.04190308 0.04190308 0.04190308 0.03354365 0.02199728 0.06686261
 0.04190308 0.04190308 0.04190308 0.08337006 0.00001395 0.08337006
 0.00000002 0.04190308 0.98110162]
[0.04163798 0.04163798 0.04163798 0.04163798 0.04163798 0.04163798
 0.04163798 0.04163798 0.04163798 0.04163798 0.01748921 0.06644186
 0.04163798 0.04163798 0.04163798 0.08284801 0.00001386 0.08284801
 0.00000002 0.04163798 0.99048626]
[0.0416363  0.0416363  0.0416363  0.0416363  0.0416363  0.0416363
 0.0416363  0.0416363  0.0416363  0.0416363  0.02185687 0.05323571
 0.0416363  0.0416363  0.0416363  0.08284469 0.00001386 0.08284469
 0.00000002 0.0416363  0.99054631]
[0.04190308 0.04190308 0.04190308 0.04190308 0.04190308 0.04190308
 0.04190308 0.04190308 0.04190308 0.04190308 0.02199728 0.06686261
 0.03354365 0.04190308 0.04190308 0.08337006 0.00001395 0.08337006
 0.00000002 0.04190308 0.98110149]
[0.04190308 0.04190308 0.04190308 0.04190308 0.04190308 0.04190308
 0.04190308 0.04190308 0.04190308 0.04190308 0.02199728 0.06686261
 0.04190308 0.03354365 0.04190308 0.08337006 0.00001395 0.08337006
 0.00000002 0.04190308 0.98110158]
[0.04190308 0.04190308 0.04190308 0.04190308 0.04190308 0.04190308
 0.04190308 0.04190308 0.04190308 0.04190308 0.02199728 0.06686261
 0.04190308 0.04190308 0.03354365 0.08337006 0.00001395 0.08337006
 0.00000002 0.04190308 0.98110154]
[0.04163525 0.04163525 0.04163525 0.04163525 0.04163525 0.04163525
 0.04163525 0.04163525 0.04163525 0.04163525 0.02185632 0.06643754
 0.04163525 0.04163525 0.04163525 0.06643754 0.00001386 0.08284264
 0.00000002 0.04163525 0.99058361]
[0.04163819 0.04163819 0.04163819 0.04163819 0.04163819 0.04163819
 0.04163819 0.04163819 0.04163819 0.04163819 0.02185787 0.06644219
 0.04163819 0.04163819 0.04163819 0.08284841 0.00001109 0.08284841
 0.00000002 0.04163819 0.99047901]
[0.04163525 0.04163525 0.04163525 0.04163525 0.04163525 0.04163525
 0.04163525 0.04163525 0.04163525 0.04163525 0.02185632 0.06643754
 0.04163525 0.04163525 0.04163525 0.08284264 0.00001386 0.06643754
 0.00000002 0.04163525 0.99058358]
[0.0419046  0.0419046  0.0419046  0.0419046  0.0419046  0.0419046
 0.0419046  0.0419046  0.0419046  0.0419046  0.02199807 0.06686501
 0.0419046  0.0419046  0.0419046  0.08337304 0.00001395 0.08337304
 0.00000002 0.0419046  0.98104829]
[0.04190308 0.04190308 0.04190308 0.04190308 0.04190308 0.04190308
 0.04190308 0.04190308 0.04190308 0.04190308 0.02199728 0.06686261
 0.04190308 0.04190308 0.04190308 0.08337006 0.00001395 0.08337006
 0.00000002 0.03354365 0.98110136]
[0.04137347 0.04137347 0.04137347 0.04137347 0.04137347 0.04137347
 0.04137347 0.04137347 0.04137347 0.04137347 0.02171856 0.06602201
 0.04137347 0.04137347 0.04137347 0.08232702 0.00001377 0.08232702
 0.00000002 0.04137347 1.        ]
scale_to_one
0.6931471805599453
x_scaled
tensor([0.9371, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.6648, 0.9371, 1.0000, 1.0000, 1.0000, 1.0000, 0.0437, 1.0000,
        0.0044, 1.0000, 0.0000])
x_scaled
tensor([1.0000, 0.9371, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.6648, 0.9371, 1.0000, 1.0000, 1.0000, 1.0000, 0.0437, 1.0000,
        0.0044, 1.0000, 0.0000])
x_scaled
tensor([1.0000, 1.0000, 0.9371, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.6648, 0.9371, 1.0000, 1.0000, 1.0000, 1.0000, 0.0437, 1.0000,
        0.0044, 1.0000, 0.0000])
x_scaled
tensor([1.0000, 1.0000, 1.0000, 0.9371, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.6648, 0.9371, 1.0000, 1.0000, 1.0000, 1.0000, 0.0437, 1.0000,
        0.0044, 1.0000, 0.0000])
x_scaled
tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.9371, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.6648, 0.9371, 1.0000, 1.0000, 1.0000, 1.0000, 0.0437, 1.0000,
        0.0044, 1.0000, 0.0000])
x_scaled
tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9371, 1.0000, 1.0000, 1.0000,
        1.0000, 0.6648, 0.9371, 1.0000, 1.0000, 1.0000, 1.0000, 0.0437, 1.0000,
        0.0044, 1.0000, 0.0000])
x_scaled
tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9371, 1.0000, 1.0000,
        1.0000, 0.6648, 0.9371, 1.0000, 1.0000, 1.0000, 1.0000, 0.0437, 1.0000,
        0.0044, 1.0000, 0.0000])
x_scaled
tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9371, 1.0000,
        1.0000, 0.6648, 0.9371, 1.0000, 1.0000, 1.0000, 1.0000, 0.0437, 1.0000,
        0.0044, 1.0000, 0.0000])
x_scaled
tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9371,
        1.0000, 0.6648, 0.9371, 1.0000, 1.0000, 1.0000, 1.0000, 0.0437, 1.0000,
        0.0044, 1.0000, 0.0000])/afs/crc.nd.edu/user/s/sbritto2/ml/Max_Entropy_Python/Basic_Functions/max_entropy_functions.py:104: RuntimeWarning: overflow encountered in exp
  EKQ = np.exp(log_EKQ)

x_scaled
tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        0.9371, 0.6648, 0.9371, 1.0000, 1.0000, 1.0000, 1.0000, 0.0437, 1.0000,
        0.0044, 1.0000, 0.0000])
x_scaled
tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.6186, 0.9371, 1.0000, 1.0000, 1.0000, 1.0000, 0.0437, 1.0000,
        0.0044, 1.0000, 0.0000])
x_scaled
tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.6648, 0.8770, 1.0000, 1.0000, 1.0000, 1.0000, 0.0437, 1.0000,
        0.0044, 1.0000, 0.0000])
x_scaled
tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.6648, 0.9371, 0.9371, 1.0000, 1.0000, 1.0000, 0.0437, 1.0000,
        0.0044, 1.0000, 0.0000])
x_scaled
tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.6648, 0.9371, 1.0000, 0.9371, 1.0000, 1.0000, 0.0437, 1.0000,
        0.0044, 1.0000, 0.0000])
x_scaled
tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.6648, 0.9371, 1.0000, 1.0000, 0.9371, 1.0000, 0.0437, 1.0000,
        0.0044, 1.0000, 0.0000])
x_scaled
tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.6648, 0.9371, 1.0000, 1.0000, 1.0000, 0.9371, 0.0437, 1.0000,
        0.0044, 1.0000, 0.0000])
x_scaled
tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.6648, 0.9371, 1.0000, 1.0000, 1.0000, 1.0000, 0.0400, 1.0000,
        0.0044, 1.0000, 0.0000])
x_scaled
tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.6648, 0.9371, 1.0000, 1.0000, 1.0000, 1.0000, 0.0437, 0.9371,
        0.0044, 1.0000, 0.0000])
x_scaled
tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.6648, 0.9371, 1.0000, 1.0000, 1.0000, 1.0000, 0.0437, 1.0000,
        0.0040, 1.0000, 0.0000])
x_scaled
tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.6648, 0.9371, 1.0000, 1.0000, 1.0000, 1.0000, 0.0437, 1.0000,
        0.0044, 0.9371, 0.0000])
x_scaled
tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.6648, 0.9371, 1.0000, 1.0000, 1.0000, 1.0000, 0.0437, 1.0000,
        0.0044, 1.0000, 0.0000])
Previous state values
[ 0.00019559 -0.00054887  0.00390166 -0.00391674 -0.00017192  0.00178456
  0.00139512 -0.00322908  0.00119717 -0.00150324  0.00141542  0.00192726
  0.00075651  0.00163028 -0.00157014 -0.00321653  0.00006269 -0.0028068
  0.00001643 -0.0005548   0.        ]
current action_value_vec
[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan]
nan
Traceback (most recent call last):
  File "./GLYCOLYSIS_TCA_GOGAT_FUNCTION.py", line 695, in <module>
    run(sys.argv[:])
  File "./GLYCOLYSIS_TCA_GOGAT_FUNCTION.py", line 531, in run
    random_steps_taken,nn_steps_taken] = me.sarsa_n(nn_model,loss_fn, optimizer, scheduler, state_sample, n_back_step, epsilon)
  File "/afs/crc.nd.edu/user/s/sbritto2/ml/Max_Entropy_Python/Basic_Functions/machine_learning_functions.py", line 209, in sarsa_n
    state_value_vec_NOT_USED] = policy_function(nn_model, states_matrix[:,t], v_log_counts_matrix[:,t], state_value_vec_NOT_USED, epsilon_greedy)#regulate each reaction.                
  File "/afs/crc.nd.edu/user/s/sbritto2/ml/Max_Entropy_Python/Basic_Functions/machine_learning_functions.py", line 553, in policy_function
    action_choice = np.random.choice(np.flatnonzero(action_value_vec == action_value_vec.max()))
  File "mtrand.pyx", line 1125, in mtrand.RandomState.choice
ValueError: 'a' cannot be empty unless no samples are taken
